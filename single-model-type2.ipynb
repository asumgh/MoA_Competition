{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-10T19:29:40.707045Z",
     "iopub.status.busy": "2020-11-10T19:29:40.706305Z",
     "iopub.status.idle": "2020-11-10T19:29:41.754762Z",
     "shell.execute_reply": "2020-11-10T19:29:41.753904Z"
    },
    "papermill": {
     "duration": 1.088346,
     "end_time": "2020-11-10T19:29:41.754892",
     "exception": false,
     "start_time": "2020-11-10T19:29:40.666546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/iterativestratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-10T19:29:41.829871Z",
     "iopub.status.busy": "2020-11-10T19:29:41.829004Z",
     "iopub.status.idle": "2020-11-10T19:29:43.990364Z",
     "shell.execute_reply": "2020-11-10T19:29:43.988916Z"
    },
    "papermill": {
     "duration": 2.203653,
     "end_time": "2020-11-10T19:29:43.990493",
     "exception": false,
     "start_time": "2020-11-10T19:29:41.786840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-11-10T19:29:44.081394Z",
     "iopub.status.busy": "2020-11-10T19:29:44.080589Z",
     "iopub.status.idle": "2020-11-10T19:29:44.090989Z",
     "shell.execute_reply": "2020-11-10T19:29:44.091673Z"
    },
    "papermill": {
     "duration": 0.069264,
     "end_time": "2020-11-10T19:29:44.091823",
     "exception": false,
     "start_time": "2020-11-10T19:29:44.022559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_features.csv',\n",
       " 'sample_submission.csv',\n",
       " 'train_drug.csv',\n",
       " 'train_features.csv',\n",
       " 'train_targets_scored.csv',\n",
       " 'train_targets_nonscored.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/lish-moa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-11-10T19:29:44.192536Z",
     "iopub.status.busy": "2020-11-10T19:29:44.191742Z",
     "iopub.status.idle": "2020-11-10T19:29:50.672046Z",
     "shell.execute_reply": "2020-11-10T19:29:50.670847Z"
    },
    "papermill": {
     "duration": 6.537162,
     "end_time": "2020-11-10T19:29:50.672172",
     "exception": false,
     "start_time": "2020-11-10T19:29:44.135010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "sample_submission = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:29:50.741841Z",
     "iopub.status.busy": "2020-11-10T19:29:50.739951Z",
     "iopub.status.idle": "2020-11-10T19:29:50.742628Z",
     "shell.execute_reply": "2020-11-10T19:29:50.743129Z"
    },
    "papermill": {
     "duration": 0.039874,
     "end_time": "2020-11-10T19:29:50.743259",
     "exception": false,
     "start_time": "2020-11-10T19:29:50.703385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:29:50.819746Z",
     "iopub.status.busy": "2020-11-10T19:29:50.819033Z",
     "iopub.status.idle": "2020-11-10T19:30:00.794169Z",
     "shell.execute_reply": "2020-11-10T19:30:00.793035Z"
    },
    "papermill": {
     "duration": 10.020365,
     "end_time": "2020-11-10T19:30:00.794344",
     "exception": false,
     "start_time": "2020-11-10T19:29:50.773979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#RankGauss\n",
    "\n",
    "for col in (GENES + CELLS):\n",
    "\n",
    "    transformer = QuantileTransformer(n_quantiles=100,random_state=1, output_distribution=\"normal\")\n",
    "    vec_len = len(train_features[col].values)\n",
    "    vec_len_test = len(test_features[col].values)\n",
    "    raw_vec = train_features[col].values.reshape(vec_len, 1)\n",
    "    transformer.fit(raw_vec)\n",
    "\n",
    "    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:30:00.863989Z",
     "iopub.status.busy": "2020-11-10T19:30:00.863077Z",
     "iopub.status.idle": "2020-11-10T19:30:00.869254Z",
     "shell.execute_reply": "2020-11-10T19:30:00.868704Z"
    },
    "papermill": {
     "duration": 0.043773,
     "end_time": "2020-11-10T19:30:00.869370",
     "exception": false,
     "start_time": "2020-11-10T19:30:00.825597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=1):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:30:00.952818Z",
     "iopub.status.busy": "2020-11-10T19:30:00.951637Z",
     "iopub.status.idle": "2020-11-10T19:30:01.400692Z",
     "shell.execute_reply": "2020-11-10T19:30:01.401271Z"
    },
    "papermill": {
     "duration": 0.500609,
     "end_time": "2020-11-10T19:30:01.401416",
     "exception": false,
     "start_time": "2020-11-10T19:30:00.900807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(random_state=1).fit(train_features[CELLS])\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), color='k', lw=2)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Total explained variance')\n",
    "plt.xlim(0, 80)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.axvline(70, c='b')\n",
    "plt.axhline(0.9, c='r')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:30:01.485030Z",
     "iopub.status.busy": "2020-11-10T19:30:01.483847Z",
     "iopub.status.idle": "2020-11-10T19:30:09.289923Z",
     "shell.execute_reply": "2020-11-10T19:30:09.288852Z"
    },
    "papermill": {
     "duration": 7.85222,
     "end_time": "2020-11-10T19:30:09.290048",
     "exception": false,
     "start_time": "2020-11-10T19:30:01.437828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GENES\n",
    "n_comp = 480  #<--Update\n",
    "pca_g = PCA(n_components=n_comp, random_state=1)\n",
    "train2 = pca_g.fit_transform(train_features[GENES])\n",
    "test2 =  pca_g.transform(test_features[GENES])\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:30:09.367001Z",
     "iopub.status.busy": "2020-11-10T19:30:09.365644Z",
     "iopub.status.idle": "2020-11-10T19:30:10.077016Z",
     "shell.execute_reply": "2020-11-10T19:30:10.076447Z"
    },
    "papermill": {
     "duration": 0.753611,
     "end_time": "2020-11-10T19:30:10.077131",
     "exception": false,
     "start_time": "2020-11-10T19:30:09.323520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CELLS\n",
    "n_comp = 69  #<--Update\n",
    "pca_c = PCA(n_components=n_comp, random_state=1)\n",
    "train2 = pca_c.fit_transform(train_features[CELLS])\n",
    "test2 = pca_c.transform(test_features[CELLS])\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:30:10.148399Z",
     "iopub.status.busy": "2020-11-10T19:30:10.147503Z",
     "iopub.status.idle": "2020-11-10T19:30:10.151047Z",
     "shell.execute_reply": "2020-11-10T19:30:10.151623Z"
    },
    "papermill": {
     "duration": 0.041808,
     "end_time": "2020-11-10T19:30:10.151758",
     "exception": false,
     "start_time": "2020-11-10T19:30:10.109950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23814, 1425)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:30:10.230180Z",
     "iopub.status.busy": "2020-11-10T19:30:10.228858Z",
     "iopub.status.idle": "2020-11-10T19:30:11.171009Z",
     "shell.execute_reply": "2020-11-10T19:30:11.172346Z"
    },
    "papermill": {
     "duration": 0.987606,
     "end_time": "2020-11-10T19:30:11.172555",
     "exception": false,
     "start_time": "2020-11-10T19:30:10.184949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23814, 1039)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_thresh = VarianceThreshold(0.8)  #<-- Update\n",
    "data = train_features.append(test_features)\n",
    "data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n",
    "\n",
    "train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "\n",
    "\n",
    "train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n",
    "\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:30:11.310890Z",
     "iopub.status.busy": "2020-11-10T19:30:11.309393Z",
     "iopub.status.idle": "2020-11-10T19:31:29.534998Z",
     "shell.execute_reply": "2020-11-10T19:31:29.533641Z"
    },
    "papermill": {
     "duration": 78.322835,
     "end_time": "2020-11-10T19:31:29.535135",
     "exception": false,
     "start_time": "2020-11-10T19:30:11.212300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_cluster(train, test, n_clusters_g = 35, n_clusters_c = 5, SEED = 123):\n",
    "    \n",
    "    features_g = list(train.columns[4:776])\n",
    "    features_c = list(train.columns[776:876])\n",
    "    \n",
    "    def create_cluster(train, test, features, kind = 'g', n_clusters = n_clusters_g):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        train[f'clusters_{kind}'] = kmeans.labels_[:train.shape[0]]\n",
    "        test[f'clusters_{kind}'] = kmeans.labels_[train.shape[0]:]\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "    train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "    train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features ,test_features=fe_cluster(train_features,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:31:29.626779Z",
     "iopub.status.busy": "2020-11-10T19:31:29.626095Z",
     "iopub.status.idle": "2020-11-10T19:31:36.211462Z",
     "shell.execute_reply": "2020-11-10T19:31:36.210767Z"
    },
    "papermill": {
     "duration": 6.643963,
     "end_time": "2020-11-10T19:31:36.211592",
     "exception": false,
     "start_time": "2020-11-10T19:31:29.567629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(df):\n",
    "    df['time_dose'] = df['cp_time'].astype(str)+df['cp_dose']\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=['time_dose'])\n",
    "    \n",
    "    \n",
    "    features_g = list(df.columns[4:776])\n",
    "    features_c = list(df.columns[776:876])\n",
    "    \n",
    "    df['g_sum'] = df[features_g].sum(axis = 1)\n",
    "    df['g_mean'] = df[features_g].mean(axis = 1)\n",
    "    df['g_std'] = df[features_g].std(axis = 1)\n",
    "    df['g_kurt'] = df[features_g].kurtosis(axis = 1)\n",
    "    df['g_skew'] = df[features_g].skew(axis = 1)\n",
    "    df['c_sum'] = df[features_c].sum(axis = 1)\n",
    "    df['c_mean'] = df[features_c].mean(axis = 1)\n",
    "    df['c_std'] = df[features_c].std(axis = 1)\n",
    "    df['c_kurt'] = df[features_c].kurtosis(axis = 1)\n",
    "    df['c_skew'] = df[features_c].skew(axis = 1)\n",
    "    df['gc_sum'] = df[features_g + features_c].sum(axis = 1)\n",
    "    df['gc_mean'] = df[features_g + features_c].mean(axis = 1)\n",
    "    df['gc_std'] = df[features_g + features_c].std(axis = 1)\n",
    "    df['gc_kurt'] = df[features_g + features_c].kurtosis(axis = 1)\n",
    "    df['gc_skew'] = df[features_g + features_c].skew(axis = 1)\n",
    "    \n",
    "    features_c = list(df.columns[776:876])\n",
    "    for feature in features_c:\n",
    "        df[f'{feature}_squared'] = df[feature] ** 2\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_features = process_data(train_features)\n",
    "test_features = process_data(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:31:36.291581Z",
     "iopub.status.busy": "2020-11-10T19:31:36.290096Z",
     "iopub.status.idle": "2020-11-10T19:31:36.974537Z",
     "shell.execute_reply": "2020-11-10T19:31:36.973911Z"
    },
    "papermill": {
     "duration": 0.726778,
     "end_time": "2020-11-10T19:31:36.974673",
     "exception": false,
     "start_time": "2020-11-10T19:31:36.247895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:31:37.049633Z",
     "iopub.status.busy": "2020-11-10T19:31:37.048457Z",
     "iopub.status.idle": "2020-11-10T19:31:37.137597Z",
     "shell.execute_reply": "2020-11-10T19:31:37.137030Z"
    },
    "papermill": {
     "duration": 0.126763,
     "end_time": "2020-11-10T19:31:37.137720",
     "exception": false,
     "start_time": "2020-11-10T19:31:37.010957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:31:37.230530Z",
     "iopub.status.busy": "2020-11-10T19:31:37.229414Z",
     "iopub.status.idle": "2020-11-10T19:31:37.235907Z",
     "shell.execute_reply": "2020-11-10T19:31:37.236508Z"
    },
    "papermill": {
     "duration": 0.065708,
     "end_time": "2020-11-10T19:31:37.236658",
     "exception": false,
     "start_time": "2020-11-10T19:31:37.170950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:31:37.355918Z",
     "iopub.status.busy": "2020-11-10T19:31:37.354960Z",
     "iopub.status.idle": "2020-11-10T19:31:39.340688Z",
     "shell.execute_reply": "2020-11-10T19:31:39.339973Z"
    },
    "papermill": {
     "duration": 2.052299,
     "end_time": "2020-11-10T19:31:39.340836",
     "exception": false,
     "start_time": "2020-11-10T19:31:37.288537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "FOLDS = 11\n",
    "\n",
    "# LOAD FILES\n",
    "scored = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\n",
    "drug = pd.read_csv('/kaggle/input/lish-moa/train_drug.csv')\n",
    "targets = scored.columns[1:]\n",
    "scored = scored.merge(drug, on='sig_id', how='left') \n",
    "\n",
    "# LOCATE DRUGS\n",
    "vc = scored.drug_id.value_counts()\n",
    "vc1 = vc.loc[(vc==6)|(vc==12)|(vc==18)].index.sort_values()\n",
    "vc2 = vc.loc[(vc!=6)&(vc!=12)&(vc!=18)].index.sort_values()\n",
    "\n",
    "# STRATIFY DRUGS 18X OR LESS\n",
    "dct1 = {}; dct2 = {}\n",
    "skf = MultilabelStratifiedKFold(n_splits=FOLDS, shuffle=True, \n",
    "          random_state=SEED)\n",
    "tmp = scored.groupby('drug_id')[targets].mean().loc[vc1]\n",
    "for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n",
    "    dd = {k:fold for k in tmp.index[idxV].values}\n",
    "    dct1.update(dd)\n",
    "\n",
    "# STRATIFY DRUGS MORE THAN 18X\n",
    "skf = MultilabelStratifiedKFold(n_splits=FOLDS, shuffle=True, \n",
    "          random_state=SEED)\n",
    "tmp = scored.loc[scored.drug_id.isin(vc2)].reset_index(drop=True)\n",
    "for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n",
    "    dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "    dct2.update(dd)\n",
    "\n",
    "# ASSIGN FOLDS\n",
    "scored['fold'] = scored.drug_id.map(dct1)\n",
    "scored.loc[scored.fold.isna(),'fold'] =\\\n",
    "    scored.loc[scored.fold.isna(),'sig_id'].map(dct2)\n",
    "scored.fold = scored.fold.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:31:39.417528Z",
     "iopub.status.busy": "2020-11-10T19:31:39.415976Z",
     "iopub.status.idle": "2020-11-10T19:31:39.662460Z",
     "shell.execute_reply": "2020-11-10T19:31:39.661563Z"
    },
    "papermill": {
     "duration": 0.286123,
     "end_time": "2020-11-10T19:31:39.662599",
     "exception": false,
     "start_time": "2020-11-10T19:31:39.376476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folds = pd.merge(train,scored[['sig_id','fold']],on='sig_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:31:39.743772Z",
     "iopub.status.busy": "2020-11-10T19:31:39.742341Z",
     "iopub.status.idle": "2020-11-10T19:31:39.746664Z",
     "shell.execute_reply": "2020-11-10T19:31:39.745714Z"
    },
    "papermill": {
     "duration": 0.04652,
     "end_time": "2020-11-10T19:31:39.746813",
     "exception": false,
     "start_time": "2020-11-10T19:31:39.700293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1405)\n",
      "(21948, 1406)\n",
      "(3624, 1199)\n",
      "(21948, 207)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0331,
     "end_time": "2020-11-10T19:31:39.813518",
     "exception": false,
     "start_time": "2020-11-10T19:31:39.780418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:31:39.893484Z",
     "iopub.status.busy": "2020-11-10T19:31:39.891703Z",
     "iopub.status.idle": "2020-11-10T19:31:39.894465Z",
     "shell.execute_reply": "2020-11-10T19:31:39.894994Z"
    },
    "papermill": {
     "duration": 0.047552,
     "end_time": "2020-11-10T19:31:39.895120",
     "exception": false,
     "start_time": "2020-11-10T19:31:39.847568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:31:39.979715Z",
     "iopub.status.busy": "2020-11-10T19:31:39.970650Z",
     "iopub.status.idle": "2020-11-10T19:31:39.982717Z",
     "shell.execute_reply": "2020-11-10T19:31:39.982082Z"
    },
    "papermill": {
     "duration": 0.053678,
     "end_time": "2020-11-10T19:31:39.982820",
     "exception": false,
     "start_time": "2020-11-10T19:31:39.929142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "#         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:31:40.064438Z",
     "iopub.status.busy": "2020-11-10T19:31:40.062341Z",
     "iopub.status.idle": "2020-11-10T19:31:40.065168Z",
     "shell.execute_reply": "2020-11-10T19:31:40.065653Z"
    },
    "papermill": {
     "duration": 0.048852,
     "end_time": "2020-11-10T19:31:40.065765",
     "exception": false,
     "start_time": "2020-11-10T19:31:40.016913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:31:40.148716Z",
     "iopub.status.busy": "2020-11-10T19:31:40.146820Z",
     "iopub.status.idle": "2020-11-10T19:31:40.149471Z",
     "shell.execute_reply": "2020-11-10T19:31:40.150013Z"
    },
    "papermill": {
     "duration": 0.049538,
     "end_time": "2020-11-10T19:31:40.150126",
     "exception": false,
     "start_time": "2020-11-10T19:31:40.100588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):      # <-- Update\n",
    "    def __init__(self, num_features, num_targets, hidden_size_medium, hidden_size_final):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size_medium))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size_medium)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size_medium, hidden_size_final))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size_final)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size_final, num_targets))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:31:40.221270Z",
     "iopub.status.busy": "2020-11-10T19:31:40.220586Z",
     "iopub.status.idle": "2020-11-10T19:31:40.224533Z",
     "shell.execute_reply": "2020-11-10T19:31:40.225008Z"
    },
    "papermill": {
     "duration": 0.042426,
     "end_time": "2020-11-10T19:31:40.225142",
     "exception": false,
     "start_time": "2020-11-10T19:31:40.182716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:31:40.303728Z",
     "iopub.status.busy": "2020-11-10T19:31:40.302366Z",
     "iopub.status.idle": "2020-11-10T19:31:40.651423Z",
     "shell.execute_reply": "2020-11-10T19:31:40.650260Z"
    },
    "papermill": {
     "duration": 0.393481,
     "end_time": "2020-11-10T19:31:40.651534",
     "exception": false,
     "start_time": "2020-11-10T19:31:40.258053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1201"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['fold','sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:31:41.107224Z",
     "iopub.status.busy": "2020-11-10T19:31:41.106219Z",
     "iopub.status.idle": "2020-11-10T19:31:41.109555Z",
     "shell.execute_reply": "2020-11-10T19:31:41.108703Z"
    },
    "papermill": {
     "duration": 0.418951,
     "end_time": "2020-11-10T19:31:41.109671",
     "exception": false,
     "start_time": "2020-11-10T19:31:40.690720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 6e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 11\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size_medium=2048\n",
    "hidden_size_final=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:31:41.220399Z",
     "iopub.status.busy": "2020-11-10T19:31:41.210812Z",
     "iopub.status.idle": "2020-11-10T19:31:41.223483Z",
     "shell.execute_reply": "2020-11-10T19:31:41.222932Z"
    },
    "papermill": {
     "duration": 0.079469,
     "end_time": "2020-11-10T19:31:41.223595",
     "exception": false,
     "start_time": "2020-11-10T19:31:41.144126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "    \n",
    "    trn_idx = train[train['fold'] != fold].index\n",
    "    val_idx = train[train['fold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['fold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['fold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size_medium=hidden_size_medium,\n",
    "        hidden_size_final = hidden_size_final\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    print(f\"FOLD: {fold}\")\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"EPOCH: {epoch}, train_loss: {train_loss}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"FOLD{fold}_.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size_medium=hidden_size_medium,\n",
    "        hidden_size_final = hidden_size_final\n",
    "\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"FOLD{fold}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:31:41.309787Z",
     "iopub.status.busy": "2020-11-10T19:31:41.309039Z",
     "iopub.status.idle": "2020-11-10T19:31:41.313260Z",
     "shell.execute_reply": "2020-11-10T19:31:41.312645Z"
    },
    "papermill": {
     "duration": 0.051646,
     "end_time": "2020-11-10T19:31:41.313371",
     "exception": false,
     "start_time": "2020-11-10T19:31:41.261725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:31:41.397705Z",
     "iopub.status.busy": "2020-11-10T19:31:41.396816Z",
     "iopub.status.idle": "2020-11-10T20:24:23.695125Z",
     "shell.execute_reply": "2020-11-10T20:24:23.694551Z"
    },
    "papermill": {
     "duration": 3162.344881,
     "end_time": "2020-11-10T20:24:23.695300",
     "exception": false,
     "start_time": "2020-11-10T19:31:41.350419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 561\n",
      "FOLD: 0\n",
      "EPOCH: 0, train_loss: 0.6570158849159876, valid_loss: 0.253533985465765\n",
      "EPOCH: 1, train_loss: 0.056413830210192084, valid_loss: 0.02108090603724122\n",
      "EPOCH: 2, train_loss: 0.02279845293229207, valid_loss: 0.01913605281151831\n",
      "EPOCH: 3, train_loss: 0.02144935462050713, valid_loss: 0.019143662648275495\n",
      "EPOCH: 4, train_loss: 0.020649441135808442, valid_loss: 0.017951265908777714\n",
      "EPOCH: 5, train_loss: 0.02020280340161079, valid_loss: 0.01926630549132824\n",
      "EPOCH: 6, train_loss: 0.020549086997142203, valid_loss: 0.017728911014273763\n",
      "EPOCH: 7, train_loss: 0.020022131884709384, valid_loss: 0.01748790906276554\n",
      "EPOCH: 8, train_loss: 0.019876352917307463, valid_loss: 0.01768555771559477\n",
      "EPOCH: 9, train_loss: 0.019783958338965207, valid_loss: 0.01756078947801143\n",
      "EPOCH: 10, train_loss: 0.019747858055126973, valid_loss: 0.017650770489126444\n",
      "EPOCH: 11, train_loss: 0.0196923827036069, valid_loss: 0.01725150435231626\n",
      "EPOCH: 12, train_loss: 0.019598482343821954, valid_loss: 0.017436185153201222\n",
      "EPOCH: 13, train_loss: 0.01958780644986874, valid_loss: 0.017638323130086064\n",
      "EPOCH: 14, train_loss: 0.01950064826852236, valid_loss: 0.01751234638504684\n",
      "EPOCH: 15, train_loss: 0.019439322802309807, valid_loss: 0.017501156544312835\n",
      "EPOCH: 16, train_loss: 0.019287500840922196, valid_loss: 0.017209677142091095\n",
      "EPOCH: 17, train_loss: 0.01912830715091565, valid_loss: 0.017374324495904148\n",
      "EPOCH: 18, train_loss: 0.019031053217939842, valid_loss: 0.017326838802546263\n",
      "EPOCH: 19, train_loss: 0.01872619805045617, valid_loss: 0.017281881533563137\n",
      "EPOCH: 20, train_loss: 0.018526538896063965, valid_loss: 0.01713730546180159\n",
      "EPOCH: 21, train_loss: 0.018204206839585915, valid_loss: 0.017207399825565517\n",
      "EPOCH: 22, train_loss: 0.0178453269151923, valid_loss: 0.017194638028740883\n",
      "EPOCH: 23, train_loss: 0.017416619242001802, valid_loss: 0.017353134346194565\n",
      "EPOCH: 24, train_loss: 0.01700351830237569, valid_loss: 0.017348661553114653\n",
      "EPOCH: 25, train_loss: 0.016414122703747872, valid_loss: 0.017247567302547395\n",
      "EPOCH: 26, train_loss: 0.01587221937445112, valid_loss: 0.017401010380126536\n",
      "EPOCH: 27, train_loss: 0.015353700993821407, valid_loss: 0.01742187619674951\n",
      "EPOCH: 28, train_loss: 0.015045709752788147, valid_loss: 0.017460047267377377\n",
      "EPOCH: 29, train_loss: 0.01493296151359876, valid_loss: 0.017427715356461704\n",
      "FOLD: 1\n",
      "EPOCH: 0, train_loss: 0.6573221916571642, valid_loss: 0.2652089484035969\n",
      "EPOCH: 1, train_loss: 0.05670050491029636, valid_loss: 0.0214589461684227\n",
      "EPOCH: 2, train_loss: 0.02266594748466443, valid_loss: 0.019013578537851572\n",
      "EPOCH: 3, train_loss: 0.021568790388604004, valid_loss: 0.018124250695109367\n",
      "EPOCH: 4, train_loss: 0.02075564672645086, valid_loss: 0.017794113839045167\n",
      "EPOCH: 5, train_loss: 0.02029494895862463, valid_loss: 0.017849091440439224\n",
      "EPOCH: 6, train_loss: 0.020078950680983372, valid_loss: 0.0177689369302243\n",
      "EPOCH: 7, train_loss: 0.019839381942382224, valid_loss: 0.017597712110728025\n",
      "EPOCH: 8, train_loss: 0.019896521567343138, valid_loss: 0.017879496794193983\n",
      "EPOCH: 9, train_loss: 0.019810003634446707, valid_loss: 0.017708004917949438\n",
      "EPOCH: 10, train_loss: 0.019752877071881905, valid_loss: 0.0174342084210366\n",
      "EPOCH: 11, train_loss: 0.019714637874410704, valid_loss: 0.01764402794651687\n",
      "EPOCH: 12, train_loss: 0.019661609895336322, valid_loss: 0.017843337496742606\n",
      "EPOCH: 13, train_loss: 0.019568730384493485, valid_loss: 0.01757674850523472\n",
      "EPOCH: 14, train_loss: 0.01954883258216656, valid_loss: 0.017425780184566975\n",
      "EPOCH: 15, train_loss: 0.01942792121703044, valid_loss: 0.017488233745098114\n",
      "EPOCH: 16, train_loss: 0.019355020199257594, valid_loss: 0.01748068048618734\n",
      "EPOCH: 17, train_loss: 0.019249117383972194, valid_loss: 0.017333706142380834\n",
      "EPOCH: 18, train_loss: 0.01905058699254042, valid_loss: 0.01731326337903738\n",
      "EPOCH: 19, train_loss: 0.018844473605545666, valid_loss: 0.017190675949677825\n",
      "EPOCH: 20, train_loss: 0.018603178075490855, valid_loss: 0.017271817196160555\n",
      "EPOCH: 21, train_loss: 0.018316390255513865, valid_loss: 0.017291741678491235\n",
      "EPOCH: 22, train_loss: 0.018000856209068727, valid_loss: 0.01720675639808178\n",
      "EPOCH: 23, train_loss: 0.017607670802718554, valid_loss: 0.017203859519213438\n",
      "EPOCH: 24, train_loss: 0.017194144941197757, valid_loss: 0.017213925952091813\n",
      "EPOCH: 25, train_loss: 0.016670951524224036, valid_loss: 0.017209115903824568\n",
      "EPOCH: 26, train_loss: 0.01617422279639122, valid_loss: 0.017239333828911185\n",
      "EPOCH: 27, train_loss: 0.015724312120045606, valid_loss: 0.017237781547009945\n",
      "EPOCH: 28, train_loss: 0.015408640751280846, valid_loss: 0.01725090481340885\n",
      "EPOCH: 29, train_loss: 0.015272667822547449, valid_loss: 0.017257498111575842\n",
      "FOLD: 2\n",
      "EPOCH: 0, train_loss: 0.6573895659202185, valid_loss: 0.2610679566860199\n",
      "EPOCH: 1, train_loss: 0.056631299547660045, valid_loss: 0.021150380838662386\n",
      "EPOCH: 2, train_loss: 0.0226857359879292, valid_loss: 0.019386648666113615\n",
      "EPOCH: 3, train_loss: 0.021399561984416764, valid_loss: 0.018327426398172975\n",
      "EPOCH: 4, train_loss: 0.02059254804864908, valid_loss: 0.018258808879181743\n",
      "EPOCH: 5, train_loss: 0.020212896550313022, valid_loss: 0.018299498362466693\n",
      "EPOCH: 6, train_loss: 0.01990723504852026, valid_loss: 0.018154921242967248\n",
      "EPOCH: 7, train_loss: 0.019816210565085594, valid_loss: 0.018089260207489133\n",
      "EPOCH: 8, train_loss: 0.01979012940174494, valid_loss: 0.01792297442443669\n",
      "EPOCH: 9, train_loss: 0.019722210816465892, valid_loss: 0.01860313815996051\n",
      "EPOCH: 10, train_loss: 0.019650227318589505, valid_loss: 0.017846761038526893\n",
      "EPOCH: 11, train_loss: 0.019632472895467892, valid_loss: 0.01816968247294426\n",
      "EPOCH: 12, train_loss: 0.01962263676791619, valid_loss: 0.01789449667558074\n",
      "EPOCH: 13, train_loss: 0.01953494591781726, valid_loss: 0.017757806926965714\n",
      "EPOCH: 14, train_loss: 0.019439290994061872, valid_loss: 0.017712575383484364\n",
      "EPOCH: 15, train_loss: 0.0193234507758648, valid_loss: 0.01796386274509132\n",
      "EPOCH: 16, train_loss: 0.019273296141853698, valid_loss: 0.01784139475785196\n",
      "EPOCH: 17, train_loss: 0.019082653383987073, valid_loss: 0.017695154761895537\n",
      "EPOCH: 18, train_loss: 0.01891884573090535, valid_loss: 0.017677299678325653\n",
      "EPOCH: 19, train_loss: 0.01874009159226448, valid_loss: 0.017850539181381464\n",
      "EPOCH: 20, train_loss: 0.018536014434618827, valid_loss: 0.017898106249049306\n",
      "EPOCH: 21, train_loss: 0.01819488229468847, valid_loss: 0.01750547206029296\n",
      "EPOCH: 22, train_loss: 0.01786685263355955, valid_loss: 0.01754971267655492\n",
      "EPOCH: 23, train_loss: 0.017486288737601195, valid_loss: 0.01757536712102592\n",
      "EPOCH: 24, train_loss: 0.01698551555044758, valid_loss: 0.01767757465131581\n",
      "EPOCH: 25, train_loss: 0.016504265642605532, valid_loss: 0.017681752797216177\n",
      "EPOCH: 26, train_loss: 0.015962932820025928, valid_loss: 0.01769713102839887\n",
      "EPOCH: 27, train_loss: 0.01547830295152007, valid_loss: 0.017681368393823504\n",
      "EPOCH: 28, train_loss: 0.015230216073970765, valid_loss: 0.01772097172215581\n",
      "EPOCH: 29, train_loss: 0.015077835163817955, valid_loss: 0.01772241177968681\n",
      "FOLD: 3\n",
      "EPOCH: 0, train_loss: 0.6585414146001523, valid_loss: 0.2598067484796047\n",
      "EPOCH: 1, train_loss: 0.05661642697090522, valid_loss: 0.021124536637216806\n",
      "EPOCH: 2, train_loss: 0.022657931853945438, valid_loss: 0.02127040456980467\n",
      "EPOCH: 3, train_loss: 0.021383018352282353, valid_loss: 0.01877401117235422\n",
      "EPOCH: 4, train_loss: 0.02077734857224501, valid_loss: 0.018455920508131385\n",
      "EPOCH: 5, train_loss: 0.020199030088499572, valid_loss: 0.018121060682460666\n",
      "EPOCH: 6, train_loss: 0.020002210059036046, valid_loss: 0.018111407291144133\n",
      "EPOCH: 7, train_loss: 0.019883285372112043, valid_loss: 0.017964898608624935\n",
      "EPOCH: 8, train_loss: 0.019813993683037084, valid_loss: 0.017875563586130738\n",
      "EPOCH: 9, train_loss: 0.019764005994567506, valid_loss: 0.017632899340242147\n",
      "EPOCH: 10, train_loss: 0.019763469146803405, valid_loss: 0.018038945738226175\n",
      "EPOCH: 11, train_loss: 0.019681344978893414, valid_loss: 0.017844404792413116\n",
      "EPOCH: 12, train_loss: 0.01967819844587491, valid_loss: 0.01782374340109527\n",
      "EPOCH: 13, train_loss: 0.01954925425637227, valid_loss: 0.01764856302179396\n",
      "EPOCH: 14, train_loss: 0.01949594060006814, valid_loss: 0.017646130174398422\n",
      "EPOCH: 15, train_loss: 0.01940055449421589, valid_loss: 0.0175871008541435\n",
      "EPOCH: 16, train_loss: 0.01927856367845566, valid_loss: 0.017501215217635036\n",
      "EPOCH: 17, train_loss: 0.019122967066673133, valid_loss: 0.017518902430310845\n",
      "EPOCH: 18, train_loss: 0.018958934893210728, valid_loss: 0.01741485227830708\n",
      "EPOCH: 19, train_loss: 0.018788942350791052, valid_loss: 0.017351066693663597\n",
      "EPOCH: 20, train_loss: 0.018533635454682205, valid_loss: 0.017254426842555404\n",
      "EPOCH: 21, train_loss: 0.01827254055593258, valid_loss: 0.017143560340628028\n",
      "EPOCH: 22, train_loss: 0.017880752802086182, valid_loss: 0.017241399502381682\n",
      "EPOCH: 23, train_loss: 0.017514007333188485, valid_loss: 0.017323931911960244\n",
      "EPOCH: 24, train_loss: 0.017057508445129946, valid_loss: 0.01720253610983491\n",
      "EPOCH: 25, train_loss: 0.01647893877891012, valid_loss: 0.017331563169136643\n",
      "EPOCH: 26, train_loss: 0.015978710702023446, valid_loss: 0.01735671190544963\n",
      "EPOCH: 27, train_loss: 0.01550849848307478, valid_loss: 0.0173541191034019\n",
      "EPOCH: 28, train_loss: 0.015179618202054348, valid_loss: 0.017344115069136024\n",
      "EPOCH: 29, train_loss: 0.014997824680251189, valid_loss: 0.017360463039949536\n",
      "FOLD: 4\n",
      "EPOCH: 0, train_loss: 0.6570983231067657, valid_loss: 0.2676926888525486\n",
      "EPOCH: 1, train_loss: 0.056784723240595594, valid_loss: 0.02095790719613433\n",
      "EPOCH: 2, train_loss: 0.022698585469371233, valid_loss: 0.019095996161922812\n",
      "EPOCH: 3, train_loss: 0.02155505720143899, valid_loss: 0.018621461698785424\n",
      "EPOCH: 4, train_loss: 0.02061155741699995, valid_loss: 0.01811933354474604\n",
      "EPOCH: 5, train_loss: 0.02037897168730314, valid_loss: 0.018019326496869326\n",
      "EPOCH: 6, train_loss: 0.0200735514696974, valid_loss: 0.017659010598435998\n",
      "EPOCH: 7, train_loss: 0.01995902587301456, valid_loss: 0.017812299076467752\n",
      "EPOCH: 8, train_loss: 0.019896008145923797, valid_loss: 0.017808370990678668\n",
      "EPOCH: 9, train_loss: 0.01983161576283284, valid_loss: 0.017527741845697165\n",
      "EPOCH: 10, train_loss: 0.01980619361767402, valid_loss: 0.017594312084838748\n",
      "EPOCH: 11, train_loss: 0.01973807646964605, valid_loss: 0.017469080165028572\n",
      "EPOCH: 12, train_loss: 0.019716457129479982, valid_loss: 0.01751751941628754\n",
      "EPOCH: 13, train_loss: 0.01962207990865677, valid_loss: 0.017324365442618728\n",
      "EPOCH: 14, train_loss: 0.019512890479885615, valid_loss: 0.017197892535477877\n",
      "EPOCH: 15, train_loss: 0.01942323652119973, valid_loss: 0.01736559276469052\n",
      "EPOCH: 16, train_loss: 0.019349922211124346, valid_loss: 0.017232432728633285\n",
      "EPOCH: 17, train_loss: 0.019161200771729153, valid_loss: 0.017230863217264414\n",
      "EPOCH: 18, train_loss: 0.01900372740167838, valid_loss: 0.017243847716599703\n",
      "EPOCH: 19, train_loss: 0.018842069503779594, valid_loss: 0.01709634391590953\n",
      "EPOCH: 20, train_loss: 0.01859561373025943, valid_loss: 0.017158082220703363\n",
      "EPOCH: 21, train_loss: 0.018363639664573547, valid_loss: 0.017096954630687833\n",
      "EPOCH: 22, train_loss: 0.017983977324687518, valid_loss: 0.017010110896080732\n",
      "EPOCH: 23, train_loss: 0.017578077454788562, valid_loss: 0.016960222274065018\n",
      "EPOCH: 24, train_loss: 0.017148700542747974, valid_loss: 0.017048741225153208\n",
      "EPOCH: 25, train_loss: 0.01664435335745414, valid_loss: 0.01702821278013289\n",
      "EPOCH: 26, train_loss: 0.01611972636041733, valid_loss: 0.017030813032761216\n",
      "EPOCH: 27, train_loss: 0.015651329062305964, valid_loss: 0.017050362657755613\n",
      "EPOCH: 28, train_loss: 0.015386234956960648, valid_loss: 0.01708825398236513\n",
      "EPOCH: 29, train_loss: 0.01524492311410797, valid_loss: 0.0170704941265285\n",
      "FOLD: 5\n",
      "EPOCH: 0, train_loss: 0.6574626194360929, valid_loss: 0.26265472173690796\n",
      "EPOCH: 1, train_loss: 0.05671196698378294, valid_loss: 0.0211040114518255\n",
      "EPOCH: 2, train_loss: 0.02260079022305898, valid_loss: 0.019747448153793812\n",
      "EPOCH: 3, train_loss: 0.021417630549806815, valid_loss: 0.018969588913023472\n",
      "EPOCH: 4, train_loss: 0.02061158698052168, valid_loss: 0.018608357291668653\n",
      "EPOCH: 5, train_loss: 0.02017239173157857, valid_loss: 0.018342269118875265\n",
      "EPOCH: 6, train_loss: 0.019867229132125012, valid_loss: 0.01836066576652229\n",
      "EPOCH: 7, train_loss: 0.019942117902712945, valid_loss: 0.018308283993974328\n",
      "EPOCH: 8, train_loss: 0.01977664024497454, valid_loss: 0.018712866585701704\n",
      "EPOCH: 9, train_loss: 0.019709380845037792, valid_loss: 0.018416826147586107\n",
      "EPOCH: 10, train_loss: 0.019640611436886665, valid_loss: 0.018343331292271614\n",
      "EPOCH: 11, train_loss: 0.019665750603263196, valid_loss: 0.018238006625324488\n",
      "EPOCH: 12, train_loss: 0.019531280662004765, valid_loss: 0.018070630496367812\n",
      "EPOCH: 13, train_loss: 0.019478251656087544, valid_loss: 0.01818902837112546\n",
      "EPOCH: 14, train_loss: 0.01940197781779063, valid_loss: 0.018429410411044955\n",
      "EPOCH: 15, train_loss: 0.019289212301373482, valid_loss: 0.018317581620067358\n",
      "EPOCH: 16, train_loss: 0.019217274462183315, valid_loss: 0.018305786652490497\n",
      "EPOCH: 17, train_loss: 0.01912326081536519, valid_loss: 0.018191922921687365\n",
      "EPOCH: 18, train_loss: 0.01890124263576208, valid_loss: 0.018140366300940514\n",
      "EPOCH: 19, train_loss: 0.01876301693324095, valid_loss: 0.018160759937018156\n",
      "EPOCH: 20, train_loss: 0.018512406601355627, valid_loss: 0.017948265420272946\n",
      "EPOCH: 21, train_loss: 0.01825607728022031, valid_loss: 0.018269485794007778\n",
      "EPOCH: 22, train_loss: 0.017857374742818184, valid_loss: 0.018215054646134377\n",
      "EPOCH: 23, train_loss: 0.01753943205739443, valid_loss: 0.018178519792854786\n",
      "EPOCH: 24, train_loss: 0.01701999444944354, valid_loss: 0.01836869167163968\n",
      "EPOCH: 25, train_loss: 0.016557511061621018, valid_loss: 0.018251298228278756\n",
      "EPOCH: 26, train_loss: 0.01608932775278122, valid_loss: 0.018229897366836667\n",
      "EPOCH: 27, train_loss: 0.01566055357360687, valid_loss: 0.01827695919200778\n",
      "EPOCH: 28, train_loss: 0.015379969329119492, valid_loss: 0.018294321605935693\n",
      "EPOCH: 29, train_loss: 0.015238172255265407, valid_loss: 0.018293901346623898\n",
      "FOLD: 6\n",
      "EPOCH: 0, train_loss: 0.6583640701495684, valid_loss: 0.27639710903167725\n",
      "EPOCH: 1, train_loss: 0.05718354262316074, valid_loss: 0.02120047272183001\n",
      "EPOCH: 2, train_loss: 0.02257720061028615, valid_loss: 0.019643418490886688\n",
      "EPOCH: 3, train_loss: 0.02150455788255502, valid_loss: 0.018087729811668396\n",
      "EPOCH: 4, train_loss: 0.020687642101293955, valid_loss: 0.01831572689116001\n",
      "EPOCH: 5, train_loss: 0.02022064582277567, valid_loss: 0.018101639114320278\n",
      "EPOCH: 6, train_loss: 0.019961893462981932, valid_loss: 0.017631124472245574\n",
      "EPOCH: 7, train_loss: 0.019966897196494617, valid_loss: 0.017625398002564907\n",
      "EPOCH: 8, train_loss: 0.019800318619952753, valid_loss: 0.01751587796024978\n",
      "EPOCH: 9, train_loss: 0.01976706211765607, valid_loss: 0.017522096866741776\n",
      "EPOCH: 10, train_loss: 0.019745169780575313, valid_loss: 0.017339674290269613\n",
      "EPOCH: 11, train_loss: 0.019672825645941954, valid_loss: 0.01748863677494228\n",
      "EPOCH: 12, train_loss: 0.019637358542054128, valid_loss: 0.017694413661956787\n",
      "EPOCH: 13, train_loss: 0.019637419078021478, valid_loss: 0.01745060831308365\n",
      "EPOCH: 14, train_loss: 0.019529094656881612, valid_loss: 0.017367235384881496\n",
      "EPOCH: 15, train_loss: 0.019487665201991033, valid_loss: 0.01741378754377365\n",
      "EPOCH: 16, train_loss: 0.01931032846466853, valid_loss: 0.01742616994306445\n",
      "EPOCH: 17, train_loss: 0.019169544275754537, valid_loss: 0.017288580304011703\n",
      "EPOCH: 18, train_loss: 0.01899004068512183, valid_loss: 0.0171417526435107\n",
      "EPOCH: 19, train_loss: 0.018855090969457075, valid_loss: 0.017144758952781558\n",
      "EPOCH: 20, train_loss: 0.018627400868214093, valid_loss: 0.017222228460013866\n",
      "EPOCH: 21, train_loss: 0.01835485898817961, valid_loss: 0.017228336073458195\n",
      "EPOCH: 22, train_loss: 0.018033411091145795, valid_loss: 0.01707317982800305\n",
      "EPOCH: 23, train_loss: 0.017650975153232232, valid_loss: 0.017144344048574567\n",
      "EPOCH: 24, train_loss: 0.017210855506933652, valid_loss: 0.017231319099664688\n",
      "EPOCH: 25, train_loss: 0.016770959163132388, valid_loss: 0.017205667216330767\n",
      "EPOCH: 26, train_loss: 0.016284026229419768, valid_loss: 0.017202645540237427\n",
      "EPOCH: 27, train_loss: 0.015846806184317056, valid_loss: 0.01725530275143683\n",
      "EPOCH: 28, train_loss: 0.015543761675078899, valid_loss: 0.01725724944844842\n",
      "EPOCH: 29, train_loss: 0.01542614815899959, valid_loss: 0.017245502909645438\n",
      "FOLD: 7\n",
      "EPOCH: 0, train_loss: 0.6541043753865399, valid_loss: 0.286112267524004\n",
      "EPOCH: 1, train_loss: 0.05578705585927148, valid_loss: 0.02058947621844709\n",
      "EPOCH: 2, train_loss: 0.022913740240508997, valid_loss: 0.019323250045999885\n",
      "EPOCH: 3, train_loss: 0.021848695305517956, valid_loss: 0.01840437320061028\n",
      "EPOCH: 4, train_loss: 0.021018898256028755, valid_loss: 0.018531477311626077\n",
      "EPOCH: 5, train_loss: 0.020728618048037155, valid_loss: 0.019626902882009745\n",
      "EPOCH: 6, train_loss: 0.020373643670655504, valid_loss: 0.017985114129260182\n",
      "EPOCH: 7, train_loss: 0.020043686763206614, valid_loss: 0.01817474141716957\n",
      "EPOCH: 8, train_loss: 0.020056884712244892, valid_loss: 0.018397630425170064\n",
      "EPOCH: 9, train_loss: 0.0197797816576837, valid_loss: 0.01771111600100994\n",
      "EPOCH: 10, train_loss: 0.01961696147918701, valid_loss: 0.017637403681874275\n",
      "EPOCH: 11, train_loss: 0.0197437738268813, valid_loss: 0.017906175227835774\n",
      "EPOCH: 12, train_loss: 0.01990862362841262, valid_loss: 0.01764142536558211\n",
      "EPOCH: 13, train_loss: 0.019695672619191907, valid_loss: 0.017630744026973844\n",
      "EPOCH: 14, train_loss: 0.0196985829668709, valid_loss: 0.017697169678285718\n",
      "EPOCH: 15, train_loss: 0.019443708884565137, valid_loss: 0.017448376398533583\n",
      "EPOCH: 16, train_loss: 0.01940861591904224, valid_loss: 0.017510903999209404\n",
      "EPOCH: 17, train_loss: 0.019238419736487957, valid_loss: 0.017505614552646875\n",
      "EPOCH: 18, train_loss: 0.019188709792834293, valid_loss: 0.017539336578920484\n",
      "EPOCH: 19, train_loss: 0.01891387683115428, valid_loss: 0.01748333452269435\n",
      "EPOCH: 20, train_loss: 0.018580459223329265, valid_loss: 0.01738333562389016\n",
      "EPOCH: 21, train_loss: 0.018451666883841346, valid_loss: 0.017564360750839114\n",
      "EPOCH: 22, train_loss: 0.01811759065412268, valid_loss: 0.01749612670391798\n",
      "EPOCH: 23, train_loss: 0.01766675779053682, valid_loss: 0.017652536975219846\n",
      "EPOCH: 24, train_loss: 0.017330771995873392, valid_loss: 0.0176040381193161\n",
      "EPOCH: 25, train_loss: 0.01685178571062375, valid_loss: 0.017531625228002667\n",
      "EPOCH: 26, train_loss: 0.016380150649177878, valid_loss: 0.017533424077555537\n",
      "EPOCH: 27, train_loss: 0.01602776029111841, valid_loss: 0.017565665999427438\n",
      "EPOCH: 28, train_loss: 0.01568835868818473, valid_loss: 0.01763734081760049\n",
      "EPOCH: 29, train_loss: 0.015511589478465575, valid_loss: 0.017621750477701426\n",
      "FOLD: 8\n",
      "EPOCH: 0, train_loss: 0.6570003406156467, valid_loss: 0.2475533541291952\n",
      "EPOCH: 1, train_loss: 0.05586241041840632, valid_loss: 0.020880643045529723\n",
      "EPOCH: 2, train_loss: 0.022859376560472235, valid_loss: 0.019357813522219658\n",
      "EPOCH: 3, train_loss: 0.021582977091775663, valid_loss: 0.01787380687892437\n",
      "EPOCH: 4, train_loss: 0.020996612343418448, valid_loss: 0.018851665314286947\n",
      "EPOCH: 5, train_loss: 0.020598759285256833, valid_loss: 0.025742504745721817\n",
      "EPOCH: 6, train_loss: 0.020309801130921026, valid_loss: 0.017617493402212858\n",
      "EPOCH: 7, train_loss: 0.02005641379311115, valid_loss: 0.01713819825090468\n",
      "EPOCH: 8, train_loss: 0.01997121194778364, valid_loss: 0.017113706097006798\n",
      "EPOCH: 9, train_loss: 0.019863099237031574, valid_loss: 0.017878312384709716\n",
      "EPOCH: 10, train_loss: 0.019888747224136243, valid_loss: 0.017312036361545324\n",
      "EPOCH: 11, train_loss: 0.01979938081076628, valid_loss: 0.01715295750182122\n",
      "EPOCH: 12, train_loss: 0.01975794310999822, valid_loss: 0.017871029442176223\n",
      "EPOCH: 13, train_loss: 0.019706067475902884, valid_loss: 0.017111847293563187\n",
      "EPOCH: 14, train_loss: 0.01965993312717993, valid_loss: 0.016971045173704624\n",
      "EPOCH: 15, train_loss: 0.01953787802235235, valid_loss: 0.01711835921742022\n",
      "EPOCH: 16, train_loss: 0.01938908731069746, valid_loss: 0.016954635502770543\n",
      "EPOCH: 17, train_loss: 0.019296663377103927, valid_loss: 0.0169064337387681\n",
      "EPOCH: 18, train_loss: 0.019146960794548445, valid_loss: 0.016900846268981695\n",
      "EPOCH: 19, train_loss: 0.0189656929313382, valid_loss: 0.017083341139368713\n",
      "EPOCH: 20, train_loss: 0.01877194048860405, valid_loss: 0.016996470745652914\n",
      "EPOCH: 21, train_loss: 0.018383455073720294, valid_loss: 0.01690088165923953\n",
      "EPOCH: 22, train_loss: 0.01810472529334358, valid_loss: 0.016825560829602182\n",
      "EPOCH: 23, train_loss: 0.017804010382181483, valid_loss: 0.016940967179834843\n",
      "EPOCH: 24, train_loss: 0.017345528024001213, valid_loss: 0.0168172144331038\n",
      "EPOCH: 25, train_loss: 0.016913406822028795, valid_loss: 0.016871841275133193\n",
      "EPOCH: 26, train_loss: 0.016477609383343143, valid_loss: 0.016906356206163764\n",
      "EPOCH: 27, train_loss: 0.016091629426596286, valid_loss: 0.01693024579435587\n",
      "EPOCH: 28, train_loss: 0.01578645408153534, valid_loss: 0.01687391963787377\n",
      "EPOCH: 29, train_loss: 0.015623960078139848, valid_loss: 0.0168874217197299\n",
      "FOLD: 9\n",
      "EPOCH: 0, train_loss: 0.6562421269054655, valid_loss: 0.2824269123375416\n",
      "EPOCH: 1, train_loss: 0.05600738629132886, valid_loss: 0.021255606086924672\n",
      "EPOCH: 2, train_loss: 0.023035264774402486, valid_loss: 0.019905207213014364\n",
      "EPOCH: 3, train_loss: 0.021997019837174236, valid_loss: 0.06786605017259717\n",
      "EPOCH: 4, train_loss: 0.021628028465599955, valid_loss: 0.020830093417316675\n",
      "EPOCH: 5, train_loss: 0.021179446785510342, valid_loss: 0.02002858999185264\n",
      "EPOCH: 6, train_loss: 0.020835859795348553, valid_loss: 0.01921190950088203\n",
      "EPOCH: 7, train_loss: 0.02045567951436284, valid_loss: 0.017690511420369148\n",
      "EPOCH: 8, train_loss: 0.02034075562901135, valid_loss: 0.01896667154505849\n",
      "EPOCH: 9, train_loss: 0.020207812184397177, valid_loss: 0.017522634472697973\n",
      "EPOCH: 10, train_loss: 0.020137337142530874, valid_loss: 0.017173186410218477\n",
      "EPOCH: 11, train_loss: 0.019948125592892683, valid_loss: 0.01743429689668119\n",
      "EPOCH: 12, train_loss: 0.019801737882102592, valid_loss: 0.017372447764500976\n",
      "EPOCH: 13, train_loss: 0.019683672091628933, valid_loss: 0.017214386025443673\n",
      "EPOCH: 14, train_loss: 0.01969454887830004, valid_loss: 0.01740065007470548\n",
      "EPOCH: 15, train_loss: 0.019619625780872906, valid_loss: 0.017117196461185813\n",
      "EPOCH: 16, train_loss: 0.01938255647598188, valid_loss: 0.01737927715294063\n",
      "EPOCH: 17, train_loss: 0.019378150660025923, valid_loss: 0.017385200830176473\n",
      "EPOCH: 18, train_loss: 0.019034506646987005, valid_loss: 0.01705092447809875\n",
      "EPOCH: 19, train_loss: 0.01908922560890264, valid_loss: 0.016963589703664184\n",
      "EPOCH: 20, train_loss: 0.018936770508372332, valid_loss: 0.016965121729299426\n",
      "EPOCH: 21, train_loss: 0.01860215029195894, valid_loss: 0.01696853036992252\n",
      "EPOCH: 22, train_loss: 0.018129912806274014, valid_loss: 0.017097359988838434\n",
      "EPOCH: 23, train_loss: 0.01783046560196937, valid_loss: 0.01690396899357438\n",
      "EPOCH: 24, train_loss: 0.017531143831489963, valid_loss: 0.016931139631196856\n",
      "EPOCH: 25, train_loss: 0.01689480925921964, valid_loss: 0.016834375797770917\n",
      "EPOCH: 26, train_loss: 0.016527353432265263, valid_loss: 0.01697459165006876\n",
      "EPOCH: 27, train_loss: 0.016133308988300305, valid_loss: 0.017034660442732275\n",
      "EPOCH: 28, train_loss: 0.015829343631674972, valid_loss: 0.016968018375337124\n",
      "EPOCH: 29, train_loss: 0.0160796305141117, valid_loss: 0.01697184215299785\n",
      "FOLD: 10\n",
      "EPOCH: 0, train_loss: 0.6566241093170948, valid_loss: 0.2672871947288513\n",
      "EPOCH: 1, train_loss: 0.05592762418568899, valid_loss: 0.021095350617542863\n",
      "EPOCH: 2, train_loss: 0.02271795401779505, valid_loss: 0.019197640707716346\n",
      "EPOCH: 3, train_loss: 0.02140759953703636, valid_loss: 0.018278155010193586\n",
      "EPOCH: 4, train_loss: 0.020757352742247093, valid_loss: 0.018030765233561397\n",
      "EPOCH: 5, train_loss: 0.020181985524220344, valid_loss: 0.01797861629165709\n",
      "EPOCH: 6, train_loss: 0.02005091918489108, valid_loss: 0.033560966374352574\n",
      "EPOCH: 7, train_loss: 0.02004837930106964, valid_loss: 0.01765150693245232\n",
      "EPOCH: 8, train_loss: 0.019859299947244998, valid_loss: 0.017695605754852295\n",
      "EPOCH: 9, train_loss: 0.019740495472573318, valid_loss: 0.017450619488954544\n",
      "EPOCH: 10, train_loss: 0.01978308865084098, valid_loss: 0.017644204664975405\n",
      "EPOCH: 11, train_loss: 0.019748583770333193, valid_loss: 0.017271638149395585\n",
      "EPOCH: 12, train_loss: 0.019684776090658627, valid_loss: 0.01741197449155152\n",
      "EPOCH: 13, train_loss: 0.019652480999819744, valid_loss: 0.017293641110882163\n",
      "EPOCH: 14, train_loss: 0.019485814568515007, valid_loss: 0.01731519983150065\n",
      "EPOCH: 15, train_loss: 0.019430698062746953, valid_loss: 0.0173088142182678\n",
      "EPOCH: 16, train_loss: 0.01934283109716116, valid_loss: 0.01713735074736178\n",
      "EPOCH: 17, train_loss: 0.019185133684331026, valid_loss: 0.01724783773534\n",
      "EPOCH: 18, train_loss: 0.01896980378585748, valid_loss: 0.01735551841557026\n",
      "EPOCH: 19, train_loss: 0.01877964335756424, valid_loss: 0.017229507910087705\n",
      "EPOCH: 20, train_loss: 0.01859442524325389, valid_loss: 0.01705907774157822\n",
      "EPOCH: 21, train_loss: 0.018309464033406515, valid_loss: 0.01706403261050582\n",
      "EPOCH: 22, train_loss: 0.018003497869731523, valid_loss: 0.01695059542544186\n",
      "EPOCH: 23, train_loss: 0.01755307364062621, valid_loss: 0.017004705732688308\n",
      "EPOCH: 24, train_loss: 0.01703024533792184, valid_loss: 0.017027357360348105\n",
      "EPOCH: 25, train_loss: 0.01654945840485967, valid_loss: 0.017104050610214472\n",
      "EPOCH: 26, train_loss: 0.016003443214755792, valid_loss: 0.01710297609679401\n",
      "EPOCH: 27, train_loss: 0.015546668153733779, valid_loss: 0.01709878840483725\n",
      "EPOCH: 28, train_loss: 0.015225075292759217, valid_loss: 0.017122829565778375\n",
      "EPOCH: 29, train_loss: 0.015115411271556066, valid_loss: 0.01712096598930657\n",
      "SEED: 42\n",
      "FOLD: 0\n",
      "EPOCH: 0, train_loss: 0.6600101911104642, valid_loss: 0.2711256518959999\n",
      "EPOCH: 1, train_loss: 0.056452514173892826, valid_loss: 0.020803833846002817\n",
      "EPOCH: 2, train_loss: 0.02271735890266987, valid_loss: 0.019176536705344915\n",
      "EPOCH: 3, train_loss: 0.021355952924260728, valid_loss: 0.018497822573408484\n",
      "EPOCH: 4, train_loss: 0.020726390015811492, valid_loss: 0.01774899079464376\n",
      "EPOCH: 5, train_loss: 0.020348894314315073, valid_loss: 0.017759658861905336\n",
      "EPOCH: 6, train_loss: 0.02030353549008186, valid_loss: 0.017563754925504327\n",
      "EPOCH: 7, train_loss: 0.019891581259285793, valid_loss: 0.0176352069247514\n",
      "EPOCH: 8, train_loss: 0.01981820775052676, valid_loss: 0.017501822905614972\n",
      "EPOCH: 9, train_loss: 0.01979682360513088, valid_loss: 0.017760038375854492\n",
      "EPOCH: 10, train_loss: 0.019805276479858618, valid_loss: 0.01755761867389083\n",
      "EPOCH: 11, train_loss: 0.019689466756505843, valid_loss: 0.017389722634106874\n",
      "EPOCH: 12, train_loss: 0.01963139922381976, valid_loss: 0.01752139604650438\n",
      "EPOCH: 13, train_loss: 0.019614418371556662, valid_loss: 0.01735933416057378\n",
      "EPOCH: 14, train_loss: 0.01960654408694842, valid_loss: 0.017442402662709355\n",
      "EPOCH: 15, train_loss: 0.019428358628199652, valid_loss: 0.01759945717640221\n",
      "EPOCH: 16, train_loss: 0.019315277966551293, valid_loss: 0.01755774999037385\n",
      "EPOCH: 17, train_loss: 0.019220608979081497, valid_loss: 0.017334802774712443\n",
      "EPOCH: 18, train_loss: 0.0190062617453245, valid_loss: 0.017195488675497472\n",
      "EPOCH: 19, train_loss: 0.018836178028812774, valid_loss: 0.017280543223023415\n",
      "EPOCH: 20, train_loss: 0.01858219895989467, valid_loss: 0.01727453898638487\n",
      "EPOCH: 21, train_loss: 0.018302721449006826, valid_loss: 0.017290196381509304\n",
      "EPOCH: 22, train_loss: 0.018004823667116653, valid_loss: 0.017168960301205516\n",
      "EPOCH: 23, train_loss: 0.01754595873017724, valid_loss: 0.017258892417885363\n",
      "EPOCH: 24, train_loss: 0.017078612787792317, valid_loss: 0.017334128497168422\n",
      "EPOCH: 25, train_loss: 0.016581047063645642, valid_loss: 0.017285596812143922\n",
      "EPOCH: 26, train_loss: 0.0160306806031328, valid_loss: 0.01733455969952047\n",
      "EPOCH: 27, train_loss: 0.015565393301538931, valid_loss: 0.0173829507548362\n",
      "EPOCH: 28, train_loss: 0.015253908645648222, valid_loss: 0.017376302275806665\n",
      "EPOCH: 29, train_loss: 0.01512062317954424, valid_loss: 0.01736936764791608\n",
      "FOLD: 1\n",
      "EPOCH: 0, train_loss: 0.6604498739425952, valid_loss: 0.2623116299510002\n",
      "EPOCH: 1, train_loss: 0.05738735387627131, valid_loss: 0.020845486083999276\n",
      "EPOCH: 2, train_loss: 0.022720155353920583, valid_loss: 0.01889710663817823\n",
      "EPOCH: 3, train_loss: 0.021556582874976672, valid_loss: 0.018307272577658296\n",
      "EPOCH: 4, train_loss: 0.02064023243311124, valid_loss: 0.018146677874028683\n",
      "EPOCH: 5, train_loss: 0.02026132045265956, valid_loss: 0.01803079736419022\n",
      "EPOCH: 6, train_loss: 0.020084065432922963, valid_loss: 0.01790437358431518\n",
      "EPOCH: 7, train_loss: 0.01988686742977454, valid_loss: 0.01756488298997283\n",
      "EPOCH: 8, train_loss: 0.01983529747201082, valid_loss: 0.017705222591757774\n",
      "EPOCH: 9, train_loss: 0.019821238895066273, valid_loss: 0.01769114565104246\n",
      "EPOCH: 10, train_loss: 0.019781263974996712, valid_loss: 0.018066530115902424\n",
      "EPOCH: 11, train_loss: 0.019728241727138177, valid_loss: 0.017530744895339012\n",
      "EPOCH: 12, train_loss: 0.01965108222495287, valid_loss: 0.01763738924637437\n",
      "EPOCH: 13, train_loss: 0.019572704290159237, valid_loss: 0.017502780072391033\n",
      "EPOCH: 14, train_loss: 0.01952537896636969, valid_loss: 0.017589946975931525\n",
      "EPOCH: 15, train_loss: 0.019370025262618676, valid_loss: 0.01751251914538443\n",
      "EPOCH: 16, train_loss: 0.019322064800713308, valid_loss: 0.01742906658910215\n",
      "EPOCH: 17, train_loss: 0.019183863933460835, valid_loss: 0.01743729948066175\n",
      "EPOCH: 18, train_loss: 0.01900499020344936, valid_loss: 0.017252016812562943\n",
      "EPOCH: 19, train_loss: 0.018814748463531334, valid_loss: 0.017287003807723522\n",
      "EPOCH: 20, train_loss: 0.018592999985393804, valid_loss: 0.01726996316574514\n",
      "EPOCH: 21, train_loss: 0.018328582867980003, valid_loss: 0.017208987614139915\n",
      "EPOCH: 22, train_loss: 0.017964111330608528, valid_loss: 0.0171033653896302\n",
      "EPOCH: 23, train_loss: 0.01754837156010744, valid_loss: 0.017198370536789298\n",
      "EPOCH: 24, train_loss: 0.017048697775373094, valid_loss: 0.017226323019713163\n",
      "EPOCH: 25, train_loss: 0.016527488708305053, valid_loss: 0.017279216088354588\n",
      "EPOCH: 26, train_loss: 0.015989617146074008, valid_loss: 0.01721766823902726\n",
      "EPOCH: 27, train_loss: 0.015546607235685373, valid_loss: 0.017259706743061543\n",
      "EPOCH: 28, train_loss: 0.015222170031987704, valid_loss: 0.017294312128797174\n",
      "EPOCH: 29, train_loss: 0.015083346456193771, valid_loss: 0.01730535877868533\n",
      "FOLD: 2\n",
      "EPOCH: 0, train_loss: 0.6609945354553369, valid_loss: 0.29331089928746223\n",
      "EPOCH: 1, train_loss: 0.05729844361448135, valid_loss: 0.02149180555716157\n",
      "EPOCH: 2, train_loss: 0.02306770838988133, valid_loss: 0.019837942207232118\n",
      "EPOCH: 3, train_loss: 0.021513132617259637, valid_loss: 0.018661809153854847\n",
      "EPOCH: 4, train_loss: 0.020880907750091493, valid_loss: 0.018295227084308863\n",
      "EPOCH: 5, train_loss: 0.0201826426319969, valid_loss: 0.018339432310312986\n",
      "EPOCH: 6, train_loss: 0.019922327966644213, valid_loss: 0.018140007508918643\n",
      "EPOCH: 7, train_loss: 0.01980311994273693, valid_loss: 0.01806076872162521\n",
      "EPOCH: 8, train_loss: 0.019743735161729347, valid_loss: 0.018234052695333958\n",
      "EPOCH: 9, train_loss: 0.019703849457586423, valid_loss: 0.01806998113170266\n",
      "EPOCH: 10, train_loss: 0.01963257593795275, valid_loss: 0.018204785184934735\n",
      "EPOCH: 11, train_loss: 0.019580517632839006, valid_loss: 0.01804517488926649\n",
      "EPOCH: 12, train_loss: 0.019553929758377563, valid_loss: 0.01807579956948757\n",
      "EPOCH: 13, train_loss: 0.019552890259103898, valid_loss: 0.017892256379127502\n",
      "EPOCH: 14, train_loss: 0.019418213134392712, valid_loss: 0.018089156597852707\n",
      "EPOCH: 15, train_loss: 0.019306753356105242, valid_loss: 0.01778391213156283\n",
      "EPOCH: 16, train_loss: 0.01915871263601077, valid_loss: 0.017746490892022848\n",
      "EPOCH: 17, train_loss: 0.019034531612235766, valid_loss: 0.017660329584032297\n",
      "EPOCH: 18, train_loss: 0.01885970906378367, valid_loss: 0.01776044280268252\n",
      "EPOCH: 19, train_loss: 0.018721796046846952, valid_loss: 0.017591767013072968\n",
      "EPOCH: 20, train_loss: 0.0184057170811754, valid_loss: 0.017473086016252637\n",
      "EPOCH: 21, train_loss: 0.018169467098628864, valid_loss: 0.01768090296536684\n",
      "EPOCH: 22, train_loss: 0.017776077589354455, valid_loss: 0.017631707713007927\n",
      "EPOCH: 23, train_loss: 0.017322085594806153, valid_loss: 0.017630616202950478\n",
      "EPOCH: 24, train_loss: 0.0167958078523859, valid_loss: 0.01764922053553164\n",
      "EPOCH: 25, train_loss: 0.01626712662908129, valid_loss: 0.01772033143788576\n",
      "EPOCH: 26, train_loss: 0.01570676718480312, valid_loss: 0.01773835509084165\n",
      "EPOCH: 27, train_loss: 0.015225116581393357, valid_loss: 0.017772848019376397\n",
      "EPOCH: 28, train_loss: 0.014899803635974726, valid_loss: 0.017788968747481704\n",
      "EPOCH: 29, train_loss: 0.014728932677266689, valid_loss: 0.017783452989533544\n",
      "FOLD: 3\n",
      "EPOCH: 0, train_loss: 0.6604437740185322, valid_loss: 0.27263326570391655\n",
      "EPOCH: 1, train_loss: 0.05688525206194474, valid_loss: 0.021092554554343224\n",
      "EPOCH: 2, train_loss: 0.02263887085689184, valid_loss: 0.020381073467433453\n",
      "EPOCH: 3, train_loss: 0.021371575788809702, valid_loss: 0.01911902753636241\n",
      "EPOCH: 4, train_loss: 0.02072040309222081, valid_loss: 0.018183444160968065\n",
      "EPOCH: 5, train_loss: 0.020150602150421876, valid_loss: 0.017951874062418938\n",
      "EPOCH: 6, train_loss: 0.020226467209748734, valid_loss: 0.018096171086654067\n",
      "EPOCH: 7, train_loss: 0.019901591926240005, valid_loss: 0.017847904236987233\n",
      "EPOCH: 8, train_loss: 0.01984945462586788, valid_loss: 0.017829936929047108\n",
      "EPOCH: 9, train_loss: 0.019748479223404176, valid_loss: 0.01770609081722796\n",
      "EPOCH: 10, train_loss: 0.019767901501976527, valid_loss: 0.017837258288636804\n",
      "EPOCH: 11, train_loss: 0.019684746145055845, valid_loss: 0.01775585557334125\n",
      "EPOCH: 12, train_loss: 0.01967163149936077, valid_loss: 0.01778275496326387\n",
      "EPOCH: 13, train_loss: 0.019611810334026814, valid_loss: 0.01777467504143715\n",
      "EPOCH: 14, train_loss: 0.019580402148839753, valid_loss: 0.01772967609576881\n",
      "EPOCH: 15, train_loss: 0.019432213133535325, valid_loss: 0.017626397777348757\n",
      "EPOCH: 16, train_loss: 0.019306571748203192, valid_loss: 0.01756454980932176\n",
      "EPOCH: 17, train_loss: 0.019167429648148708, valid_loss: 0.017538849962875247\n",
      "EPOCH: 18, train_loss: 0.01903935798849815, valid_loss: 0.017525107599794865\n",
      "EPOCH: 19, train_loss: 0.018819452932056707, valid_loss: 0.017317546298727393\n",
      "EPOCH: 20, train_loss: 0.018564097272853058, valid_loss: 0.01755743403919041\n",
      "EPOCH: 21, train_loss: 0.018329909071326256, valid_loss: 0.01752685126848519\n",
      "EPOCH: 22, train_loss: 0.017995333657241784, valid_loss: 0.017260118387639523\n",
      "EPOCH: 23, train_loss: 0.01762330386405572, valid_loss: 0.01735059078782797\n",
      "EPOCH: 24, train_loss: 0.01713772057197415, valid_loss: 0.01729259337298572\n",
      "EPOCH: 25, train_loss: 0.016611424788164023, valid_loss: 0.01726792403496802\n",
      "EPOCH: 26, train_loss: 0.016108674570344962, valid_loss: 0.017309059854596853\n",
      "EPOCH: 27, train_loss: 0.015591264953120397, valid_loss: 0.01736216456629336\n",
      "EPOCH: 28, train_loss: 0.01531496137762681, valid_loss: 0.017394555499777198\n",
      "EPOCH: 29, train_loss: 0.015143799500014538, valid_loss: 0.017390994355082512\n",
      "FOLD: 4\n",
      "EPOCH: 0, train_loss: 0.6604684144258499, valid_loss: 0.2627803459763527\n",
      "EPOCH: 1, train_loss: 0.05722119102779871, valid_loss: 0.021106738597154617\n",
      "EPOCH: 2, train_loss: 0.022820808900854528, valid_loss: 0.019661172525957227\n",
      "EPOCH: 3, train_loss: 0.02147323853121354, valid_loss: 0.018240266479551792\n",
      "EPOCH: 4, train_loss: 0.020813762878951352, valid_loss: 0.018089882098138332\n",
      "EPOCH: 5, train_loss: 0.020210712503355283, valid_loss: 0.01818527071736753\n",
      "EPOCH: 6, train_loss: 0.020059792277140494, valid_loss: 0.01770489104092121\n",
      "EPOCH: 7, train_loss: 0.019929561644601516, valid_loss: 0.017678898526355624\n",
      "EPOCH: 8, train_loss: 0.019879487820733815, valid_loss: 0.01756125967949629\n",
      "EPOCH: 9, train_loss: 0.019722149014855042, valid_loss: 0.017753990832716227\n",
      "EPOCH: 10, train_loss: 0.019740284110109012, valid_loss: 0.01734602893702686\n",
      "EPOCH: 11, train_loss: 0.019700181909287587, valid_loss: 0.017448455095291138\n",
      "EPOCH: 12, train_loss: 0.019662028417373315, valid_loss: 0.01743329712189734\n",
      "EPOCH: 13, train_loss: 0.019616671694585912, valid_loss: 0.017339271726086736\n",
      "EPOCH: 14, train_loss: 0.019507696231206257, valid_loss: 0.017501027090474963\n",
      "EPOCH: 15, train_loss: 0.01949887450497884, valid_loss: 0.017574022756889462\n",
      "EPOCH: 16, train_loss: 0.019415271014739305, valid_loss: 0.017172849737107754\n",
      "EPOCH: 17, train_loss: 0.019219814990766537, valid_loss: 0.01710739848203957\n",
      "EPOCH: 18, train_loss: 0.019033202065680273, valid_loss: 0.01715321419760585\n",
      "EPOCH: 19, train_loss: 0.018817381073649112, valid_loss: 0.017563750501722097\n",
      "EPOCH: 20, train_loss: 0.018630431559032355, valid_loss: 0.017125983955338597\n",
      "EPOCH: 21, train_loss: 0.01834475499792741, valid_loss: 0.01694746850989759\n",
      "EPOCH: 22, train_loss: 0.01795579557521985, valid_loss: 0.017053578747436404\n",
      "EPOCH: 23, train_loss: 0.01755207960899824, valid_loss: 0.017067436361685395\n",
      "EPOCH: 24, train_loss: 0.017139429095177315, valid_loss: 0.016995914047583938\n",
      "EPOCH: 25, train_loss: 0.01659767359542923, valid_loss: 0.017030266346409917\n",
      "EPOCH: 26, train_loss: 0.016088429766778763, valid_loss: 0.017054109601303935\n",
      "EPOCH: 27, train_loss: 0.0156153814556698, valid_loss: 0.017103001475334167\n",
      "EPOCH: 28, train_loss: 0.015337016564817766, valid_loss: 0.01710223569534719\n",
      "EPOCH: 29, train_loss: 0.015185336462962322, valid_loss: 0.01711198571138084\n",
      "FOLD: 5\n",
      "EPOCH: 0, train_loss: 0.659598395992548, valid_loss: 0.2779146321117878\n",
      "EPOCH: 1, train_loss: 0.05656071568433291, valid_loss: 0.021451993845403194\n",
      "EPOCH: 2, train_loss: 0.022565768243601687, valid_loss: 0.01940132398158312\n",
      "EPOCH: 3, train_loss: 0.021259596810126916, valid_loss: 0.01900462806224823\n",
      "EPOCH: 4, train_loss: 0.020604048186960894, valid_loss: 0.01880690921097994\n",
      "EPOCH: 5, train_loss: 0.02034179813777789, valid_loss: 0.01866721734404564\n",
      "EPOCH: 6, train_loss: 0.020031427081005696, valid_loss: 0.018405309645459056\n",
      "EPOCH: 7, train_loss: 0.019892097474672854, valid_loss: 0.01836079405620694\n",
      "EPOCH: 8, train_loss: 0.019842729712717045, valid_loss: 0.018214805983006954\n",
      "EPOCH: 9, train_loss: 0.019678475980002146, valid_loss: 0.018416315084323287\n",
      "EPOCH: 10, train_loss: 0.019642023632350642, valid_loss: 0.01841921079903841\n",
      "EPOCH: 11, train_loss: 0.01964732641593004, valid_loss: 0.018465335480868816\n",
      "EPOCH: 12, train_loss: 0.01955056319443079, valid_loss: 0.01829121564514935\n",
      "EPOCH: 13, train_loss: 0.01946221760068184, valid_loss: 0.018468796275556087\n",
      "EPOCH: 14, train_loss: 0.019379948194210347, valid_loss: 0.01825648988597095\n",
      "EPOCH: 15, train_loss: 0.019352704549256045, valid_loss: 0.01849881326779723\n",
      "EPOCH: 16, train_loss: 0.01924350115064627, valid_loss: 0.018250273074954748\n",
      "EPOCH: 17, train_loss: 0.019087744446901176, valid_loss: 0.01808083150535822\n",
      "EPOCH: 18, train_loss: 0.018894684405472033, valid_loss: 0.018466020235791802\n",
      "EPOCH: 19, train_loss: 0.018755238765898425, valid_loss: 0.018213351722806692\n",
      "EPOCH: 20, train_loss: 0.018455462195934393, valid_loss: 0.01820141589269042\n",
      "EPOCH: 21, train_loss: 0.01819419476370781, valid_loss: 0.018080586567521095\n",
      "EPOCH: 22, train_loss: 0.017836674904594056, valid_loss: 0.018288493854925036\n",
      "EPOCH: 23, train_loss: 0.017481849600489322, valid_loss: 0.01808859989978373\n",
      "EPOCH: 24, train_loss: 0.017036439265864782, valid_loss: 0.018183454405516386\n",
      "EPOCH: 25, train_loss: 0.016510385160262767, valid_loss: 0.018041502218693495\n",
      "EPOCH: 26, train_loss: 0.015990733969001435, valid_loss: 0.01809670845977962\n",
      "EPOCH: 27, train_loss: 0.015550375271302003, valid_loss: 0.01811585295945406\n",
      "EPOCH: 28, train_loss: 0.015216136482568124, valid_loss: 0.018076580949127674\n",
      "EPOCH: 29, train_loss: 0.015095967488984266, valid_loss: 0.018081772373989224\n",
      "FOLD: 6\n",
      "EPOCH: 0, train_loss: 0.6601266054770886, valid_loss: 0.2817642204463482\n",
      "EPOCH: 1, train_loss: 0.056812883354723454, valid_loss: 0.020795550663024187\n",
      "EPOCH: 2, train_loss: 0.022886476336190335, valid_loss: 0.018952077254652977\n",
      "EPOCH: 3, train_loss: 0.021439172494678926, valid_loss: 0.017949508503079414\n",
      "EPOCH: 4, train_loss: 0.020669222069092285, valid_loss: 0.018237483454868197\n",
      "EPOCH: 5, train_loss: 0.020226457371161535, valid_loss: 0.018100488232448697\n",
      "EPOCH: 6, train_loss: 0.02000792799756313, valid_loss: 0.017949909204617143\n",
      "EPOCH: 7, train_loss: 0.020001195538311433, valid_loss: 0.01778397522866726\n",
      "EPOCH: 8, train_loss: 0.019934375268908646, valid_loss: 0.01752829272300005\n",
      "EPOCH: 9, train_loss: 0.01980258237857085, valid_loss: 0.018097695661708713\n",
      "EPOCH: 10, train_loss: 0.01976072372725377, valid_loss: 0.01739168493077159\n",
      "EPOCH: 11, train_loss: 0.019744512505638294, valid_loss: 0.017576699145138264\n",
      "EPOCH: 12, train_loss: 0.019637496115114443, valid_loss: 0.017554381396621466\n",
      "EPOCH: 13, train_loss: 0.01958122080526291, valid_loss: 0.017381848534569144\n",
      "EPOCH: 14, train_loss: 0.019509895274845455, valid_loss: 0.017506067641079426\n",
      "EPOCH: 15, train_loss: 0.019414506995907195, valid_loss: 0.017422499135136604\n",
      "EPOCH: 16, train_loss: 0.019363878939587336, valid_loss: 0.017379969591274858\n",
      "EPOCH: 17, train_loss: 0.019224301888010442, valid_loss: 0.0173436114564538\n",
      "EPOCH: 18, train_loss: 0.019039014808069438, valid_loss: 0.017306025372818112\n",
      "EPOCH: 19, train_loss: 0.018774074430649098, valid_loss: 0.017222396796569228\n",
      "EPOCH: 20, train_loss: 0.01857798360288143, valid_loss: 0.017178087728098035\n",
      "EPOCH: 21, train_loss: 0.018328976196547348, valid_loss: 0.01708407187834382\n",
      "EPOCH: 22, train_loss: 0.01796714698848052, valid_loss: 0.01708180853165686\n",
      "EPOCH: 23, train_loss: 0.017555498064328462, valid_loss: 0.01707228017039597\n",
      "EPOCH: 24, train_loss: 0.01713161489281517, valid_loss: 0.01717596361413598\n",
      "EPOCH: 25, train_loss: 0.01660186784246411, valid_loss: 0.017112082103267312\n",
      "EPOCH: 26, train_loss: 0.01611380237274063, valid_loss: 0.017133348854258657\n",
      "EPOCH: 27, train_loss: 0.015673091682868127, valid_loss: 0.01715506985783577\n",
      "EPOCH: 28, train_loss: 0.015366095536125775, valid_loss: 0.01717967796139419\n",
      "EPOCH: 29, train_loss: 0.015228438334396252, valid_loss: 0.017168335150927305\n",
      "FOLD: 7\n",
      "EPOCH: 0, train_loss: 0.6578200957443141, valid_loss: 0.2768045589327812\n",
      "EPOCH: 1, train_loss: 0.05612785923235779, valid_loss: 0.02141588367521763\n",
      "EPOCH: 2, train_loss: 0.024636469215531892, valid_loss: 0.019738588482141495\n",
      "EPOCH: 3, train_loss: 0.02211268500813955, valid_loss: 0.019866444868966937\n",
      "EPOCH: 4, train_loss: 0.021369436189909524, valid_loss: 0.018552507739514112\n",
      "EPOCH: 5, train_loss: 0.020914338175443154, valid_loss: 0.018589868675917387\n",
      "EPOCH: 6, train_loss: 0.020738652423967288, valid_loss: 0.01805221661925316\n",
      "EPOCH: 7, train_loss: 0.02054715281517445, valid_loss: 0.017941259313374758\n",
      "EPOCH: 8, train_loss: 0.02010394929896427, valid_loss: 0.018243973376229405\n",
      "EPOCH: 9, train_loss: 0.020078628453650053, valid_loss: 0.018370943143963814\n",
      "EPOCH: 10, train_loss: 0.019958076055479956, valid_loss: 0.01780153368599713\n",
      "EPOCH: 11, train_loss: 0.019852216131513632, valid_loss: 0.017693929374217987\n",
      "EPOCH: 12, train_loss: 0.01972051658019235, valid_loss: 0.018115342827513814\n",
      "EPOCH: 13, train_loss: 0.019734365111099012, valid_loss: 0.017787829972803593\n",
      "EPOCH: 14, train_loss: 0.019636298187925845, valid_loss: 0.017660992918536067\n",
      "EPOCH: 15, train_loss: 0.019515280317090735, valid_loss: 0.017665346385911107\n",
      "EPOCH: 16, train_loss: 0.01950726080450076, valid_loss: 0.017547850031405687\n",
      "EPOCH: 17, train_loss: 0.019311250977312462, valid_loss: 0.01758538349531591\n",
      "EPOCH: 18, train_loss: 0.01920513412620448, valid_loss: 0.017583262408152223\n",
      "EPOCH: 19, train_loss: 0.019172321792833413, valid_loss: 0.017594815464690328\n",
      "EPOCH: 20, train_loss: 0.018893588687988776, valid_loss: 0.017312447307631373\n",
      "EPOCH: 21, train_loss: 0.01862951273782344, valid_loss: 0.01749171386472881\n",
      "EPOCH: 22, train_loss: 0.018172364446181286, valid_loss: 0.017581788124516606\n",
      "EPOCH: 23, train_loss: 0.01791179998294462, valid_loss: 0.017413039226084948\n",
      "EPOCH: 24, train_loss: 0.01758195957333981, valid_loss: 0.01739341695792973\n",
      "EPOCH: 25, train_loss: 0.017039490710425226, valid_loss: 0.017524868715554476\n",
      "EPOCH: 26, train_loss: 0.01657181129425387, valid_loss: 0.017471024068072438\n",
      "EPOCH: 27, train_loss: 0.016084002389843706, valid_loss: 0.017560628708451986\n",
      "EPOCH: 28, train_loss: 0.01581053419298009, valid_loss: 0.017547516617923975\n",
      "EPOCH: 29, train_loss: 0.015628238798036605, valid_loss: 0.017498935339972377\n",
      "FOLD: 8\n",
      "EPOCH: 0, train_loss: 0.6580116914797433, valid_loss: 0.2550786193460226\n",
      "EPOCH: 1, train_loss: 0.055200155682956116, valid_loss: 0.021251686150208116\n",
      "EPOCH: 2, train_loss: 0.023125949846226956, valid_loss: 0.019246181938797235\n",
      "EPOCH: 3, train_loss: 0.021535934503131276, valid_loss: 0.017708547180518508\n",
      "EPOCH: 4, train_loss: 0.02084928996200803, valid_loss: 0.02476245630532503\n",
      "EPOCH: 5, train_loss: 0.020596675692668445, valid_loss: 0.018342522904276848\n",
      "EPOCH: 6, train_loss: 0.02020493251141868, valid_loss: 0.017101752571761608\n",
      "EPOCH: 7, train_loss: 0.020054247513224807, valid_loss: 0.01764152874238789\n",
      "EPOCH: 8, train_loss: 0.01996180375071266, valid_loss: 0.017154606175608933\n",
      "EPOCH: 9, train_loss: 0.01984812484323224, valid_loss: 0.01732454390730709\n",
      "EPOCH: 10, train_loss: 0.019791832806754717, valid_loss: 0.01722559821791947\n",
      "EPOCH: 11, train_loss: 0.019792825266530242, valid_loss: 0.017298937658779323\n",
      "EPOCH: 12, train_loss: 0.01974119316739372, valid_loss: 0.01714829122647643\n",
      "EPOCH: 13, train_loss: 0.019849308424546748, valid_loss: 0.0172743919538334\n",
      "EPOCH: 14, train_loss: 0.019711078333232223, valid_loss: 0.0169792624656111\n",
      "EPOCH: 15, train_loss: 0.01953234386783612, valid_loss: 0.017225246294401586\n",
      "EPOCH: 16, train_loss: 0.0195087401927272, valid_loss: 0.016900961636565626\n",
      "EPOCH: 17, train_loss: 0.019319648441823222, valid_loss: 0.016823562560603023\n",
      "EPOCH: 18, train_loss: 0.019279409860131106, valid_loss: 0.01700846932362765\n",
      "EPOCH: 19, train_loss: 0.019257656640455693, valid_loss: 0.01728910021483898\n",
      "EPOCH: 20, train_loss: 0.018784101015027567, valid_loss: 0.016916922526434064\n",
      "EPOCH: 21, train_loss: 0.018528958405309087, valid_loss: 0.01679958321619779\n",
      "EPOCH: 22, train_loss: 0.018180066837540157, valid_loss: 0.016701677115634084\n",
      "EPOCH: 23, train_loss: 0.017912033450188516, valid_loss: 0.016698904684744775\n",
      "EPOCH: 24, train_loss: 0.017486362446901164, valid_loss: 0.016825577127747238\n",
      "EPOCH: 25, train_loss: 0.01704804974171934, valid_loss: 0.016864558565430343\n",
      "EPOCH: 26, train_loss: 0.016557583644325975, valid_loss: 0.016848822706378996\n",
      "EPOCH: 27, train_loss: 0.01613958348531889, valid_loss: 0.01683848083484918\n",
      "EPOCH: 28, train_loss: 0.015904690056473395, valid_loss: 0.01684747461695224\n",
      "EPOCH: 29, train_loss: 0.015704877721735195, valid_loss: 0.016859698691405356\n",
      "FOLD: 9\n",
      "EPOCH: 0, train_loss: 0.6584262255626389, valid_loss: 0.2608148492872715\n",
      "EPOCH: 1, train_loss: 0.057274427429973324, valid_loss: 0.022487453650683165\n",
      "EPOCH: 2, train_loss: 0.023492998950466325, valid_loss: 0.020051785511896014\n",
      "EPOCH: 3, train_loss: 0.02211230377890641, valid_loss: 0.02696378226391971\n",
      "EPOCH: 4, train_loss: 0.02196003133548966, valid_loss: 0.022028433857485652\n",
      "EPOCH: 5, train_loss: 0.021266704755304736, valid_loss: 0.018546083942055702\n",
      "EPOCH: 6, train_loss: 0.020561511003518405, valid_loss: 0.018501223996281624\n",
      "EPOCH: 7, train_loss: 0.02046282671957831, valid_loss: 0.017959680408239365\n",
      "EPOCH: 8, train_loss: 0.020121578669434863, valid_loss: 0.018280248157680035\n",
      "EPOCH: 9, train_loss: 0.02021861128226111, valid_loss: 0.01767857326194644\n",
      "EPOCH: 10, train_loss: 0.019730688208313304, valid_loss: 0.01742822304368019\n",
      "EPOCH: 11, train_loss: 0.019470420218061044, valid_loss: 0.017844246700406075\n",
      "EPOCH: 12, train_loss: 0.019620714732740498, valid_loss: 0.017713913694024086\n",
      "EPOCH: 13, train_loss: 0.01956108443533318, valid_loss: 0.017415935406461358\n",
      "EPOCH: 14, train_loss: 0.019672945330414592, valid_loss: 0.017484583891928196\n",
      "EPOCH: 15, train_loss: 0.019556410728564746, valid_loss: 0.017337091267108917\n",
      "EPOCH: 16, train_loss: 0.019514659726167026, valid_loss: 0.01748540927655995\n",
      "EPOCH: 17, train_loss: 0.0192316848360285, valid_loss: 0.01726908958517015\n",
      "EPOCH: 18, train_loss: 0.019192325446424605, valid_loss: 0.017237442079931498\n",
      "EPOCH: 19, train_loss: 0.01881101556546703, valid_loss: 0.01697454508394003\n",
      "EPOCH: 20, train_loss: 0.0184592645426717, valid_loss: 0.01699177920818329\n",
      "EPOCH: 21, train_loss: 0.018183464703114726, valid_loss: 0.016929029719904065\n",
      "EPOCH: 22, train_loss: 0.017735043210507947, valid_loss: 0.017094930401071906\n",
      "EPOCH: 23, train_loss: 0.01732631977883321, valid_loss: 0.0170142954448238\n",
      "EPOCH: 24, train_loss: 0.016896364019735703, valid_loss: 0.017115345457568765\n",
      "EPOCH: 25, train_loss: 0.016277917307106, valid_loss: 0.0171254922170192\n",
      "EPOCH: 26, train_loss: 0.015811979075115692, valid_loss: 0.017197913257405162\n",
      "EPOCH: 27, train_loss: 0.01521405038907181, valid_loss: 0.01718912599608302\n",
      "EPOCH: 28, train_loss: 0.015130233667979512, valid_loss: 0.017152427462860942\n",
      "EPOCH: 29, train_loss: 0.014967209624150131, valid_loss: 0.017204034607857466\n",
      "FOLD: 10\n",
      "EPOCH: 0, train_loss: 0.6589497400399966, valid_loss: 0.2519761584699154\n",
      "EPOCH: 1, train_loss: 0.056478424642521605, valid_loss: 0.020784561755135655\n",
      "EPOCH: 2, train_loss: 0.022683496061616983, valid_loss: 0.01931607536971569\n",
      "EPOCH: 3, train_loss: 0.021499835695020664, valid_loss: 0.01839547185227275\n",
      "EPOCH: 4, train_loss: 0.020794202501957234, valid_loss: 0.017737759510055184\n",
      "EPOCH: 5, train_loss: 0.020196908249113806, valid_loss: 0.0176612613722682\n",
      "EPOCH: 6, train_loss: 0.020119041132812317, valid_loss: 0.0175430946983397\n",
      "EPOCH: 7, train_loss: 0.019963878684510022, valid_loss: 0.01755532599054277\n",
      "EPOCH: 8, train_loss: 0.019874882358962145, valid_loss: 0.01761942240409553\n",
      "EPOCH: 9, train_loss: 0.019837271350507554, valid_loss: 0.01742630056105554\n",
      "EPOCH: 10, train_loss: 0.019765340221615937, valid_loss: 0.01739225210621953\n",
      "EPOCH: 11, train_loss: 0.019714513244346168, valid_loss: 0.01742034568451345\n",
      "EPOCH: 12, train_loss: 0.019739536186441396, valid_loss: 0.017572947312146425\n",
      "EPOCH: 13, train_loss: 0.01963328517591342, valid_loss: 0.017541922396048903\n",
      "EPOCH: 14, train_loss: 0.019539224365964915, valid_loss: 0.017462136689573526\n",
      "EPOCH: 15, train_loss: 0.01952450892004447, valid_loss: 0.017311529256403446\n",
      "EPOCH: 16, train_loss: 0.019328563521878842, valid_loss: 0.017357055563479662\n",
      "EPOCH: 17, train_loss: 0.019244377859509908, valid_loss: 0.017278405837714672\n",
      "EPOCH: 18, train_loss: 0.019021447509145126, valid_loss: 0.01702144183218479\n",
      "EPOCH: 19, train_loss: 0.018803115193851482, valid_loss: 0.01719673932529986\n",
      "EPOCH: 20, train_loss: 0.018613238842823565, valid_loss: 0.017045827582478523\n",
      "EPOCH: 21, train_loss: 0.018389492940444212, valid_loss: 0.017045193584635854\n",
      "EPOCH: 22, train_loss: 0.018071225438362513, valid_loss: 0.017039022408425808\n",
      "EPOCH: 23, train_loss: 0.017556362260037508, valid_loss: 0.016859935596585274\n",
      "EPOCH: 24, train_loss: 0.017146598583517168, valid_loss: 0.016897642519325018\n",
      "EPOCH: 25, train_loss: 0.016671136224594634, valid_loss: 0.016908141085878015\n",
      "EPOCH: 26, train_loss: 0.016161540523171425, valid_loss: 0.01704176072962582\n",
      "EPOCH: 27, train_loss: 0.015685470201648198, valid_loss: 0.01705806120298803\n",
      "EPOCH: 28, train_loss: 0.015398811429547958, valid_loss: 0.017046257155016065\n",
      "EPOCH: 29, train_loss: 0.01528829059157616, valid_loss: 0.017049262765794992\n",
      "SEED: 256\n",
      "FOLD: 0\n",
      "EPOCH: 0, train_loss: 0.6608637074629465, valid_loss: 0.27381639182567596\n",
      "EPOCH: 1, train_loss: 0.05751157743044388, valid_loss: 0.021041463827714324\n",
      "EPOCH: 2, train_loss: 0.022704907024327, valid_loss: 0.019247780553996563\n",
      "EPOCH: 3, train_loss: 0.021507067916293938, valid_loss: 0.018296833848580718\n",
      "EPOCH: 4, train_loss: 0.020723919766262557, valid_loss: 0.017846921226009727\n",
      "EPOCH: 5, train_loss: 0.020287530592236765, valid_loss: 0.0178050072863698\n",
      "EPOCH: 6, train_loss: 0.020046092307147306, valid_loss: 0.01777808926999569\n",
      "EPOCH: 7, train_loss: 0.019875591716323145, valid_loss: 0.01784342620521784\n",
      "EPOCH: 8, train_loss: 0.01983961957291915, valid_loss: 0.01792563288472593\n",
      "EPOCH: 9, train_loss: 0.019796129292211473, valid_loss: 0.017574247904121876\n",
      "EPOCH: 10, train_loss: 0.019803400246951826, valid_loss: 0.01772961555980146\n",
      "EPOCH: 11, train_loss: 0.019740913731929582, valid_loss: 0.017938577802851796\n",
      "EPOCH: 12, train_loss: 0.019692159592150114, valid_loss: 0.017631423426792026\n",
      "EPOCH: 13, train_loss: 0.019613530940543383, valid_loss: 0.017502160975709558\n",
      "EPOCH: 14, train_loss: 0.019538083161490086, valid_loss: 0.017415297916159034\n",
      "EPOCH: 15, train_loss: 0.019491148634980887, valid_loss: 0.01747972215525806\n",
      "EPOCH: 16, train_loss: 0.019320900169893716, valid_loss: 0.017437172355130315\n",
      "EPOCH: 17, train_loss: 0.019193648026348688, valid_loss: 0.017451355466619134\n",
      "EPOCH: 18, train_loss: 0.019062571537991364, valid_loss: 0.017345236614346504\n",
      "EPOCH: 19, train_loss: 0.01878494055320819, valid_loss: 0.01739815645851195\n",
      "EPOCH: 20, train_loss: 0.018629186380750094, valid_loss: 0.017274419078603387\n",
      "EPOCH: 21, train_loss: 0.018243040865621507, valid_loss: 0.017295554280281067\n",
      "EPOCH: 22, train_loss: 0.017948322595121004, valid_loss: 0.017167666577734053\n",
      "EPOCH: 23, train_loss: 0.017598124698568612, valid_loss: 0.017057840945199132\n",
      "EPOCH: 24, train_loss: 0.017103761553955384, valid_loss: 0.017136331414803863\n",
      "EPOCH: 25, train_loss: 0.01661785202435194, valid_loss: 0.017167030135169625\n",
      "EPOCH: 26, train_loss: 0.016070470572091065, valid_loss: 0.017211762722581625\n",
      "EPOCH: 27, train_loss: 0.015623871905681415, valid_loss: 0.017195281921885908\n",
      "EPOCH: 28, train_loss: 0.015351828486204911, valid_loss: 0.017199433408677578\n",
      "EPOCH: 29, train_loss: 0.015241842287091108, valid_loss: 0.01721203059423715\n",
      "FOLD: 1\n",
      "EPOCH: 0, train_loss: 0.6592721828283408, valid_loss: 0.2649821378290653\n",
      "EPOCH: 1, train_loss: 0.05671953187825588, valid_loss: 0.02076512831263244\n",
      "EPOCH: 2, train_loss: 0.022726168617224082, valid_loss: 0.019347930094227195\n",
      "EPOCH: 3, train_loss: 0.021438586310698435, valid_loss: 0.01830725558102131\n",
      "EPOCH: 4, train_loss: 0.0206949084233015, valid_loss: 0.02170223300345242\n",
      "EPOCH: 5, train_loss: 0.020358297949991166, valid_loss: 0.01845770888030529\n",
      "EPOCH: 6, train_loss: 0.02003643697557541, valid_loss: 0.017955625662580132\n",
      "EPOCH: 7, train_loss: 0.01993275784815733, valid_loss: 0.017718109535053372\n",
      "EPOCH: 8, train_loss: 0.019905485451603547, valid_loss: 0.01763534266501665\n",
      "EPOCH: 9, train_loss: 0.01977985540930277, valid_loss: 0.017734161112457514\n",
      "EPOCH: 10, train_loss: 0.019760193947989207, valid_loss: 0.01783356093801558\n",
      "EPOCH: 11, train_loss: 0.019765007715576734, valid_loss: 0.01742411474697292\n",
      "EPOCH: 12, train_loss: 0.01963594539138751, valid_loss: 0.01761776371859014\n",
      "EPOCH: 13, train_loss: 0.019579157448158815, valid_loss: 0.01762791210785508\n",
      "EPOCH: 14, train_loss: 0.01949301340545599, valid_loss: 0.017775184009224176\n",
      "EPOCH: 15, train_loss: 0.019435001632724054, valid_loss: 0.017237595515325665\n",
      "EPOCH: 16, train_loss: 0.019315277465069905, valid_loss: 0.017250681295990944\n",
      "EPOCH: 17, train_loss: 0.01921592394892986, valid_loss: 0.01726416125893593\n",
      "EPOCH: 18, train_loss: 0.01901114065773212, valid_loss: 0.017603362910449505\n",
      "EPOCH: 19, train_loss: 0.018822444578967035, valid_loss: 0.017633874667808414\n",
      "EPOCH: 20, train_loss: 0.018576318947359536, valid_loss: 0.01719682407565415\n",
      "EPOCH: 21, train_loss: 0.01834104148050149, valid_loss: 0.01709994557313621\n",
      "EPOCH: 22, train_loss: 0.01796771812801942, valid_loss: 0.01723776524886489\n",
      "EPOCH: 23, train_loss: 0.017559092766485918, valid_loss: 0.017256234772503376\n",
      "EPOCH: 24, train_loss: 0.017138799198735982, valid_loss: 0.017316524870693684\n",
      "EPOCH: 25, train_loss: 0.016620229344623975, valid_loss: 0.017308076843619347\n",
      "EPOCH: 26, train_loss: 0.0161084555184994, valid_loss: 0.01746897236444056\n",
      "EPOCH: 27, train_loss: 0.015645970447132222, valid_loss: 0.017386117484420538\n",
      "EPOCH: 28, train_loss: 0.015345621209305067, valid_loss: 0.01740025612525642\n",
      "EPOCH: 29, train_loss: 0.015198958930201255, valid_loss: 0.017413907451555133\n",
      "FOLD: 2\n",
      "EPOCH: 0, train_loss: 0.6586331713658112, valid_loss: 0.2637261562049389\n",
      "EPOCH: 1, train_loss: 0.056089004764381126, valid_loss: 0.02077841223217547\n",
      "EPOCH: 2, train_loss: 0.022730120505468968, valid_loss: 0.019129176856949925\n",
      "EPOCH: 3, train_loss: 0.021566684214541547, valid_loss: 0.018491816939786077\n",
      "EPOCH: 4, train_loss: 0.020568992894811507, valid_loss: 0.018417821265757084\n",
      "EPOCH: 5, train_loss: 0.020151649601757526, valid_loss: 0.018172968877479434\n",
      "EPOCH: 6, train_loss: 0.020018391024607878, valid_loss: 0.01832520659081638\n",
      "EPOCH: 7, train_loss: 0.019906137831127033, valid_loss: 0.017798798391595483\n",
      "EPOCH: 8, train_loss: 0.019718194499802895, valid_loss: 0.01786880916915834\n",
      "EPOCH: 9, train_loss: 0.019710033367841672, valid_loss: 0.01813888782635331\n",
      "EPOCH: 10, train_loss: 0.019642901845658436, valid_loss: 0.01819218718446791\n",
      "EPOCH: 11, train_loss: 0.019666250365284774, valid_loss: 0.0177358475048095\n",
      "EPOCH: 12, train_loss: 0.019563724358494464, valid_loss: 0.017856776947155595\n",
      "EPOCH: 13, train_loss: 0.01947909751190589, valid_loss: 0.017947510350495577\n",
      "EPOCH: 14, train_loss: 0.019399861232019387, valid_loss: 0.017894365591928363\n",
      "EPOCH: 15, train_loss: 0.019354258449031755, valid_loss: 0.017929410096257925\n",
      "EPOCH: 16, train_loss: 0.019250910203808393, valid_loss: 0.01804918865673244\n",
      "EPOCH: 17, train_loss: 0.019116492392734077, valid_loss: 0.017511619487777352\n",
      "EPOCH: 18, train_loss: 0.018885102337942675, valid_loss: 0.017658434808254242\n",
      "EPOCH: 19, train_loss: 0.018702408346610192, valid_loss: 0.017597764264792204\n",
      "EPOCH: 20, train_loss: 0.01844858406828, valid_loss: 0.01782225980423391\n",
      "EPOCH: 21, train_loss: 0.018122578899447735, valid_loss: 0.017440742114558816\n",
      "EPOCH: 22, train_loss: 0.01772010080420818, valid_loss: 0.017623308347538114\n",
      "EPOCH: 23, train_loss: 0.017285440594722062, valid_loss: 0.017600329592823982\n",
      "EPOCH: 24, train_loss: 0.016766720976776037, valid_loss: 0.01768457959406078\n",
      "EPOCH: 25, train_loss: 0.01613763488160494, valid_loss: 0.01767811388708651\n",
      "EPOCH: 26, train_loss: 0.01555849509074902, valid_loss: 0.017708262894302607\n",
      "EPOCH: 27, train_loss: 0.015038516360502213, valid_loss: 0.0177992379758507\n",
      "EPOCH: 28, train_loss: 0.014687254798049346, valid_loss: 0.017806760733947158\n",
      "EPOCH: 29, train_loss: 0.014592408262288723, valid_loss: 0.017820570850744843\n",
      "FOLD: 3\n",
      "EPOCH: 0, train_loss: 0.6583469815743275, valid_loss: 0.2593972906470299\n",
      "EPOCH: 1, train_loss: 0.05604822255479984, valid_loss: 0.021847807802259922\n",
      "EPOCH: 2, train_loss: 0.022632569385071594, valid_loss: 0.019854878773912787\n",
      "EPOCH: 3, train_loss: 0.021418537037112773, valid_loss: 0.018444191431626678\n",
      "EPOCH: 4, train_loss: 0.020715941006365497, valid_loss: 0.018263889476656914\n",
      "EPOCH: 5, train_loss: 0.020186414177983236, valid_loss: 0.017974817659705877\n",
      "EPOCH: 6, train_loss: 0.02003410298568316, valid_loss: 0.017819076776504517\n",
      "EPOCH: 7, train_loss: 0.01995007560039178, valid_loss: 0.017861142521724105\n",
      "EPOCH: 8, train_loss: 0.019870946159920633, valid_loss: 0.018197690602391958\n",
      "EPOCH: 9, train_loss: 0.019821483785143264, valid_loss: 0.01769836200401187\n",
      "EPOCH: 10, train_loss: 0.01976989785161538, valid_loss: 0.017793470062315464\n",
      "EPOCH: 11, train_loss: 0.01972940621467737, valid_loss: 0.01777933118864894\n",
      "EPOCH: 12, train_loss: 0.019647722753385704, valid_loss: 0.017749690683558583\n",
      "EPOCH: 13, train_loss: 0.019602442757250406, valid_loss: 0.01781301572918892\n",
      "EPOCH: 14, train_loss: 0.019579364058489982, valid_loss: 0.017718139803037047\n",
      "EPOCH: 15, train_loss: 0.019462059347484358, valid_loss: 0.017714441288262606\n",
      "EPOCH: 16, train_loss: 0.01934757021566232, valid_loss: 0.017505807802081108\n",
      "EPOCH: 17, train_loss: 0.019171567394947395, valid_loss: 0.017522776033729315\n",
      "EPOCH: 18, train_loss: 0.019042475746037103, valid_loss: 0.017586485017091036\n",
      "EPOCH: 19, train_loss: 0.018845693256037358, valid_loss: 0.017501611728221178\n",
      "EPOCH: 20, train_loss: 0.018602266119649775, valid_loss: 0.017346662003546953\n",
      "EPOCH: 21, train_loss: 0.018353654764210567, valid_loss: 0.01717446348629892\n",
      "EPOCH: 22, train_loss: 0.018034950018120117, valid_loss: 0.017265469068661332\n",
      "EPOCH: 23, train_loss: 0.01767001995960107, valid_loss: 0.017153117572888732\n",
      "EPOCH: 24, train_loss: 0.017187993185451396, valid_loss: 0.017211588798090816\n",
      "EPOCH: 25, train_loss: 0.0166827702584366, valid_loss: 0.017268587602302432\n",
      "EPOCH: 26, train_loss: 0.01616172357581747, valid_loss: 0.017256529768928885\n",
      "EPOCH: 27, train_loss: 0.01571449749649335, valid_loss: 0.017293892102316022\n",
      "EPOCH: 28, train_loss: 0.015436400337001452, valid_loss: 0.017308283131569624\n",
      "EPOCH: 29, train_loss: 0.015297525228025058, valid_loss: 0.01730797882191837\n",
      "FOLD: 4\n",
      "EPOCH: 0, train_loss: 0.6585352420806885, valid_loss: 0.25877002999186516\n",
      "EPOCH: 1, train_loss: 0.0561066713088598, valid_loss: 0.020967046730220318\n",
      "EPOCH: 2, train_loss: 0.022882596876185674, valid_loss: 0.019182985881343484\n",
      "EPOCH: 3, train_loss: 0.021388471556397583, valid_loss: 0.018496899167075753\n",
      "EPOCH: 4, train_loss: 0.020681187462730285, valid_loss: 0.0182201461866498\n",
      "EPOCH: 5, train_loss: 0.020285841985008657, valid_loss: 0.017912810435518622\n",
      "EPOCH: 6, train_loss: 0.01998318476268114, valid_loss: 0.017788982950150967\n",
      "EPOCH: 7, train_loss: 0.019851877067524653, valid_loss: 0.017543702851980925\n",
      "EPOCH: 8, train_loss: 0.019806244959815953, valid_loss: 0.017541017616167665\n",
      "EPOCH: 9, train_loss: 0.01973318564108549, valid_loss: 0.017775611486285925\n",
      "EPOCH: 10, train_loss: 0.01970555406445876, valid_loss: 0.01756246923469007\n",
      "EPOCH: 11, train_loss: 0.019636910146054547, valid_loss: 0.01753288321197033\n",
      "EPOCH: 12, train_loss: 0.019656746361691218, valid_loss: 0.017440416617318988\n",
      "EPOCH: 13, train_loss: 0.01955436432781892, valid_loss: 0.01744483457878232\n",
      "EPOCH: 14, train_loss: 0.0194783818263274, valid_loss: 0.01728895423002541\n",
      "EPOCH: 15, train_loss: 0.01943889117011657, valid_loss: 0.017434775829315186\n",
      "EPOCH: 16, train_loss: 0.019323708919378426, valid_loss: 0.017031602561473846\n",
      "EPOCH: 17, train_loss: 0.019230514358824644, valid_loss: 0.01731934887357056\n",
      "EPOCH: 18, train_loss: 0.01910211590047066, valid_loss: 0.017130097141489387\n",
      "EPOCH: 19, train_loss: 0.018840478661541756, valid_loss: 0.017166614765301347\n",
      "EPOCH: 20, train_loss: 0.01859700720375165, valid_loss: 0.017203768249601126\n",
      "EPOCH: 21, train_loss: 0.018356143664091062, valid_loss: 0.01721219252794981\n",
      "EPOCH: 22, train_loss: 0.017974160325068694, valid_loss: 0.01704247808083892\n",
      "EPOCH: 23, train_loss: 0.01756103250842828, valid_loss: 0.016992528922855854\n",
      "EPOCH: 24, train_loss: 0.017100582806727826, valid_loss: 0.017108850413933396\n",
      "EPOCH: 25, train_loss: 0.01659437996120407, valid_loss: 0.017132819863036275\n",
      "EPOCH: 26, train_loss: 0.01610551503463051, valid_loss: 0.01709162862971425\n",
      "EPOCH: 27, train_loss: 0.015606529485338774, valid_loss: 0.01705595338717103\n",
      "EPOCH: 28, train_loss: 0.015283526446765814, valid_loss: 0.01708837179467082\n",
      "EPOCH: 29, train_loss: 0.015158520999531716, valid_loss: 0.01708075520582497\n",
      "FOLD: 5\n",
      "EPOCH: 0, train_loss: 0.6595253065610543, valid_loss: 0.2831358499825001\n",
      "EPOCH: 1, train_loss: 0.05703001094456667, valid_loss: 0.021292695542797446\n",
      "EPOCH: 2, train_loss: 0.022609560439984005, valid_loss: 0.01972533017396927\n",
      "EPOCH: 3, train_loss: 0.021725109706704434, valid_loss: 0.0190416700206697\n",
      "EPOCH: 4, train_loss: 0.020635493266849946, valid_loss: 0.018688572803512216\n",
      "EPOCH: 5, train_loss: 0.020227679648460485, valid_loss: 0.018608815502375364\n",
      "EPOCH: 6, train_loss: 0.019980752410796974, valid_loss: 0.018616986693814397\n",
      "EPOCH: 7, train_loss: 0.01992166395752858, valid_loss: 0.01843230938538909\n",
      "EPOCH: 8, train_loss: 0.019789924080937337, valid_loss: 0.018632696475833654\n",
      "EPOCH: 9, train_loss: 0.01969064664668762, valid_loss: 0.018391958437860012\n",
      "EPOCH: 10, train_loss: 0.019690399965605676, valid_loss: 0.01884977170266211\n",
      "EPOCH: 11, train_loss: 0.01963128885015463, valid_loss: 0.01849870872683823\n",
      "EPOCH: 12, train_loss: 0.019598235686620075, valid_loss: 0.018379576271399856\n",
      "EPOCH: 13, train_loss: 0.019592225241164368, valid_loss: 0.018285546684637666\n",
      "EPOCH: 14, train_loss: 0.019428914388976037, valid_loss: 0.017929797526448965\n",
      "EPOCH: 15, train_loss: 0.019321715912948817, valid_loss: 0.01819757279008627\n",
      "EPOCH: 16, train_loss: 0.0191990236680095, valid_loss: 0.01843521324917674\n",
      "EPOCH: 17, train_loss: 0.019084366468282845, valid_loss: 0.018512678565457463\n",
      "EPOCH: 18, train_loss: 0.018949761031529844, valid_loss: 0.01834592199884355\n",
      "EPOCH: 19, train_loss: 0.018717709857110795, valid_loss: 0.018197938334196806\n",
      "EPOCH: 20, train_loss: 0.018435945997062404, valid_loss: 0.01821827352978289\n",
      "EPOCH: 21, train_loss: 0.01816575926465866, valid_loss: 0.018202940467745066\n",
      "EPOCH: 22, train_loss: 0.01783621012686919, valid_loss: 0.018202069215476513\n",
      "EPOCH: 23, train_loss: 0.017487687679628532, valid_loss: 0.018067110795527697\n",
      "EPOCH: 24, train_loss: 0.016930796444798127, valid_loss: 0.018119574757292867\n",
      "EPOCH: 25, train_loss: 0.016464913884798687, valid_loss: 0.018193191848695278\n",
      "EPOCH: 26, train_loss: 0.01591838878364517, valid_loss: 0.018183168722316623\n",
      "EPOCH: 27, train_loss: 0.015499562741472172, valid_loss: 0.018283162033185363\n",
      "EPOCH: 28, train_loss: 0.015201393968592852, valid_loss: 0.01827630726620555\n",
      "EPOCH: 29, train_loss: 0.015057822319273, valid_loss: 0.018267578911036253\n",
      "FOLD: 6\n",
      "EPOCH: 0, train_loss: 0.6604329045766439, valid_loss: 0.2776324190199375\n",
      "EPOCH: 1, train_loss: 0.05738985953995815, valid_loss: 0.021092680050060153\n",
      "EPOCH: 2, train_loss: 0.02269968946870321, valid_loss: 0.019067690707743168\n",
      "EPOCH: 3, train_loss: 0.021396339608308595, valid_loss: 0.019700898323208094\n",
      "EPOCH: 4, train_loss: 0.020720830449882228, valid_loss: 0.018557636067271233\n",
      "EPOCH: 5, train_loss: 0.02017330612318638, valid_loss: 0.017558750929310918\n",
      "EPOCH: 6, train_loss: 0.02002653467636078, valid_loss: 0.01756886299699545\n",
      "EPOCH: 7, train_loss: 0.020123357120423745, valid_loss: 0.017802261048927903\n",
      "EPOCH: 8, train_loss: 0.01984220626166998, valid_loss: 0.017539888620376587\n",
      "EPOCH: 9, train_loss: 0.01978899612545203, valid_loss: 0.01743404450826347\n",
      "EPOCH: 10, train_loss: 0.019732184254397184, valid_loss: 0.017560076666995883\n",
      "EPOCH: 11, train_loss: 0.019757731029620536, valid_loss: 0.017707135528326035\n",
      "EPOCH: 12, train_loss: 0.019679000959373437, valid_loss: 0.017815113998949528\n",
      "EPOCH: 13, train_loss: 0.019615946194300286, valid_loss: 0.017574490513652563\n",
      "EPOCH: 14, train_loss: 0.01956301545485472, valid_loss: 0.017468928126618266\n",
      "EPOCH: 15, train_loss: 0.01950243707650747, valid_loss: 0.017435793532058597\n",
      "EPOCH: 16, train_loss: 0.019312753055531245, valid_loss: 0.017331928946077824\n",
      "EPOCH: 17, train_loss: 0.01920799134920041, valid_loss: 0.017117856768891215\n",
      "EPOCH: 18, train_loss: 0.01904174258025029, valid_loss: 0.017293111188337207\n",
      "EPOCH: 19, train_loss: 0.018826263789565135, valid_loss: 0.01723350351676345\n",
      "EPOCH: 20, train_loss: 0.018662230828060553, valid_loss: 0.017122871708124876\n",
      "EPOCH: 21, train_loss: 0.018436670279464662, valid_loss: 0.01717694685794413\n",
      "EPOCH: 22, train_loss: 0.018034058790176343, valid_loss: 0.017216947628185153\n",
      "EPOCH: 23, train_loss: 0.017635699934684314, valid_loss: 0.017021860694512725\n",
      "EPOCH: 24, train_loss: 0.017219899270014886, valid_loss: 0.01710641081444919\n",
      "EPOCH: 25, train_loss: 0.01674370113043831, valid_loss: 0.017140405485406518\n",
      "EPOCH: 26, train_loss: 0.016267632396939475, valid_loss: 0.017080897465348244\n",
      "EPOCH: 27, train_loss: 0.015858547535175696, valid_loss: 0.017189957667142153\n",
      "EPOCH: 28, train_loss: 0.015574399740076982, valid_loss: 0.017184033524245024\n",
      "EPOCH: 29, train_loss: 0.015473557660021843, valid_loss: 0.01720190024934709\n",
      "FOLD: 7\n",
      "EPOCH: 0, train_loss: 0.6572553560703616, valid_loss: 0.24956317618489265\n",
      "EPOCH: 1, train_loss: 0.056081879931160164, valid_loss: 0.023891889955848455\n",
      "EPOCH: 2, train_loss: 0.023520668426269216, valid_loss: 0.08239099476486444\n",
      "EPOCH: 3, train_loss: 0.02258396297221697, valid_loss: 0.019561166875064373\n",
      "EPOCH: 4, train_loss: 0.02138184463676018, valid_loss: 0.021579708671197295\n",
      "EPOCH: 5, train_loss: 0.02091724008227451, valid_loss: 0.018692458514124155\n",
      "EPOCH: 6, train_loss: 0.020542179505470434, valid_loss: 0.017861470114439726\n",
      "EPOCH: 7, train_loss: 0.020390363292226307, valid_loss: 0.018441736698150635\n",
      "EPOCH: 8, train_loss: 0.02024780529775197, valid_loss: 0.01859335578046739\n",
      "EPOCH: 9, train_loss: 0.02002941694440721, valid_loss: 0.017782827839255333\n",
      "EPOCH: 10, train_loss: 0.01989741880399517, valid_loss: 0.017801798414438963\n",
      "EPOCH: 11, train_loss: 0.019754398637745953, valid_loss: 0.017946728505194187\n",
      "EPOCH: 12, train_loss: 0.019769208576483063, valid_loss: 0.017795382533222437\n",
      "EPOCH: 13, train_loss: 0.019711614645357374, valid_loss: 0.017960513941943645\n",
      "EPOCH: 14, train_loss: 0.019645959044559094, valid_loss: 0.017634754301980138\n",
      "EPOCH: 15, train_loss: 0.01963284149577346, valid_loss: 0.017642692662775517\n",
      "EPOCH: 16, train_loss: 0.019562943708858912, valid_loss: 0.01756619056686759\n",
      "EPOCH: 17, train_loss: 0.01925356957259812, valid_loss: 0.017490688245743513\n",
      "EPOCH: 18, train_loss: 0.01907235676351982, valid_loss: 0.017602964770048857\n",
      "EPOCH: 19, train_loss: 0.018971782625664638, valid_loss: 0.017407822888344526\n",
      "EPOCH: 20, train_loss: 0.01877857251918014, valid_loss: 0.017568551236763597\n",
      "EPOCH: 21, train_loss: 0.018652954857937897, valid_loss: 0.01758204004727304\n",
      "EPOCH: 22, train_loss: 0.01847326489094692, valid_loss: 0.017737894551828504\n",
      "EPOCH: 23, train_loss: 0.01798886645443832, valid_loss: 0.01748175546526909\n",
      "EPOCH: 24, train_loss: 0.017484159032000773, valid_loss: 0.01755335391499102\n",
      "EPOCH: 25, train_loss: 0.017009777229137813, valid_loss: 0.017591650364920497\n",
      "EPOCH: 26, train_loss: 0.016455670759742018, valid_loss: 0.01756383804604411\n",
      "EPOCH: 27, train_loss: 0.015986803718665732, valid_loss: 0.017587147187441587\n",
      "EPOCH: 28, train_loss: 0.015674969711918618, valid_loss: 0.017634505406022072\n",
      "EPOCH: 29, train_loss: 0.015551890859592564, valid_loss: 0.01762719894759357\n",
      "FOLD: 8\n",
      "EPOCH: 0, train_loss: 0.658906070114691, valid_loss: 0.24069633148610592\n",
      "EPOCH: 1, train_loss: 0.056177508628255206, valid_loss: 0.02085027052089572\n",
      "EPOCH: 2, train_loss: 0.02292468834998487, valid_loss: 0.018782541388645768\n",
      "EPOCH: 3, train_loss: 0.021620102250311947, valid_loss: 0.017777126049622893\n",
      "EPOCH: 4, train_loss: 0.020901686948122857, valid_loss: 0.01735558151267469\n",
      "EPOCH: 5, train_loss: 0.0202430664219811, valid_loss: 0.018738250248134136\n",
      "EPOCH: 6, train_loss: 0.02040403199535382, valid_loss: 0.017410122323781252\n",
      "EPOCH: 7, train_loss: 0.020097442890835714, valid_loss: 0.017257582396268845\n",
      "EPOCH: 8, train_loss: 0.0200326446019396, valid_loss: 0.01757649634964764\n",
      "EPOCH: 9, train_loss: 0.01998105897462066, valid_loss: 0.0174351679161191\n",
      "EPOCH: 10, train_loss: 0.019907207122143313, valid_loss: 0.017584556713700294\n",
      "EPOCH: 11, train_loss: 0.019959110837382606, valid_loss: 0.01739577087573707\n",
      "EPOCH: 12, train_loss: 0.01979763775215119, valid_loss: 0.01720142620615661\n",
      "EPOCH: 13, train_loss: 0.019665669696994976, valid_loss: 0.017204928095452487\n",
      "EPOCH: 14, train_loss: 0.019600245747951012, valid_loss: 0.01695568603463471\n",
      "EPOCH: 15, train_loss: 0.019604992687324935, valid_loss: 0.017053332878276706\n",
      "EPOCH: 16, train_loss: 0.019432049456842338, valid_loss: 0.017030923161655664\n",
      "EPOCH: 17, train_loss: 0.019322175603312782, valid_loss: 0.01702621055301279\n",
      "EPOCH: 18, train_loss: 0.01919463406540925, valid_loss: 0.01696096220985055\n",
      "EPOCH: 19, train_loss: 0.01894627120110053, valid_loss: 0.01699553953949362\n",
      "EPOCH: 20, train_loss: 0.01865366912340816, valid_loss: 0.01685955503489822\n",
      "EPOCH: 21, train_loss: 0.018410628720457796, valid_loss: 0.016837812610901892\n",
      "EPOCH: 22, train_loss: 0.01812545361020897, valid_loss: 0.01697210199199617\n",
      "EPOCH: 23, train_loss: 0.01774453785553386, valid_loss: 0.016846889979206026\n",
      "EPOCH: 24, train_loss: 0.017272666025953957, valid_loss: 0.016799996024928987\n",
      "EPOCH: 25, train_loss: 0.016819432625382005, valid_loss: 0.01677467639092356\n",
      "EPOCH: 26, train_loss: 0.016385029954246327, valid_loss: 0.01683832297567278\n",
      "EPOCH: 27, train_loss: 0.015809593085623994, valid_loss: 0.01687698846217245\n",
      "EPOCH: 28, train_loss: 0.01550599713397177, valid_loss: 0.016868291655555367\n",
      "EPOCH: 29, train_loss: 0.015408749244164062, valid_loss: 0.016885275370441377\n",
      "FOLD: 9\n",
      "EPOCH: 0, train_loss: 0.6580462998981718, valid_loss: 0.28125666826963425\n",
      "EPOCH: 1, train_loss: 0.05703159282573416, valid_loss: 0.022008964093402028\n",
      "EPOCH: 2, train_loss: 0.023627459484187863, valid_loss: 0.021853400394320488\n",
      "EPOCH: 3, train_loss: 0.02220797911286354, valid_loss: 0.019716776907444\n",
      "EPOCH: 4, train_loss: 0.02163287164949918, valid_loss: 0.018528359243646264\n",
      "EPOCH: 5, train_loss: 0.020786675801382788, valid_loss: 0.018313798354938626\n",
      "EPOCH: 6, train_loss: 0.020517366525681712, valid_loss: 0.018232263391837478\n",
      "EPOCH: 7, train_loss: 0.020227808186996588, valid_loss: 0.018218167359009385\n",
      "EPOCH: 8, train_loss: 0.020330338609180872, valid_loss: 0.01871290197595954\n",
      "EPOCH: 9, train_loss: 0.02023596277672656, valid_loss: 0.017375672701746225\n",
      "EPOCH: 10, train_loss: 0.019866407813527918, valid_loss: 0.017870155861601233\n",
      "EPOCH: 11, train_loss: 0.019902675282917445, valid_loss: 0.017632248578593135\n",
      "EPOCH: 12, train_loss: 0.01967880996297809, valid_loss: 0.017310523195192218\n",
      "EPOCH: 13, train_loss: 0.019679623832808264, valid_loss: 0.017543500987812877\n",
      "EPOCH: 14, train_loss: 0.019753543919400325, valid_loss: 0.01766597479581833\n",
      "EPOCH: 15, train_loss: 0.01957575286019452, valid_loss: 0.017006349517032504\n",
      "EPOCH: 16, train_loss: 0.019406031039130838, valid_loss: 0.017137150513008237\n",
      "EPOCH: 17, train_loss: 0.019284109596776056, valid_loss: 0.017309381859377027\n",
      "EPOCH: 18, train_loss: 0.019092080690249612, valid_loss: 0.017140551935881376\n",
      "EPOCH: 19, train_loss: 0.019156967395845846, valid_loss: 0.017144600162282586\n",
      "EPOCH: 20, train_loss: 0.018695789719401282, valid_loss: 0.01709936768747866\n",
      "EPOCH: 21, train_loss: 0.0184299160219446, valid_loss: 0.016931572696194053\n",
      "EPOCH: 22, train_loss: 0.01803221216401722, valid_loss: 0.01704832655377686\n",
      "EPOCH: 23, train_loss: 0.017826763724413098, valid_loss: 0.016914991894736886\n",
      "EPOCH: 24, train_loss: 0.017536132714322097, valid_loss: 0.016859454568475485\n",
      "EPOCH: 25, train_loss: 0.01695777718685096, valid_loss: 0.016887819627299905\n",
      "EPOCH: 26, train_loss: 0.016332929281965843, valid_loss: 0.01695172069594264\n",
      "EPOCH: 27, train_loss: 0.015945884210493744, valid_loss: 0.016963422764092684\n",
      "EPOCH: 28, train_loss: 0.01578794721561142, valid_loss: 0.01692986278794706\n",
      "EPOCH: 29, train_loss: 0.015733751928127263, valid_loss: 0.016970672411844134\n",
      "FOLD: 10\n",
      "EPOCH: 0, train_loss: 0.6593462209670972, valid_loss: 0.25888172164559364\n",
      "EPOCH: 1, train_loss: 0.05650145061409626, valid_loss: 0.021160608856007457\n",
      "EPOCH: 2, train_loss: 0.02253811987928855, valid_loss: 0.0197280989959836\n",
      "EPOCH: 3, train_loss: 0.021907394513105735, valid_loss: 0.01824956596828997\n",
      "EPOCH: 4, train_loss: 0.020692452859993164, valid_loss: 0.018122019711881876\n",
      "EPOCH: 5, train_loss: 0.020334122344278373, valid_loss: 0.017731022089719772\n",
      "EPOCH: 6, train_loss: 0.020192981864779424, valid_loss: 0.01754020806401968\n",
      "EPOCH: 7, train_loss: 0.01989007991953538, valid_loss: 0.017305991845205426\n",
      "EPOCH: 8, train_loss: 0.01993952512454528, valid_loss: 0.01748625678010285\n",
      "EPOCH: 9, train_loss: 0.019849590073602322, valid_loss: 0.01753985579125583\n",
      "EPOCH: 10, train_loss: 0.019788905596121762, valid_loss: 0.017599775455892086\n",
      "EPOCH: 11, train_loss: 0.019769217914495714, valid_loss: 0.017895719036459923\n",
      "EPOCH: 12, train_loss: 0.019741477468648017, valid_loss: 0.017675301060080528\n",
      "EPOCH: 13, train_loss: 0.01966502006428364, valid_loss: 0.017255197977647185\n",
      "EPOCH: 14, train_loss: 0.019614794100515354, valid_loss: 0.017325031338259578\n",
      "EPOCH: 15, train_loss: 0.019475248045264147, valid_loss: 0.0173703629989177\n",
      "EPOCH: 16, train_loss: 0.019330866515445404, valid_loss: 0.01737836143001914\n",
      "EPOCH: 17, train_loss: 0.019203520642641265, valid_loss: 0.01723884860984981\n",
      "EPOCH: 18, train_loss: 0.01908803031517145, valid_loss: 0.01711875619366765\n",
      "EPOCH: 19, train_loss: 0.01884294814692858, valid_loss: 0.016977335326373577\n",
      "EPOCH: 20, train_loss: 0.018617813690350607, valid_loss: 0.01703317603096366\n",
      "EPOCH: 21, train_loss: 0.018293676969523612, valid_loss: 0.016946670366451144\n",
      "EPOCH: 22, train_loss: 0.01799407075995054, valid_loss: 0.017139229690656066\n",
      "EPOCH: 23, train_loss: 0.017598536546127155, valid_loss: 0.01700542215257883\n",
      "EPOCH: 24, train_loss: 0.01712411527450268, valid_loss: 0.017073475755751133\n",
      "EPOCH: 25, train_loss: 0.016606529350750722, valid_loss: 0.017129815882071853\n",
      "EPOCH: 26, train_loss: 0.016084867207190164, valid_loss: 0.01709847990423441\n",
      "EPOCH: 27, train_loss: 0.01563693895840492, valid_loss: 0.017160099931061268\n",
      "EPOCH: 28, train_loss: 0.015296094907590976, valid_loss: 0.017210341058671474\n",
      "EPOCH: 29, train_loss: 0.015211375955587778, valid_loss: 0.017187388613820076\n",
      "SEED: 1881\n",
      "FOLD: 0\n",
      "EPOCH: 0, train_loss: 0.6580365632589047, valid_loss: 0.2796436734497547\n",
      "EPOCH: 1, train_loss: 0.056302651070440426, valid_loss: 0.02109822304919362\n",
      "EPOCH: 2, train_loss: 0.022672769900124807, valid_loss: 0.01906172395683825\n",
      "EPOCH: 3, train_loss: 0.02139728346791787, valid_loss: 0.018136212835088372\n",
      "EPOCH: 4, train_loss: 0.020800235514075328, valid_loss: 0.01807963429018855\n",
      "EPOCH: 5, train_loss: 0.02025225741836505, valid_loss: 0.017927918815985322\n",
      "EPOCH: 6, train_loss: 0.01998723842776739, valid_loss: 0.017790726153180003\n",
      "EPOCH: 7, train_loss: 0.01988858982729606, valid_loss: 0.017864621710032225\n",
      "EPOCH: 8, train_loss: 0.019798924788259543, valid_loss: 0.01791760860942304\n",
      "EPOCH: 9, train_loss: 0.019800229189105522, valid_loss: 0.017622996005229652\n",
      "EPOCH: 10, train_loss: 0.01971361217781519, valid_loss: 0.017698534997180104\n",
      "EPOCH: 11, train_loss: 0.019715642007306602, valid_loss: 0.017619006102904677\n",
      "EPOCH: 12, train_loss: 0.019645235525109828, valid_loss: 0.017474664142355323\n",
      "EPOCH: 13, train_loss: 0.019558805279815808, valid_loss: 0.017478789668530226\n",
      "EPOCH: 14, train_loss: 0.019475220368267633, valid_loss: 0.017548876348882914\n",
      "EPOCH: 15, train_loss: 0.01933386320104966, valid_loss: 0.017383230850100517\n",
      "EPOCH: 16, train_loss: 0.019294543860432428, valid_loss: 0.01759446249343455\n",
      "EPOCH: 17, train_loss: 0.019142723069168054, valid_loss: 0.017527235439047217\n",
      "EPOCH: 18, train_loss: 0.018961752000718545, valid_loss: 0.017254476668313146\n",
      "EPOCH: 19, train_loss: 0.01871205670520281, valid_loss: 0.01719393813982606\n",
      "EPOCH: 20, train_loss: 0.018458518605583753, valid_loss: 0.0172642411198467\n",
      "EPOCH: 21, train_loss: 0.018177548518929727, valid_loss: 0.017241197638213634\n",
      "EPOCH: 22, train_loss: 0.017854010184796956, valid_loss: 0.01715684903319925\n",
      "EPOCH: 23, train_loss: 0.01741450150998739, valid_loss: 0.01723286707419902\n",
      "EPOCH: 24, train_loss: 0.016931279132572506, valid_loss: 0.017301187850534916\n",
      "EPOCH: 25, train_loss: 0.016387757260161333, valid_loss: 0.017234125290997326\n",
      "EPOCH: 26, train_loss: 0.015823889571504716, valid_loss: 0.017235010396689177\n",
      "EPOCH: 27, train_loss: 0.015371946486620566, valid_loss: 0.017293667187914252\n",
      "EPOCH: 28, train_loss: 0.01507431361824274, valid_loss: 0.017299152561463416\n",
      "EPOCH: 29, train_loss: 0.0149283580816327, valid_loss: 0.017298446502536535\n",
      "FOLD: 1\n",
      "EPOCH: 0, train_loss: 0.6604235405341173, valid_loss: 0.27462245151400566\n",
      "EPOCH: 1, train_loss: 0.0572363891137334, valid_loss: 0.020922059658914804\n",
      "EPOCH: 2, train_loss: 0.02263878412449207, valid_loss: 0.01926138694398105\n",
      "EPOCH: 3, train_loss: 0.021362613623914044, valid_loss: 0.01828199182637036\n",
      "EPOCH: 4, train_loss: 0.02099246894701933, valid_loss: 0.017984346486628056\n",
      "EPOCH: 5, train_loss: 0.020269244336164914, valid_loss: 0.017877215519547462\n",
      "EPOCH: 6, train_loss: 0.020042647941945456, valid_loss: 0.017603681655600667\n",
      "EPOCH: 7, train_loss: 0.019993485763477974, valid_loss: 0.017808151431381702\n",
      "EPOCH: 8, train_loss: 0.019810747570143297, valid_loss: 0.01784483529627323\n",
      "EPOCH: 9, train_loss: 0.01978950820958767, valid_loss: 0.01750983693636954\n",
      "EPOCH: 10, train_loss: 0.01977935836960872, valid_loss: 0.01743616396561265\n",
      "EPOCH: 11, train_loss: 0.019640827694764502, valid_loss: 0.01764646591618657\n",
      "EPOCH: 12, train_loss: 0.01963839739656601, valid_loss: 0.01738522620871663\n",
      "EPOCH: 13, train_loss: 0.0196290728994287, valid_loss: 0.017749076476320624\n",
      "EPOCH: 14, train_loss: 0.019507209268900063, valid_loss: 0.017381486017256975\n",
      "EPOCH: 15, train_loss: 0.01937769460850037, valid_loss: 0.01740886690095067\n",
      "EPOCH: 16, train_loss: 0.019280335794274624, valid_loss: 0.017423001118004322\n",
      "EPOCH: 17, train_loss: 0.019094420358156547, valid_loss: 0.01739664119668305\n",
      "EPOCH: 18, train_loss: 0.01899560681806925, valid_loss: 0.01728172181174159\n",
      "EPOCH: 19, train_loss: 0.018799476492672395, valid_loss: 0.017365464009344578\n",
      "EPOCH: 20, train_loss: 0.018569927256649885, valid_loss: 0.017282988177612424\n",
      "EPOCH: 21, train_loss: 0.018225339611466877, valid_loss: 0.01726127532310784\n",
      "EPOCH: 22, train_loss: 0.01791708431660365, valid_loss: 0.017206263728439808\n",
      "EPOCH: 23, train_loss: 0.017472556887719877, valid_loss: 0.017270942917093635\n",
      "EPOCH: 24, train_loss: 0.01696261551040105, valid_loss: 0.017249302938580513\n",
      "EPOCH: 25, train_loss: 0.01640112390025304, valid_loss: 0.01729400549083948\n",
      "EPOCH: 26, train_loss: 0.0158784374451408, valid_loss: 0.01733524864539504\n",
      "EPOCH: 27, train_loss: 0.015398241937733613, valid_loss: 0.017335025127977133\n",
      "EPOCH: 28, train_loss: 0.015058528428945022, valid_loss: 0.0173490799497813\n",
      "EPOCH: 29, train_loss: 0.014954348190281635, valid_loss: 0.017340569524094462\n",
      "FOLD: 2\n",
      "EPOCH: 0, train_loss: 0.6587900198422946, valid_loss: 0.2741715796291828\n",
      "EPOCH: 1, train_loss: 0.05668700004044252, valid_loss: 0.021375900134444237\n",
      "EPOCH: 2, train_loss: 0.02268110177455804, valid_loss: 0.019405521685257554\n",
      "EPOCH: 3, train_loss: 0.021425366401672363, valid_loss: 0.01863808510825038\n",
      "EPOCH: 4, train_loss: 0.020692927691225823, valid_loss: 0.01933156233280897\n",
      "EPOCH: 5, train_loss: 0.02039881148494971, valid_loss: 0.023088307585567236\n",
      "EPOCH: 6, train_loss: 0.020076995428938132, valid_loss: 0.018016664078459144\n",
      "EPOCH: 7, train_loss: 0.019863750857229415, valid_loss: 0.018189316149801016\n",
      "EPOCH: 8, train_loss: 0.01981319632763282, valid_loss: 0.017898415680974722\n",
      "EPOCH: 9, train_loss: 0.01980128588202672, valid_loss: 0.01795100956223905\n",
      "EPOCH: 10, train_loss: 0.01971730656730823, valid_loss: 0.017948552267625928\n",
      "EPOCH: 11, train_loss: 0.019697741987422492, valid_loss: 0.01803562487475574\n",
      "EPOCH: 12, train_loss: 0.01960658652182573, valid_loss: 0.017965585924685\n",
      "EPOCH: 13, train_loss: 0.01961485692896904, valid_loss: 0.01788131962530315\n",
      "EPOCH: 14, train_loss: 0.019517800484139185, valid_loss: 0.01756244944408536\n",
      "EPOCH: 15, train_loss: 0.01943373092665122, valid_loss: 0.017857700353488326\n",
      "EPOCH: 16, train_loss: 0.019246222785650156, valid_loss: 0.017608531983569264\n",
      "EPOCH: 17, train_loss: 0.019103445852987278, valid_loss: 0.0178363926243037\n",
      "EPOCH: 18, train_loss: 0.01899210585711094, valid_loss: 0.017711821012198925\n",
      "EPOCH: 19, train_loss: 0.018893138696558964, valid_loss: 0.017803362105041742\n",
      "EPOCH: 20, train_loss: 0.018542132674692534, valid_loss: 0.017562976107001305\n",
      "EPOCH: 21, train_loss: 0.018237850939234097, valid_loss: 0.01755630224943161\n",
      "EPOCH: 22, train_loss: 0.01792457724849765, valid_loss: 0.01747177541255951\n",
      "EPOCH: 23, train_loss: 0.01751713103686388, valid_loss: 0.01763894548639655\n",
      "EPOCH: 24, train_loss: 0.017055338284430597, valid_loss: 0.017648465000092983\n",
      "EPOCH: 25, train_loss: 0.016528560517308038, valid_loss: 0.01768222125247121\n",
      "EPOCH: 26, train_loss: 0.01601646228048664, valid_loss: 0.017669877968728542\n",
      "EPOCH: 27, train_loss: 0.015518369988944286, valid_loss: 0.017745288321748376\n",
      "EPOCH: 28, train_loss: 0.01518574008383812, valid_loss: 0.01774533954448998\n",
      "EPOCH: 29, train_loss: 0.01509534371777987, valid_loss: 0.01774554676376283\n",
      "FOLD: 3\n",
      "EPOCH: 0, train_loss: 0.6585180281828611, valid_loss: 0.2693285383284092\n",
      "EPOCH: 1, train_loss: 0.05674798843952326, valid_loss: 0.021052142372354865\n",
      "EPOCH: 2, train_loss: 0.022610130481039867, valid_loss: 0.01991746574640274\n",
      "EPOCH: 3, train_loss: 0.02155579760288581, valid_loss: 0.01892199437133968\n",
      "EPOCH: 4, train_loss: 0.02065087897846332, valid_loss: 0.018618212547153234\n",
      "EPOCH: 5, train_loss: 0.02015405172147812, valid_loss: 0.01792825828306377\n",
      "EPOCH: 6, train_loss: 0.019932407861909807, valid_loss: 0.018110908335074782\n",
      "EPOCH: 7, train_loss: 0.02002014609005971, valid_loss: 0.01787385460920632\n",
      "EPOCH: 8, train_loss: 0.019823935694801502, valid_loss: 0.017831489210948348\n",
      "EPOCH: 9, train_loss: 0.01974644538206168, valid_loss: 0.01791660161688924\n",
      "EPOCH: 10, train_loss: 0.019732025834039237, valid_loss: 0.017705835634842515\n",
      "EPOCH: 11, train_loss: 0.019643691440041248, valid_loss: 0.017649803776293993\n",
      "EPOCH: 12, train_loss: 0.019607186532364443, valid_loss: 0.01777148642577231\n",
      "EPOCH: 13, train_loss: 0.019566469825804234, valid_loss: 0.01768701709806919\n",
      "EPOCH: 14, train_loss: 0.019450104914796658, valid_loss: 0.017427158076316118\n",
      "EPOCH: 15, train_loss: 0.01935049027013473, valid_loss: 0.017475541681051254\n",
      "EPOCH: 16, train_loss: 0.019221917941020086, valid_loss: 0.01768945879302919\n",
      "EPOCH: 17, train_loss: 0.0191004230425908, valid_loss: 0.017565418500453234\n",
      "EPOCH: 18, train_loss: 0.0189607251339998, valid_loss: 0.017412912799045444\n",
      "EPOCH: 19, train_loss: 0.01876622151869994, valid_loss: 0.017362346639856696\n",
      "EPOCH: 20, train_loss: 0.0185393211312401, valid_loss: 0.01728070038370788\n",
      "EPOCH: 21, train_loss: 0.018207896357545487, valid_loss: 0.01734484196640551\n",
      "EPOCH: 22, train_loss: 0.017827877512153905, valid_loss: 0.01735540176741779\n",
      "EPOCH: 23, train_loss: 0.01748491806957202, valid_loss: 0.017316465266048908\n",
      "EPOCH: 24, train_loss: 0.016969998199970294, valid_loss: 0.01731189712882042\n",
      "EPOCH: 25, train_loss: 0.016457062513113786, valid_loss: 0.017334254691377282\n",
      "EPOCH: 26, train_loss: 0.015903570080319278, valid_loss: 0.017385125625878572\n",
      "EPOCH: 27, train_loss: 0.01540654237405994, valid_loss: 0.017382679041475058\n",
      "EPOCH: 28, train_loss: 0.015116436609950585, valid_loss: 0.01739187422208488\n",
      "EPOCH: 29, train_loss: 0.01495735452343256, valid_loss: 0.017388115404173732\n",
      "FOLD: 4\n",
      "EPOCH: 0, train_loss: 0.6609269246841089, valid_loss: 0.2900572456419468\n",
      "EPOCH: 1, train_loss: 0.057344324552477934, valid_loss: 0.021242207381874323\n",
      "EPOCH: 2, train_loss: 0.02279560659558345, valid_loss: 0.019165343372151256\n",
      "EPOCH: 3, train_loss: 0.021577906818726122, valid_loss: 0.01797021459788084\n",
      "EPOCH: 4, train_loss: 0.020783246733630314, valid_loss: 0.017943522427231073\n",
      "EPOCH: 5, train_loss: 0.020364880848389406, valid_loss: 0.017774336505681276\n",
      "EPOCH: 6, train_loss: 0.020037267333230913, valid_loss: 0.017618271755054593\n",
      "EPOCH: 7, train_loss: 0.01984971398726488, valid_loss: 0.0176388758700341\n",
      "EPOCH: 8, train_loss: 0.019830225966870785, valid_loss: 0.017723192228004336\n",
      "EPOCH: 9, train_loss: 0.01978410231188322, valid_loss: 0.017524841241538525\n",
      "EPOCH: 10, train_loss: 0.01973193967476105, valid_loss: 0.01744369533844292\n",
      "EPOCH: 11, train_loss: 0.01968435515673497, valid_loss: 0.017709034262225032\n",
      "EPOCH: 12, train_loss: 0.019677159280922167, valid_loss: 0.017310615396127105\n",
      "EPOCH: 13, train_loss: 0.0195938004180789, valid_loss: 0.017669657012447715\n",
      "EPOCH: 14, train_loss: 0.01954553861362048, valid_loss: 0.017578834667801857\n",
      "EPOCH: 15, train_loss: 0.019468152394088414, valid_loss: 0.017534298356622458\n",
      "EPOCH: 16, train_loss: 0.019340392034978438, valid_loss: 0.017325292341411114\n",
      "EPOCH: 17, train_loss: 0.019177580777651224, valid_loss: 0.017300483072176576\n",
      "EPOCH: 18, train_loss: 0.01907922334682483, valid_loss: 0.017311096657067537\n",
      "EPOCH: 19, train_loss: 0.018833652711831607, valid_loss: 0.017260291380807757\n",
      "EPOCH: 20, train_loss: 0.018550106443655796, valid_loss: 0.017214672407135367\n",
      "EPOCH: 21, train_loss: 0.01828966423487052, valid_loss: 0.017075964249670506\n",
      "EPOCH: 22, train_loss: 0.017960100386960384, valid_loss: 0.01713248621672392\n",
      "EPOCH: 23, train_loss: 0.017524821146462973, valid_loss: 0.017049629241228104\n",
      "EPOCH: 24, train_loss: 0.017059650869132616, valid_loss: 0.017294966150075197\n",
      "EPOCH: 25, train_loss: 0.01652250688475294, valid_loss: 0.01722240261733532\n",
      "EPOCH: 26, train_loss: 0.01598831632723793, valid_loss: 0.017277955543249846\n",
      "EPOCH: 27, train_loss: 0.01553012536934171, valid_loss: 0.017234451603144407\n",
      "EPOCH: 28, train_loss: 0.015187311845903214, valid_loss: 0.017257481580600142\n",
      "EPOCH: 29, train_loss: 0.015080713428174838, valid_loss: 0.017260018503293395\n",
      "FOLD: 5\n",
      "EPOCH: 0, train_loss: 0.6590095498622992, valid_loss: 0.27298588678240776\n",
      "EPOCH: 1, train_loss: 0.05731303548106016, valid_loss: 0.022462108870968223\n",
      "EPOCH: 2, train_loss: 0.022840937551779624, valid_loss: 0.019700043136253953\n",
      "EPOCH: 3, train_loss: 0.021603599978754155, valid_loss: 0.01863504061475396\n",
      "EPOCH: 4, train_loss: 0.02065104114799163, valid_loss: 0.01849263720214367\n",
      "EPOCH: 5, train_loss: 0.020236937424693353, valid_loss: 0.018553473288193345\n",
      "EPOCH: 6, train_loss: 0.01998031896371872, valid_loss: 0.018368871184065938\n",
      "EPOCH: 7, train_loss: 0.01983814853697251, valid_loss: 0.018437400925904512\n",
      "EPOCH: 8, train_loss: 0.019701007801370744, valid_loss: 0.01819748873822391\n",
      "EPOCH: 9, train_loss: 0.019602781830307763, valid_loss: 0.01825503120198846\n",
      "EPOCH: 10, train_loss: 0.019582026470930148, valid_loss: 0.018242045771330595\n",
      "EPOCH: 11, train_loss: 0.019605702004180506, valid_loss: 0.018349421210587025\n",
      "EPOCH: 12, train_loss: 0.01949917372220602, valid_loss: 0.018304294906556606\n",
      "EPOCH: 13, train_loss: 0.019439408531746805, valid_loss: 0.018483881140127778\n",
      "EPOCH: 14, train_loss: 0.01935347828727502, valid_loss: 0.018323073629289865\n",
      "EPOCH: 15, train_loss: 0.01923008229679022, valid_loss: 0.01826811535283923\n",
      "EPOCH: 16, train_loss: 0.01915338282019664, valid_loss: 0.018360602669417858\n",
      "EPOCH: 17, train_loss: 0.019061146733852532, valid_loss: 0.018073095241561532\n",
      "EPOCH: 18, train_loss: 0.01889077361482076, valid_loss: 0.0182054799515754\n",
      "EPOCH: 19, train_loss: 0.018717401708738927, valid_loss: 0.01821880368515849\n",
      "EPOCH: 20, train_loss: 0.01845791116834451, valid_loss: 0.018137053353711963\n",
      "EPOCH: 21, train_loss: 0.0181540075976115, valid_loss: 0.018234372837468982\n",
      "EPOCH: 22, train_loss: 0.01781001367056981, valid_loss: 0.018203095998615026\n",
      "EPOCH: 23, train_loss: 0.017417066658918675, valid_loss: 0.018245473271235824\n",
      "EPOCH: 24, train_loss: 0.01691801031717123, valid_loss: 0.018076740438118577\n",
      "EPOCH: 25, train_loss: 0.01636410016232194, valid_loss: 0.018265749095007777\n",
      "EPOCH: 26, train_loss: 0.015810631526013214, valid_loss: 0.018253274029120803\n",
      "EPOCH: 27, train_loss: 0.01534336682361288, valid_loss: 0.018324762117117643\n",
      "EPOCH: 28, train_loss: 0.01506474131766038, valid_loss: 0.018321075243875384\n",
      "EPOCH: 29, train_loss: 0.014883904705922574, valid_loss: 0.018316772999241948\n",
      "FOLD: 6\n",
      "EPOCH: 0, train_loss: 0.6598218144514622, valid_loss: 0.27510128542780876\n",
      "EPOCH: 1, train_loss: 0.05716858066331882, valid_loss: 0.02078919787891209\n",
      "EPOCH: 2, train_loss: 0.02277283110202123, valid_loss: 0.01910316850990057\n",
      "EPOCH: 3, train_loss: 0.02137309993402316, valid_loss: 0.019634620286524296\n",
      "EPOCH: 4, train_loss: 0.02070199270756581, valid_loss: 0.018055054591968656\n",
      "EPOCH: 5, train_loss: 0.020187001508206893, valid_loss: 0.01792227220721543\n",
      "EPOCH: 6, train_loss: 0.020081244958325837, valid_loss: 0.017633260693401098\n",
      "EPOCH: 7, train_loss: 0.01988012935870733, valid_loss: 0.017649018904194236\n",
      "EPOCH: 8, train_loss: 0.019847474825114775, valid_loss: 0.01778570981696248\n",
      "EPOCH: 9, train_loss: 0.019786322752061564, valid_loss: 0.0177525847684592\n",
      "EPOCH: 10, train_loss: 0.019789182891448338, valid_loss: 0.01754200574941933\n",
      "EPOCH: 11, train_loss: 0.019719112019699354, valid_loss: 0.017468992387875915\n",
      "EPOCH: 12, train_loss: 0.019619345569457762, valid_loss: 0.01756793912500143\n",
      "EPOCH: 13, train_loss: 0.019604056978072874, valid_loss: 0.017582659143954515\n",
      "EPOCH: 14, train_loss: 0.01951182375733669, valid_loss: 0.01750951656140387\n",
      "EPOCH: 15, train_loss: 0.019446494177174874, valid_loss: 0.017186664510518312\n",
      "EPOCH: 16, train_loss: 0.019274339485817995, valid_loss: 0.017386706080287695\n",
      "EPOCH: 17, train_loss: 0.019136214294494726, valid_loss: 0.01746525219641626\n",
      "EPOCH: 18, train_loss: 0.019047781729545347, valid_loss: 0.017226243624463677\n",
      "EPOCH: 19, train_loss: 0.018827869079242915, valid_loss: 0.01715761236846447\n",
      "EPOCH: 20, train_loss: 0.018577410146976128, valid_loss: 0.017171450424939394\n",
      "EPOCH: 21, train_loss: 0.01827028205092901, valid_loss: 0.01729278126731515\n",
      "EPOCH: 22, train_loss: 0.017959907221106384, valid_loss: 0.01711042644456029\n",
      "EPOCH: 23, train_loss: 0.017560052124258034, valid_loss: 0.0172131871804595\n",
      "EPOCH: 24, train_loss: 0.01707477268213645, valid_loss: 0.017019177321344614\n",
      "EPOCH: 25, train_loss: 0.016531122454370443, valid_loss: 0.017175600165501237\n",
      "EPOCH: 26, train_loss: 0.016038695744310435, valid_loss: 0.01717833778820932\n",
      "EPOCH: 27, train_loss: 0.015563513964223556, valid_loss: 0.017274852842092514\n",
      "EPOCH: 28, train_loss: 0.015273375257563133, valid_loss: 0.017272782512009144\n",
      "EPOCH: 29, train_loss: 0.015152547269677505, valid_loss: 0.017263394314795732\n",
      "FOLD: 7\n",
      "EPOCH: 0, train_loss: 0.6581248708918125, valid_loss: 0.26996874809265137\n",
      "EPOCH: 1, train_loss: 0.05624398442951939, valid_loss: 0.021056236932054162\n",
      "EPOCH: 2, train_loss: 0.023206583495381513, valid_loss: 0.026563277700915933\n",
      "EPOCH: 3, train_loss: 0.0218551432407355, valid_loss: 0.030930228997021914\n",
      "EPOCH: 4, train_loss: 0.02124755775343768, valid_loss: 0.018905283883213997\n",
      "EPOCH: 5, train_loss: 0.020684930767062345, valid_loss: 0.01829980523325503\n",
      "EPOCH: 6, train_loss: 0.020599567013073573, valid_loss: 0.018827229272574186\n",
      "EPOCH: 7, train_loss: 0.020429025062277346, valid_loss: 0.017956063151359558\n",
      "EPOCH: 8, train_loss: 0.0200688842966964, valid_loss: 0.017926445230841637\n",
      "EPOCH: 9, train_loss: 0.020087403610725946, valid_loss: 0.018150985008105636\n",
      "EPOCH: 10, train_loss: 0.019976980724855313, valid_loss: 0.017849237890914083\n",
      "EPOCH: 11, train_loss: 0.020052977000610737, valid_loss: 0.01815516105853021\n",
      "EPOCH: 12, train_loss: 0.019854566483180736, valid_loss: 0.017629038309678435\n",
      "EPOCH: 13, train_loss: 0.019731497250591652, valid_loss: 0.017644439823925495\n",
      "EPOCH: 14, train_loss: 0.019612221507049058, valid_loss: 0.017574701691046357\n",
      "EPOCH: 15, train_loss: 0.01973403429117384, valid_loss: 0.017535476246848702\n",
      "EPOCH: 16, train_loss: 0.019701209155064594, valid_loss: 0.01762323617003858\n",
      "EPOCH: 17, train_loss: 0.019569423780599726, valid_loss: 0.017558883409947157\n",
      "EPOCH: 18, train_loss: 0.01924020179276225, valid_loss: 0.017383497906848788\n",
      "EPOCH: 19, train_loss: 0.0190856130204246, valid_loss: 0.01734649995341897\n",
      "EPOCH: 20, train_loss: 0.019065393276418312, valid_loss: 0.01737779681570828\n",
      "EPOCH: 21, train_loss: 0.018718343746813037, valid_loss: 0.017343201441690326\n",
      "EPOCH: 22, train_loss: 0.018445256555193586, valid_loss: 0.017448723781853914\n",
      "EPOCH: 23, train_loss: 0.018360428512096405, valid_loss: 0.017479177797213197\n",
      "EPOCH: 24, train_loss: 0.01784090407758574, valid_loss: 0.017306414432823658\n",
      "EPOCH: 25, train_loss: 0.017581170212618912, valid_loss: 0.017390340100973845\n",
      "EPOCH: 26, train_loss: 0.017214282404018354, valid_loss: 0.017361152451485395\n",
      "EPOCH: 27, train_loss: 0.016829699513655674, valid_loss: 0.017407613107934594\n",
      "EPOCH: 28, train_loss: 0.016636007041021993, valid_loss: 0.017486149445176125\n",
      "EPOCH: 29, train_loss: 0.01641880204500277, valid_loss: 0.017465123906731606\n",
      "FOLD: 8\n",
      "EPOCH: 0, train_loss: 0.6575702323189264, valid_loss: 0.266572967171669\n",
      "EPOCH: 1, train_loss: 0.05553832742137999, valid_loss: 0.020292163360863924\n",
      "EPOCH: 2, train_loss: 0.022922753297452685, valid_loss: 0.01927393046207726\n",
      "EPOCH: 3, train_loss: 0.021540539810740496, valid_loss: 0.018836930161342025\n",
      "EPOCH: 4, train_loss: 0.02088093988691704, valid_loss: 0.03734961338341236\n",
      "EPOCH: 5, train_loss: 0.02067381079909922, valid_loss: 0.01729226892348379\n",
      "EPOCH: 6, train_loss: 0.02025899941785426, valid_loss: 0.020070777274668217\n",
      "EPOCH: 7, train_loss: 0.020162793489385256, valid_loss: 0.017212451435625553\n",
      "EPOCH: 8, train_loss: 0.02001042878608915, valid_loss: 0.017342022387310863\n",
      "EPOCH: 9, train_loss: 0.020013976677120487, valid_loss: 0.017275537480600178\n",
      "EPOCH: 10, train_loss: 0.019863278734721716, valid_loss: 0.017398778814822435\n",
      "EPOCH: 11, train_loss: 0.019896901813866216, valid_loss: 0.017118709161877632\n",
      "EPOCH: 12, train_loss: 0.01983256197145468, valid_loss: 0.017117958632297814\n",
      "EPOCH: 13, train_loss: 0.019684398028103612, valid_loss: 0.016930273617617786\n",
      "EPOCH: 14, train_loss: 0.019598982308672953, valid_loss: 0.017298386432230473\n",
      "EPOCH: 15, train_loss: 0.01953475243305858, valid_loss: 0.01692158670630306\n",
      "EPOCH: 16, train_loss: 0.01935822661683152, valid_loss: 0.017074695322662592\n",
      "EPOCH: 17, train_loss: 0.019349478656732585, valid_loss: 0.016913969302549958\n",
      "EPOCH: 18, train_loss: 0.019221266024286233, valid_loss: 0.017027509748004377\n",
      "EPOCH: 19, train_loss: 0.019051455173499977, valid_loss: 0.016851140302605927\n",
      "EPOCH: 20, train_loss: 0.01869572720289985, valid_loss: 0.01694427989423275\n",
      "EPOCH: 21, train_loss: 0.018549964515657366, valid_loss: 0.016892162733711302\n",
      "EPOCH: 22, train_loss: 0.018183187711276586, valid_loss: 0.01679168175905943\n",
      "EPOCH: 23, train_loss: 0.017756643811170057, valid_loss: 0.016747522866353393\n",
      "EPOCH: 24, train_loss: 0.017401080885076824, valid_loss: 0.01684978266712278\n",
      "EPOCH: 25, train_loss: 0.016888910220770895, valid_loss: 0.016871550818905234\n",
      "EPOCH: 26, train_loss: 0.016364881297266935, valid_loss: 0.016834755311720073\n",
      "EPOCH: 27, train_loss: 0.015901849793765365, valid_loss: 0.01691014936659485\n",
      "EPOCH: 28, train_loss: 0.015613292402858976, valid_loss: 0.01689902669750154\n",
      "EPOCH: 29, train_loss: 0.015475144185408761, valid_loss: 0.016924825962632895\n",
      "FOLD: 9\n",
      "EPOCH: 0, train_loss: 0.6581728428224974, valid_loss: 0.2788389027118683\n",
      "EPOCH: 1, train_loss: 0.05680926938694489, valid_loss: 0.020973509177565575\n",
      "EPOCH: 2, train_loss: 0.02332127214515511, valid_loss: 0.021344311768189073\n",
      "EPOCH: 3, train_loss: 0.022137956151479406, valid_loss: 0.020036970265209675\n",
      "EPOCH: 4, train_loss: 0.021427447990148882, valid_loss: 0.023983608232811093\n",
      "EPOCH: 5, train_loss: 0.021304713137730767, valid_loss: 0.018797903321683407\n",
      "EPOCH: 6, train_loss: 0.02057773169554487, valid_loss: 0.017876742407679558\n",
      "EPOCH: 7, train_loss: 0.020269840885000893, valid_loss: 0.01872479123994708\n",
      "EPOCH: 8, train_loss: 0.020364908831594867, valid_loss: 0.017700779484584928\n",
      "EPOCH: 9, train_loss: 0.02011341549739053, valid_loss: 0.017612710129469633\n",
      "EPOCH: 10, train_loss: 0.019787665963455846, valid_loss: 0.017369463574141264\n",
      "EPOCH: 11, train_loss: 0.019669503633734545, valid_loss: 0.017295228550210595\n",
      "EPOCH: 12, train_loss: 0.019716480346042897, valid_loss: 0.01728748739697039\n",
      "EPOCH: 13, train_loss: 0.01956480060102819, valid_loss: 0.01764536346308887\n",
      "EPOCH: 14, train_loss: 0.01965432988974867, valid_loss: 0.017521479167044163\n",
      "EPOCH: 15, train_loss: 0.019647514164636407, valid_loss: 0.017303118482232094\n",
      "EPOCH: 16, train_loss: 0.019792861104766024, valid_loss: 0.017175797140225768\n",
      "EPOCH: 17, train_loss: 0.01953530038082147, valid_loss: 0.017175660002976656\n",
      "EPOCH: 18, train_loss: 0.019584196843678438, valid_loss: 0.01728491997346282\n",
      "EPOCH: 19, train_loss: 0.019479338999224615, valid_loss: 0.016989198280498385\n",
      "EPOCH: 20, train_loss: 0.019180858130507832, valid_loss: 0.016911155311390758\n",
      "EPOCH: 21, train_loss: 0.018769889433361307, valid_loss: 0.016950471559539437\n",
      "EPOCH: 22, train_loss: 0.018656719405251213, valid_loss: 0.016791256959550083\n",
      "EPOCH: 23, train_loss: 0.01856103395642359, valid_loss: 0.016850344138219953\n",
      "EPOCH: 24, train_loss: 0.018079401995939545, valid_loss: 0.016853797249495983\n",
      "EPOCH: 25, train_loss: 0.017792519394166862, valid_loss: 0.01684210100211203\n",
      "EPOCH: 26, train_loss: 0.017303528865398484, valid_loss: 0.016918827081099153\n",
      "EPOCH: 27, train_loss: 0.016993870746485795, valid_loss: 0.016887226840481162\n",
      "EPOCH: 28, train_loss: 0.016801032756419875, valid_loss: 0.016942121321335435\n",
      "EPOCH: 29, train_loss: 0.016810197642521015, valid_loss: 0.01688827737234533\n",
      "FOLD: 10\n",
      "EPOCH: 0, train_loss: 0.6592846153638302, valid_loss: 0.2533760815858841\n",
      "EPOCH: 1, train_loss: 0.05695426784073695, valid_loss: 0.02100689895451069\n",
      "EPOCH: 2, train_loss: 0.022645095769220438, valid_loss: 0.019560103537514806\n",
      "EPOCH: 3, train_loss: 0.02144674522181352, valid_loss: 0.018355369102209806\n",
      "EPOCH: 4, train_loss: 0.020761333907452915, valid_loss: 0.01841689203865826\n",
      "EPOCH: 5, train_loss: 0.02018726261284871, valid_loss: 0.017607846530154347\n",
      "EPOCH: 6, train_loss: 0.01999052496961294, valid_loss: 0.017772003076970577\n",
      "EPOCH: 7, train_loss: 0.019972888466257315, valid_loss: 0.01752240606583655\n",
      "EPOCH: 8, train_loss: 0.019861450896431238, valid_loss: 0.01753432536497712\n",
      "EPOCH: 9, train_loss: 0.019821310487504188, valid_loss: 0.017499104840680957\n",
      "EPOCH: 10, train_loss: 0.019774425249451246, valid_loss: 0.017483560368418694\n",
      "EPOCH: 11, train_loss: 0.019735751315378226, valid_loss: 0.017500778194516897\n",
      "EPOCH: 12, train_loss: 0.019697442889595643, valid_loss: 0.01748290634714067\n",
      "EPOCH: 13, train_loss: 0.019612521243592102, valid_loss: 0.01742796623148024\n",
      "EPOCH: 14, train_loss: 0.01960107985024269, valid_loss: 0.017310040071606636\n",
      "EPOCH: 15, train_loss: 0.01941246883227275, valid_loss: 0.017417883733287454\n",
      "EPOCH: 16, train_loss: 0.019394740916024417, valid_loss: 0.017197109991684556\n",
      "EPOCH: 17, train_loss: 0.01926873130007432, valid_loss: 0.017077680211514235\n",
      "EPOCH: 18, train_loss: 0.01905797042239171, valid_loss: 0.016962528694421053\n",
      "EPOCH: 19, train_loss: 0.01881543795267741, valid_loss: 0.017344668740406632\n",
      "EPOCH: 20, train_loss: 0.01866862464409608, valid_loss: 0.017132221721112728\n",
      "EPOCH: 21, train_loss: 0.018341603426214974, valid_loss: 0.017054447205737233\n",
      "EPOCH: 22, train_loss: 0.01797076252599557, valid_loss: 0.01699619018472731\n",
      "EPOCH: 23, train_loss: 0.01753398100248514, valid_loss: 0.016935705672949553\n",
      "EPOCH: 24, train_loss: 0.0170457073344061, valid_loss: 0.016927445307374\n",
      "EPOCH: 25, train_loss: 0.016529390612282813, valid_loss: 0.016969925723969936\n",
      "EPOCH: 26, train_loss: 0.015986848634500533, valid_loss: 0.017019654624164104\n",
      "EPOCH: 27, train_loss: 0.015525049947870847, valid_loss: 0.017027327325195074\n",
      "EPOCH: 28, train_loss: 0.015206187605284728, valid_loss: 0.01709616230800748\n",
      "EPOCH: 29, train_loss: 0.015061654604207247, valid_loss: 0.017078085569664836\n",
      "SEED: 1903\n",
      "FOLD: 0\n",
      "EPOCH: 0, train_loss: 0.6584780674714309, valid_loss: 0.2786308266222477\n",
      "EPOCH: 1, train_loss: 0.057130899089269147, valid_loss: 0.020842740312218666\n",
      "EPOCH: 2, train_loss: 0.022648298921875466, valid_loss: 0.0195956458337605\n",
      "EPOCH: 3, train_loss: 0.02185459456478174, valid_loss: 0.018421068089082837\n",
      "EPOCH: 4, train_loss: 0.020777159489882298, valid_loss: 0.01824102527461946\n",
      "EPOCH: 5, train_loss: 0.020243449327655327, valid_loss: 0.01762614701874554\n",
      "EPOCH: 6, train_loss: 0.0200279500717536, valid_loss: 0.018123664427548647\n",
      "EPOCH: 7, train_loss: 0.019971112553507853, valid_loss: 0.017862722743302584\n",
      "EPOCH: 8, train_loss: 0.019812234199773043, valid_loss: 0.017722686054185033\n",
      "EPOCH: 9, train_loss: 0.019759819221993286, valid_loss: 0.017916723852977157\n",
      "EPOCH: 10, train_loss: 0.019721225692102544, valid_loss: 0.0177014647051692\n",
      "EPOCH: 11, train_loss: 0.019717141365011532, valid_loss: 0.017480536364018917\n",
      "EPOCH: 12, train_loss: 0.019625986162095498, valid_loss: 0.017375377705320716\n",
      "EPOCH: 13, train_loss: 0.01952170592565567, valid_loss: 0.017673318041488528\n",
      "EPOCH: 14, train_loss: 0.019437806776318796, valid_loss: 0.01748449867591262\n",
      "EPOCH: 15, train_loss: 0.019325002550314635, valid_loss: 0.017555713187903166\n",
      "EPOCH: 16, train_loss: 0.019287037472121227, valid_loss: 0.017348040593788028\n",
      "EPOCH: 17, train_loss: 0.019196975331466932, valid_loss: 0.017383550526574254\n",
      "EPOCH: 18, train_loss: 0.01895447178051258, valid_loss: 0.017600653925910592\n",
      "EPOCH: 19, train_loss: 0.01870409580759513, valid_loss: 0.01716278027743101\n",
      "EPOCH: 20, train_loss: 0.01842154161288188, valid_loss: 0.01710567285772413\n",
      "EPOCH: 21, train_loss: 0.018158350402537066, valid_loss: 0.017249613185413182\n",
      "EPOCH: 22, train_loss: 0.017812679091898296, valid_loss: 0.0171790310414508\n",
      "EPOCH: 23, train_loss: 0.017428953057298295, valid_loss: 0.0171650480479002\n",
      "EPOCH: 24, train_loss: 0.016944662631990817, valid_loss: 0.01728002796880901\n",
      "EPOCH: 25, train_loss: 0.016390220465090793, valid_loss: 0.017261798144318163\n",
      "EPOCH: 26, train_loss: 0.015814911824865982, valid_loss: 0.017212596256285906\n",
      "EPOCH: 27, train_loss: 0.01529586397541257, valid_loss: 0.017274797311984003\n",
      "EPOCH: 28, train_loss: 0.014963170764251398, valid_loss: 0.01729869598057121\n",
      "EPOCH: 29, train_loss: 0.014835929880157495, valid_loss: 0.017323710839264095\n",
      "FOLD: 1\n",
      "EPOCH: 0, train_loss: 0.6570958113059019, valid_loss: 0.25520193576812744\n",
      "EPOCH: 1, train_loss: 0.056143991076029263, valid_loss: 0.020850351778790355\n",
      "EPOCH: 2, train_loss: 0.02275718493052782, valid_loss: 0.019134201342239976\n",
      "EPOCH: 3, train_loss: 0.021500707890551824, valid_loss: 0.01831200998276472\n",
      "EPOCH: 4, train_loss: 0.02063950702834588, valid_loss: 0.017760049318894744\n",
      "EPOCH: 5, train_loss: 0.02023103393805333, valid_loss: 0.01758316345512867\n",
      "EPOCH: 6, train_loss: 0.01994168865852631, valid_loss: 0.017616018187254667\n",
      "EPOCH: 7, train_loss: 0.019890898766999062, valid_loss: 0.01768132857978344\n",
      "EPOCH: 8, train_loss: 0.019815897951141383, valid_loss: 0.018157583428546786\n",
      "EPOCH: 9, train_loss: 0.019830240318790462, valid_loss: 0.01786921755410731\n",
      "EPOCH: 10, train_loss: 0.019658771033088367, valid_loss: 0.017638789024204016\n",
      "EPOCH: 11, train_loss: 0.01968651818923461, valid_loss: 0.01758592971600592\n",
      "EPOCH: 12, train_loss: 0.019627817070636995, valid_loss: 0.01764344982802868\n",
      "EPOCH: 13, train_loss: 0.019576433329628065, valid_loss: 0.0174918279517442\n",
      "EPOCH: 14, train_loss: 0.0195094753200045, valid_loss: 0.017570018535479903\n",
      "EPOCH: 15, train_loss: 0.019376154272602156, valid_loss: 0.017465468030422926\n",
      "EPOCH: 16, train_loss: 0.019276043113607626, valid_loss: 0.017574775498360395\n",
      "EPOCH: 17, train_loss: 0.019125535415533263, valid_loss: 0.017260208958759904\n",
      "EPOCH: 18, train_loss: 0.01907012255814595, valid_loss: 0.01731597795151174\n",
      "EPOCH: 19, train_loss: 0.01879272321000313, valid_loss: 0.017342132283374667\n",
      "EPOCH: 20, train_loss: 0.018567208391733658, valid_loss: 0.01719261589460075\n",
      "EPOCH: 21, train_loss: 0.01824425120288745, valid_loss: 0.017328239511698484\n",
      "EPOCH: 22, train_loss: 0.01793684877264194, valid_loss: 0.01721416017971933\n",
      "EPOCH: 23, train_loss: 0.01753405479188913, valid_loss: 0.0172138256020844\n",
      "EPOCH: 24, train_loss: 0.01699559973218502, valid_loss: 0.017301012063398957\n",
      "EPOCH: 25, train_loss: 0.01644162642650115, valid_loss: 0.017372662434354424\n",
      "EPOCH: 26, train_loss: 0.015914873148386296, valid_loss: 0.01732246787287295\n",
      "EPOCH: 27, train_loss: 0.0154058357509665, valid_loss: 0.017335545271635056\n",
      "EPOCH: 28, train_loss: 0.015107388966358624, valid_loss: 0.017356073250994086\n",
      "EPOCH: 29, train_loss: 0.01495013300042886, valid_loss: 0.017360277706757188\n",
      "FOLD: 2\n",
      "EPOCH: 0, train_loss: 0.6580697565506666, valid_loss: 0.2810179740190506\n",
      "EPOCH: 1, train_loss: 0.05690086451478493, valid_loss: 0.020940055372193456\n",
      "EPOCH: 2, train_loss: 0.022822588252333496, valid_loss: 0.01936477585695684\n",
      "EPOCH: 3, train_loss: 0.021331263109086417, valid_loss: 0.019134765723720193\n",
      "EPOCH: 4, train_loss: 0.021049039414486825, valid_loss: 0.018374694045633078\n",
      "EPOCH: 5, train_loss: 0.020216053065199118, valid_loss: 0.0180991911329329\n",
      "EPOCH: 6, train_loss: 0.019986736325499337, valid_loss: 0.018013046588748693\n",
      "EPOCH: 7, train_loss: 0.019887093669519976, valid_loss: 0.018368661403656006\n",
      "EPOCH: 8, train_loss: 0.01984798774505273, valid_loss: 0.01801047148182988\n",
      "EPOCH: 9, train_loss: 0.019747544772540912, valid_loss: 0.018102780217304826\n",
      "EPOCH: 10, train_loss: 0.019670146493575513, valid_loss: 0.017891247756779194\n",
      "EPOCH: 11, train_loss: 0.019650261156643048, valid_loss: 0.017965969629585743\n",
      "EPOCH: 12, train_loss: 0.019558958398799103, valid_loss: 0.017869865987449884\n",
      "EPOCH: 13, train_loss: 0.019509844625225432, valid_loss: 0.017833912512287498\n",
      "EPOCH: 14, train_loss: 0.019476829168315116, valid_loss: 0.017811965197324753\n",
      "EPOCH: 15, train_loss: 0.019315645695687868, valid_loss: 0.0177030258346349\n",
      "EPOCH: 16, train_loss: 0.019252152612002995, valid_loss: 0.018276895862072706\n",
      "EPOCH: 17, train_loss: 0.01910400877778347, valid_loss: 0.017789538949728012\n",
      "EPOCH: 18, train_loss: 0.01894124363286373, valid_loss: 0.01778360246680677\n",
      "EPOCH: 19, train_loss: 0.018732518196488038, valid_loss: 0.01762051903642714\n",
      "EPOCH: 20, train_loss: 0.018447607134779293, valid_loss: 0.017577024176716805\n",
      "EPOCH: 21, train_loss: 0.01819299338146662, valid_loss: 0.017574674217030406\n",
      "EPOCH: 22, train_loss: 0.017806231402433835, valid_loss: 0.01761688361875713\n",
      "EPOCH: 23, train_loss: 0.01736913837540226, valid_loss: 0.017637841403484344\n",
      "EPOCH: 24, train_loss: 0.01685461159556722, valid_loss: 0.01756458659656346\n",
      "EPOCH: 25, train_loss: 0.016315784675475113, valid_loss: 0.017538298154249787\n",
      "EPOCH: 26, train_loss: 0.01573925295796914, valid_loss: 0.017659263452515006\n",
      "EPOCH: 27, train_loss: 0.01526626519476756, valid_loss: 0.0176971354521811\n",
      "EPOCH: 28, train_loss: 0.014887043585379919, valid_loss: 0.01770449010655284\n",
      "EPOCH: 29, train_loss: 0.014754983202482645, valid_loss: 0.017714618938043714\n",
      "FOLD: 3\n",
      "EPOCH: 0, train_loss: 0.6574934965524918, valid_loss: 0.2625073939561844\n",
      "EPOCH: 1, train_loss: 0.0566000682898821, valid_loss: 0.020978964865207672\n",
      "EPOCH: 2, train_loss: 0.022710977408748407, valid_loss: 0.01948139094747603\n",
      "EPOCH: 3, train_loss: 0.021438156732190877, valid_loss: 0.0186654981225729\n",
      "EPOCH: 4, train_loss: 0.02051622525621683, valid_loss: 0.018100814893841743\n",
      "EPOCH: 5, train_loss: 0.020214241571151294, valid_loss: 0.018262613099068403\n",
      "EPOCH: 6, train_loss: 0.019945717942065153, valid_loss: 0.01797475037164986\n",
      "EPOCH: 7, train_loss: 0.019873282752740078, valid_loss: 0.017993245739489794\n",
      "EPOCH: 8, train_loss: 0.01978261436884984, valid_loss: 0.01794716017320752\n",
      "EPOCH: 9, train_loss: 0.019698117573100787, valid_loss: 0.017725359881296754\n",
      "EPOCH: 10, train_loss: 0.01967326909876787, valid_loss: 0.017771265469491482\n",
      "EPOCH: 11, train_loss: 0.01963507405553873, valid_loss: 0.017623130697757006\n",
      "EPOCH: 12, train_loss: 0.019574542243320208, valid_loss: 0.018092750571668148\n",
      "EPOCH: 13, train_loss: 0.01954215308890129, valid_loss: 0.01791327726095915\n",
      "EPOCH: 14, train_loss: 0.019453296318459205, valid_loss: 0.01743707782588899\n",
      "EPOCH: 15, train_loss: 0.019348163635302812, valid_loss: 0.017573420656844974\n",
      "EPOCH: 16, train_loss: 0.01928302373450536, valid_loss: 0.017516725696623325\n",
      "EPOCH: 17, train_loss: 0.01912052148523239, valid_loss: 0.01758179720491171\n",
      "EPOCH: 18, train_loss: 0.018932472293575604, valid_loss: 0.01746023609302938\n",
      "EPOCH: 19, train_loss: 0.01876507482180993, valid_loss: 0.017305875895544887\n",
      "EPOCH: 20, train_loss: 0.01850256462318775, valid_loss: 0.01743246312253177\n",
      "EPOCH: 21, train_loss: 0.018197901881276034, valid_loss: 0.01727189915254712\n",
      "EPOCH: 22, train_loss: 0.017860968644993428, valid_loss: 0.017207189928740263\n",
      "EPOCH: 23, train_loss: 0.017465764274581883, valid_loss: 0.017179629998281598\n",
      "EPOCH: 24, train_loss: 0.016940631927588046, valid_loss: 0.017226816155016422\n",
      "EPOCH: 25, train_loss: 0.016402268507637274, valid_loss: 0.01725095324218273\n",
      "EPOCH: 26, train_loss: 0.015818035564361475, valid_loss: 0.017337340861558914\n",
      "EPOCH: 27, train_loss: 0.015370034576895146, valid_loss: 0.01733109075576067\n",
      "EPOCH: 28, train_loss: 0.015005505058723383, valid_loss: 0.01735865301452577\n",
      "EPOCH: 29, train_loss: 0.014871021959548578, valid_loss: 0.01737152598798275\n",
      "FOLD: 4\n",
      "EPOCH: 0, train_loss: 0.6572863406095749, valid_loss: 0.26887858286499977\n",
      "EPOCH: 1, train_loss: 0.05550346960528539, valid_loss: 0.020824404433369637\n",
      "EPOCH: 2, train_loss: 0.022653187171388894, valid_loss: 0.01887786784209311\n",
      "EPOCH: 3, train_loss: 0.02141529832703945, valid_loss: 0.01843835017643869\n",
      "EPOCH: 4, train_loss: 0.020654978946997568, valid_loss: 0.0179144823923707\n",
      "EPOCH: 5, train_loss: 0.02027686339062758, valid_loss: 0.01740782940760255\n",
      "EPOCH: 6, train_loss: 0.019961383432531968, valid_loss: 0.01763115171343088\n",
      "EPOCH: 7, train_loss: 0.019925543178732578, valid_loss: 0.01787837385199964\n",
      "EPOCH: 8, train_loss: 0.019856386388150547, valid_loss: 0.017691562650725245\n",
      "EPOCH: 9, train_loss: 0.019802334527365673, valid_loss: 0.01766844978556037\n",
      "EPOCH: 10, train_loss: 0.01973058331089142, valid_loss: 0.017435066401958466\n",
      "EPOCH: 11, train_loss: 0.019784566182165574, valid_loss: 0.017560505541041493\n",
      "EPOCH: 12, train_loss: 0.01964845556097153, valid_loss: 0.017548866802826524\n",
      "EPOCH: 13, train_loss: 0.01956667698537692, valid_loss: 0.017262856708839536\n",
      "EPOCH: 14, train_loss: 0.01952420487904396, valid_loss: 0.017284017521888018\n",
      "EPOCH: 15, train_loss: 0.019377329792731848, valid_loss: 0.017429222585633397\n",
      "EPOCH: 16, train_loss: 0.01924854122961943, valid_loss: 0.01731777098029852\n",
      "EPOCH: 17, train_loss: 0.019109191969992258, valid_loss: 0.017306428402662277\n",
      "EPOCH: 18, train_loss: 0.019029521980346777, valid_loss: 0.0172080690972507\n",
      "EPOCH: 19, train_loss: 0.01875535558718137, valid_loss: 0.017271175049245358\n",
      "EPOCH: 20, train_loss: 0.018474748119329795, valid_loss: 0.017113272566348314\n",
      "EPOCH: 21, train_loss: 0.018197817369722404, valid_loss: 0.017073903465643525\n",
      "EPOCH: 22, train_loss: 0.01786010081951435, valid_loss: 0.017066411208361387\n",
      "EPOCH: 23, train_loss: 0.017423988272173282, valid_loss: 0.017065990949049592\n",
      "EPOCH: 24, train_loss: 0.016953420264121048, valid_loss: 0.017140005016699433\n",
      "EPOCH: 25, train_loss: 0.016413600518344305, valid_loss: 0.01716186571866274\n",
      "EPOCH: 26, train_loss: 0.015834605500388604, valid_loss: 0.01715649524703622\n",
      "EPOCH: 27, train_loss: 0.015335799839634161, valid_loss: 0.017168510938063264\n",
      "EPOCH: 28, train_loss: 0.015002313129699383, valid_loss: 0.017191886669024825\n",
      "EPOCH: 29, train_loss: 0.014891747755404467, valid_loss: 0.017202844144776464\n",
      "FOLD: 5\n",
      "EPOCH: 0, train_loss: 0.6587485277499908, valid_loss: 0.2873522564768791\n",
      "EPOCH: 1, train_loss: 0.05751028250998411, valid_loss: 0.021098142489790916\n",
      "EPOCH: 2, train_loss: 0.022853563109842632, valid_loss: 0.019508649362251163\n",
      "EPOCH: 3, train_loss: 0.02136890587802881, valid_loss: 0.018737121019512415\n",
      "EPOCH: 4, train_loss: 0.020663851275084875, valid_loss: 0.018600906245410442\n",
      "EPOCH: 5, train_loss: 0.020098691161435384, valid_loss: 0.01883796346373856\n",
      "EPOCH: 6, train_loss: 0.020001717078953218, valid_loss: 0.01814835169352591\n",
      "EPOCH: 7, train_loss: 0.019834755681073055, valid_loss: 0.01832453371025622\n",
      "EPOCH: 8, train_loss: 0.019776383486504737, valid_loss: 0.018302786629647017\n",
      "EPOCH: 9, train_loss: 0.019706810370851785, valid_loss: 0.01843478553928435\n",
      "EPOCH: 10, train_loss: 0.019667464069640025, valid_loss: 0.01842505345121026\n",
      "EPOCH: 11, train_loss: 0.019624637845808115, valid_loss: 0.018524261424317956\n",
      "EPOCH: 12, train_loss: 0.01952683686828002, valid_loss: 0.0181809077039361\n",
      "EPOCH: 13, train_loss: 0.019442193257885102, valid_loss: 0.01824751915410161\n",
      "EPOCH: 14, train_loss: 0.019414083435176276, valid_loss: 0.017949228873476386\n",
      "EPOCH: 15, train_loss: 0.01926658507914115, valid_loss: 0.01832321542315185\n",
      "EPOCH: 16, train_loss: 0.019139911597355817, valid_loss: 0.01824432658031583\n",
      "EPOCH: 17, train_loss: 0.01903433362260843, valid_loss: 0.018047789810225368\n",
      "EPOCH: 18, train_loss: 0.018869007913730085, valid_loss: 0.018197867553681135\n",
      "EPOCH: 19, train_loss: 0.018687266593751233, valid_loss: 0.018077505752444267\n",
      "EPOCH: 20, train_loss: 0.018449638874675982, valid_loss: 0.018116830149665475\n",
      "EPOCH: 21, train_loss: 0.01815365584423909, valid_loss: 0.018278429051861167\n",
      "EPOCH: 22, train_loss: 0.01775952622007865, valid_loss: 0.018140351865440607\n",
      "EPOCH: 23, train_loss: 0.017313356057573587, valid_loss: 0.018302328418940306\n",
      "EPOCH: 24, train_loss: 0.016874601539128866, valid_loss: 0.01831426634453237\n",
      "EPOCH: 25, train_loss: 0.01626418901082033, valid_loss: 0.018204459454864264\n",
      "EPOCH: 26, train_loss: 0.015766506405690543, valid_loss: 0.01828439813107252\n",
      "EPOCH: 27, train_loss: 0.01525404677989009, valid_loss: 0.01830333494581282\n",
      "EPOCH: 28, train_loss: 0.014941809173577871, valid_loss: 0.01832623966038227\n",
      "EPOCH: 29, train_loss: 0.014781887941540051, valid_loss: 0.018333944492042065\n",
      "FOLD: 6\n",
      "EPOCH: 0, train_loss: 0.6587300289135712, valid_loss: 0.27344830706715584\n",
      "EPOCH: 1, train_loss: 0.05732129466457245, valid_loss: 0.020971646066755056\n",
      "EPOCH: 2, train_loss: 0.022702837124084815, valid_loss: 0.019209084566682577\n",
      "EPOCH: 3, train_loss: 0.02183183705290923, valid_loss: 0.019199079601094127\n",
      "EPOCH: 4, train_loss: 0.020920507824764803, valid_loss: 0.017951173707842827\n",
      "EPOCH: 5, train_loss: 0.020199331526572887, valid_loss: 0.017800390487536788\n",
      "EPOCH: 6, train_loss: 0.019966969290413916, valid_loss: 0.01754118362441659\n",
      "EPOCH: 7, train_loss: 0.019914793375975046, valid_loss: 0.017464337404817343\n",
      "EPOCH: 8, train_loss: 0.019863314902744234, valid_loss: 0.017550777876749635\n",
      "EPOCH: 9, train_loss: 0.01981995913844842, valid_loss: 0.017947223503142595\n",
      "EPOCH: 10, train_loss: 0.019782940713832013, valid_loss: 0.01751220365986228\n",
      "EPOCH: 11, train_loss: 0.01973395995222605, valid_loss: 0.017724804813042283\n",
      "EPOCH: 12, train_loss: 0.01965269312644616, valid_loss: 0.01760013261809945\n",
      "EPOCH: 13, train_loss: 0.019630223894730594, valid_loss: 0.017602802254259586\n",
      "EPOCH: 14, train_loss: 0.019490322313056543, valid_loss: 0.017470429185777903\n",
      "EPOCH: 15, train_loss: 0.01939779610779041, valid_loss: 0.017354120034724474\n",
      "EPOCH: 16, train_loss: 0.019248215505518973, valid_loss: 0.017478954512625933\n",
      "EPOCH: 17, train_loss: 0.01917397531752403, valid_loss: 0.01737562078051269\n",
      "EPOCH: 18, train_loss: 0.01901266838495548, valid_loss: 0.01727412547916174\n",
      "EPOCH: 19, train_loss: 0.01873650746897627, valid_loss: 0.01740393554791808\n",
      "EPOCH: 20, train_loss: 0.018607977968760025, valid_loss: 0.017163521610200405\n",
      "EPOCH: 21, train_loss: 0.018257230281447753, valid_loss: 0.01710212859325111\n",
      "EPOCH: 22, train_loss: 0.017915894611714743, valid_loss: 0.017039588652551174\n",
      "EPOCH: 23, train_loss: 0.017502174402276676, valid_loss: 0.0171648096293211\n",
      "EPOCH: 24, train_loss: 0.01704849964246536, valid_loss: 0.017085487488657236\n",
      "EPOCH: 25, train_loss: 0.01651591558057146, valid_loss: 0.01716773770749569\n",
      "EPOCH: 26, train_loss: 0.015948861515006192, valid_loss: 0.017160427989438176\n",
      "EPOCH: 27, train_loss: 0.01548496242134999, valid_loss: 0.017228334210813046\n",
      "EPOCH: 28, train_loss: 0.015176493256615523, valid_loss: 0.017252865247428417\n",
      "EPOCH: 29, train_loss: 0.015026894266693255, valid_loss: 0.017241172026842833\n",
      "FOLD: 7\n",
      "EPOCH: 0, train_loss: 0.6559694258472587, valid_loss: 0.26637832820415497\n",
      "EPOCH: 1, train_loss: 0.05484346632810333, valid_loss: 0.020622413605451584\n",
      "EPOCH: 2, train_loss: 0.02280299688536155, valid_loss: 0.019817833555862308\n",
      "EPOCH: 3, train_loss: 0.02279332042023351, valid_loss: 0.05862677842378616\n",
      "EPOCH: 4, train_loss: 0.026879684103629255, valid_loss: 0.019740895833820105\n",
      "EPOCH: 5, train_loss: 0.022478280895495716, valid_loss: 0.01878572953864932\n",
      "EPOCH: 6, train_loss: 0.021656416380141354, valid_loss: 0.018332019681110978\n",
      "EPOCH: 7, train_loss: 0.021151973264692706, valid_loss: 0.018246603664010763\n",
      "EPOCH: 8, train_loss: 0.020751482512377486, valid_loss: 0.018308738945052028\n",
      "EPOCH: 9, train_loss: 0.020683534702734103, valid_loss: 0.018090412486344576\n",
      "EPOCH: 10, train_loss: 0.020481013751859907, valid_loss: 0.018068006727844477\n",
      "EPOCH: 11, train_loss: 0.020208703283267685, valid_loss: 0.017953321104869246\n",
      "EPOCH: 12, train_loss: 0.02021544749695289, valid_loss: 0.01805128436535597\n",
      "EPOCH: 13, train_loss: 0.0202082210939519, valid_loss: 0.018027508398517966\n",
      "EPOCH: 14, train_loss: 0.02006738390066201, valid_loss: 0.01767000835388899\n",
      "EPOCH: 15, train_loss: 0.01988907233823704, valid_loss: 0.017636426724493504\n",
      "EPOCH: 16, train_loss: 0.019662977443842947, valid_loss: 0.01758903660811484\n",
      "EPOCH: 17, train_loss: 0.019499352531908435, valid_loss: 0.01773669058457017\n",
      "EPOCH: 18, train_loss: 0.019307083579935606, valid_loss: 0.017574043944478035\n",
      "EPOCH: 19, train_loss: 0.019115101404582398, valid_loss: 0.01763202645815909\n",
      "EPOCH: 20, train_loss: 0.018945616611008402, valid_loss: 0.017457287292927504\n",
      "EPOCH: 21, train_loss: 0.018755772657975366, valid_loss: 0.017435824498534203\n",
      "EPOCH: 22, train_loss: 0.01843091359809984, valid_loss: 0.01741681690327823\n",
      "EPOCH: 23, train_loss: 0.01798850279065627, valid_loss: 0.017432702239602804\n",
      "EPOCH: 24, train_loss: 0.017447177815852286, valid_loss: 0.017459914786741138\n",
      "EPOCH: 25, train_loss: 0.016998535894517657, valid_loss: 0.01745301717892289\n",
      "EPOCH: 26, train_loss: 0.016520777929432785, valid_loss: 0.017441088566556573\n",
      "EPOCH: 27, train_loss: 0.016313143793634976, valid_loss: 0.01741785812191665\n",
      "EPOCH: 28, train_loss: 0.015864501330011254, valid_loss: 0.017468552105128765\n",
      "EPOCH: 29, train_loss: 0.015647654362683054, valid_loss: 0.017463156022131443\n",
      "FOLD: 8\n",
      "EPOCH: 0, train_loss: 0.6568918484675733, valid_loss: 0.26013023778796196\n",
      "EPOCH: 1, train_loss: 0.05569526595594008, valid_loss: 0.02027710061520338\n",
      "EPOCH: 2, train_loss: 0.022718491857942148, valid_loss: 0.018564823316410184\n",
      "EPOCH: 3, train_loss: 0.021805867222668248, valid_loss: 0.019602159736678004\n",
      "EPOCH: 4, train_loss: 0.02099906832356996, valid_loss: 0.01775381457991898\n",
      "EPOCH: 5, train_loss: 0.02030970238715033, valid_loss: 0.018699058797210455\n",
      "EPOCH: 6, train_loss: 0.020260398830228215, valid_loss: 0.017437534406781197\n",
      "EPOCH: 7, train_loss: 0.02001131656049173, valid_loss: 0.018225525273010135\n",
      "EPOCH: 8, train_loss: 0.019798314552518386, valid_loss: 0.017234943457879126\n",
      "EPOCH: 9, train_loss: 0.01985383342621447, valid_loss: 0.017547789844684303\n",
      "EPOCH: 10, train_loss: 0.019716739324452, valid_loss: 0.017266335897147655\n",
      "EPOCH: 11, train_loss: 0.019791058394350584, valid_loss: 0.017637429991737008\n",
      "EPOCH: 12, train_loss: 0.01986477325988721, valid_loss: 0.01747669547330588\n",
      "EPOCH: 13, train_loss: 0.01973811459220663, valid_loss: 0.017032364034093916\n",
      "EPOCH: 14, train_loss: 0.019571561672830882, valid_loss: 0.017182504292577505\n",
      "EPOCH: 15, train_loss: 0.019539284684895714, valid_loss: 0.016831278335303068\n",
      "EPOCH: 16, train_loss: 0.01930045160830398, valid_loss: 0.017122842487879097\n",
      "EPOCH: 17, train_loss: 0.01930585788869405, valid_loss: 0.017009350354783237\n",
      "EPOCH: 18, train_loss: 0.019132674777809576, valid_loss: 0.016974096884950995\n",
      "EPOCH: 19, train_loss: 0.01894980221043659, valid_loss: 0.01692437077872455\n",
      "EPOCH: 20, train_loss: 0.018757958955402616, valid_loss: 0.0167309531243518\n",
      "EPOCH: 21, train_loss: 0.01855434192038035, valid_loss: 0.016780523117631674\n",
      "EPOCH: 22, train_loss: 0.018127441241205494, valid_loss: 0.01684416609350592\n",
      "EPOCH: 23, train_loss: 0.017807315846409977, valid_loss: 0.016956249717622995\n",
      "EPOCH: 24, train_loss: 0.01729787210639142, valid_loss: 0.01685432658996433\n",
      "EPOCH: 25, train_loss: 0.016875591918920414, valid_loss: 0.016874723485670984\n",
      "EPOCH: 26, train_loss: 0.01641888310543344, valid_loss: 0.016847862163558602\n",
      "EPOCH: 27, train_loss: 0.015972872783394553, valid_loss: 0.01689213828649372\n",
      "EPOCH: 28, train_loss: 0.015676830329378194, valid_loss: 0.016965916962362826\n",
      "EPOCH: 29, train_loss: 0.015556694527121284, valid_loss: 0.0169353315141052\n",
      "FOLD: 9\n",
      "EPOCH: 0, train_loss: 0.6577327956881704, valid_loss: 0.28259843587875366\n",
      "EPOCH: 1, train_loss: 0.056333739970681036, valid_loss: 0.020897048292681575\n",
      "EPOCH: 2, train_loss: 0.023123972047167488, valid_loss: 0.021035858662799\n",
      "EPOCH: 3, train_loss: 0.022078485664310334, valid_loss: 0.019668535329401493\n",
      "EPOCH: 4, train_loss: 0.02142858967373643, valid_loss: 0.01832557306624949\n",
      "EPOCH: 5, train_loss: 0.020665720046226736, valid_loss: 0.020210002548992634\n",
      "EPOCH: 6, train_loss: 0.020433689644442327, valid_loss: 0.01785910571925342\n",
      "EPOCH: 7, train_loss: 0.020058176256244696, valid_loss: 0.017684130696579814\n",
      "EPOCH: 8, train_loss: 0.020117968509468852, valid_loss: 0.01783652394078672\n",
      "EPOCH: 9, train_loss: 0.019965671120753772, valid_loss: 0.017741627292707562\n",
      "EPOCH: 10, train_loss: 0.019807630560443372, valid_loss: 0.01754997600801289\n",
      "EPOCH: 11, train_loss: 0.019796594034267378, valid_loss: 0.017481817165389657\n",
      "EPOCH: 12, train_loss: 0.01981685968422437, valid_loss: 0.01764086098410189\n",
      "EPOCH: 13, train_loss: 0.01998926894857159, valid_loss: 0.01745752664282918\n",
      "EPOCH: 14, train_loss: 0.019771662151700335, valid_loss: 0.017265882808715105\n",
      "EPOCH: 15, train_loss: 0.019675569160829617, valid_loss: 0.01765851373784244\n",
      "EPOCH: 16, train_loss: 0.019744010995837707, valid_loss: 0.017765969969332218\n",
      "EPOCH: 17, train_loss: 0.019405779051535493, valid_loss: 0.017131609842181206\n",
      "EPOCH: 18, train_loss: 0.01901161060020139, valid_loss: 0.016898843459784985\n",
      "EPOCH: 19, train_loss: 0.018951196977986567, valid_loss: 0.017042197985574603\n",
      "EPOCH: 20, train_loss: 0.018747399761518346, valid_loss: 0.016909752506762743\n",
      "EPOCH: 21, train_loss: 0.018525442957312246, valid_loss: 0.016865672077983618\n",
      "EPOCH: 22, train_loss: 0.018166443580596506, valid_loss: 0.01694834348745644\n",
      "EPOCH: 23, train_loss: 0.018147980912199504, valid_loss: 0.017034619115293026\n",
      "EPOCH: 24, train_loss: 0.01767776449081264, valid_loss: 0.016847759834490716\n",
      "EPOCH: 25, train_loss: 0.01743018258174386, valid_loss: 0.01681052823550999\n",
      "EPOCH: 26, train_loss: 0.0168461624202849, valid_loss: 0.01683014410082251\n",
      "EPOCH: 27, train_loss: 0.016520785061713263, valid_loss: 0.016817825846374035\n",
      "EPOCH: 28, train_loss: 0.016393157842132865, valid_loss: 0.016837577451951802\n",
      "EPOCH: 29, train_loss: 0.016355579612847372, valid_loss: 0.0168010585475713\n",
      "FOLD: 10\n",
      "EPOCH: 0, train_loss: 0.6582013013271185, valid_loss: 0.2796136364340782\n",
      "EPOCH: 1, train_loss: 0.05647726287730993, valid_loss: 0.021094301715493202\n",
      "EPOCH: 2, train_loss: 0.022652205820075978, valid_loss: 0.01910059479996562\n",
      "EPOCH: 3, train_loss: 0.021358274090557527, valid_loss: 0.018211357528343797\n",
      "EPOCH: 4, train_loss: 0.020730992110493857, valid_loss: 0.027821948053315282\n",
      "EPOCH: 5, train_loss: 0.02064379309423459, valid_loss: 0.01760806585662067\n",
      "EPOCH: 6, train_loss: 0.020037305302535877, valid_loss: 0.01744553353637457\n",
      "EPOCH: 7, train_loss: 0.01989286746352147, valid_loss: 0.017772441497072577\n",
      "EPOCH: 8, train_loss: 0.019869958337109823, valid_loss: 0.01735029648989439\n",
      "EPOCH: 9, train_loss: 0.019822737775169887, valid_loss: 0.017366494052112103\n",
      "EPOCH: 10, train_loss: 0.01974889803200196, valid_loss: 0.017445473233237863\n",
      "EPOCH: 11, train_loss: 0.019725020330112714, valid_loss: 0.017494417494162917\n",
      "EPOCH: 12, train_loss: 0.01968641175578038, valid_loss: 0.017328148474916816\n",
      "EPOCH: 13, train_loss: 0.019550757793088753, valid_loss: 0.017279507825151086\n",
      "EPOCH: 14, train_loss: 0.019450039435655642, valid_loss: 0.01749856793321669\n",
      "EPOCH: 15, train_loss: 0.019439846062316343, valid_loss: 0.01755937491543591\n",
      "EPOCH: 16, train_loss: 0.019341690203127187, valid_loss: 0.017196632456034422\n",
      "EPOCH: 17, train_loss: 0.019208335628112156, valid_loss: 0.017198041547089815\n",
      "EPOCH: 18, train_loss: 0.019020631192968443, valid_loss: 0.017097901785746217\n",
      "EPOCH: 19, train_loss: 0.018773166080697987, valid_loss: 0.017099143005907536\n",
      "EPOCH: 20, train_loss: 0.018569136038422585, valid_loss: 0.017180082155391574\n",
      "EPOCH: 21, train_loss: 0.018284724810375616, valid_loss: 0.017034736461937428\n",
      "EPOCH: 22, train_loss: 0.017951354050101377, valid_loss: 0.01700130756944418\n",
      "EPOCH: 23, train_loss: 0.017569319762958165, valid_loss: 0.017033351119607687\n",
      "EPOCH: 24, train_loss: 0.01704213345566621, valid_loss: 0.017149006947875023\n",
      "EPOCH: 25, train_loss: 0.0165273634931789, valid_loss: 0.01699522929266095\n",
      "EPOCH: 26, train_loss: 0.01593942658450359, valid_loss: 0.017000262392684817\n",
      "EPOCH: 27, train_loss: 0.015412379808437366, valid_loss: 0.017061407444998622\n",
      "EPOCH: 28, train_loss: 0.015118867445450563, valid_loss: 0.01709301071241498\n",
      "EPOCH: 29, train_loss: 0.01499829301610589, valid_loss: 0.017089034197852015\n",
      "SEED: 2020\n",
      "FOLD: 0\n",
      "EPOCH: 0, train_loss: 0.6592106192539899, valid_loss: 0.28423628583550453\n",
      "EPOCH: 1, train_loss: 0.05703995546373802, valid_loss: 0.0211190867703408\n",
      "EPOCH: 2, train_loss: 0.022617440599088486, valid_loss: 0.019347626017406583\n",
      "EPOCH: 3, train_loss: 0.021503682654255476, valid_loss: 0.018237153301015496\n",
      "EPOCH: 4, train_loss: 0.021369568908061735, valid_loss: 0.018090003402903676\n",
      "EPOCH: 5, train_loss: 0.020276844525375426, valid_loss: 0.017497857101261616\n",
      "EPOCH: 6, train_loss: 0.02004579956141802, valid_loss: 0.017677412601187825\n",
      "EPOCH: 7, train_loss: 0.019906949419050645, valid_loss: 0.017645667772740126\n",
      "EPOCH: 8, train_loss: 0.019854858684807252, valid_loss: 0.01775988284498453\n",
      "EPOCH: 9, train_loss: 0.019805609726179868, valid_loss: 0.01780646899715066\n",
      "EPOCH: 10, train_loss: 0.01976490658349716, valid_loss: 0.017534363782033324\n",
      "EPOCH: 11, train_loss: 0.019695220419611685, valid_loss: 0.017461162758991122\n",
      "EPOCH: 12, train_loss: 0.019617595088978607, valid_loss: 0.017559454776346684\n",
      "EPOCH: 13, train_loss: 0.019601553057630856, valid_loss: 0.01753390464000404\n",
      "EPOCH: 14, train_loss: 0.019545250643904392, valid_loss: 0.01749625732190907\n",
      "EPOCH: 15, train_loss: 0.019452590590868242, valid_loss: 0.017342641134746373\n",
      "EPOCH: 16, train_loss: 0.019286741956304282, valid_loss: 0.017493989318609238\n",
      "EPOCH: 17, train_loss: 0.019200170961901162, valid_loss: 0.01740187988616526\n",
      "EPOCH: 18, train_loss: 0.019021548927785493, valid_loss: 0.017374586896039546\n",
      "EPOCH: 19, train_loss: 0.018806762253053676, valid_loss: 0.017258708248846233\n",
      "EPOCH: 20, train_loss: 0.018554264918351784, valid_loss: 0.017298165243119\n",
      "EPOCH: 21, train_loss: 0.018298397676493876, valid_loss: 0.0171959912404418\n",
      "EPOCH: 22, train_loss: 0.01797520498243662, valid_loss: 0.01711989496834576\n",
      "EPOCH: 23, train_loss: 0.017534055197850253, valid_loss: 0.017114520887844265\n",
      "EPOCH: 24, train_loss: 0.017033956586741485, valid_loss: 0.017034202232025564\n",
      "EPOCH: 25, train_loss: 0.016516968201941404, valid_loss: 0.017073282739147544\n",
      "EPOCH: 26, train_loss: 0.01594366152317096, valid_loss: 0.017176279332488775\n",
      "EPOCH: 27, train_loss: 0.015498041987228088, valid_loss: 0.017199904075823724\n",
      "EPOCH: 28, train_loss: 0.015159658120515255, valid_loss: 0.0172103235963732\n",
      "EPOCH: 29, train_loss: 0.015015843766144453, valid_loss: 0.01722277607768774\n",
      "FOLD: 1\n",
      "EPOCH: 0, train_loss: 0.6577752217268332, valid_loss: 0.2709152474999428\n",
      "EPOCH: 1, train_loss: 0.05646558094005554, valid_loss: 0.02086763666011393\n",
      "EPOCH: 2, train_loss: 0.022745373993156813, valid_loss: 0.019862865330651402\n",
      "EPOCH: 3, train_loss: 0.02182926891896969, valid_loss: 0.03100780537351966\n",
      "EPOCH: 4, train_loss: 0.02100472450733949, valid_loss: 0.017991971224546432\n",
      "EPOCH: 5, train_loss: 0.02035852851202855, valid_loss: 0.017614987213164568\n",
      "EPOCH: 6, train_loss: 0.02005654463592248, valid_loss: 0.018093343125656247\n",
      "EPOCH: 7, train_loss: 0.01995604671537876, valid_loss: 0.017810772638767958\n",
      "EPOCH: 8, train_loss: 0.019868522118299436, valid_loss: 0.017679092474281788\n",
      "EPOCH: 9, train_loss: 0.01989793994774421, valid_loss: 0.01799682225100696\n",
      "EPOCH: 10, train_loss: 0.019785280339419842, valid_loss: 0.017917944816872478\n",
      "EPOCH: 11, train_loss: 0.01976339748272529, valid_loss: 0.01761701120994985\n",
      "EPOCH: 12, train_loss: 0.01970008772630722, valid_loss: 0.017612942028790712\n",
      "EPOCH: 13, train_loss: 0.01961237130065759, valid_loss: 0.017706868005916476\n",
      "EPOCH: 14, train_loss: 0.019510449793858405, valid_loss: 0.017389059299603105\n",
      "EPOCH: 15, train_loss: 0.019428211455352794, valid_loss: 0.017478021793067455\n",
      "EPOCH: 16, train_loss: 0.019308547178904217, valid_loss: 0.017491595121100545\n",
      "EPOCH: 17, train_loss: 0.019234153346564524, valid_loss: 0.017229159828275442\n",
      "EPOCH: 18, train_loss: 0.019020470241323497, valid_loss: 0.017403576290234923\n",
      "EPOCH: 19, train_loss: 0.018848551246218193, valid_loss: 0.017251143231987953\n",
      "EPOCH: 20, train_loss: 0.018572770656110384, valid_loss: 0.01719210227020085\n",
      "EPOCH: 21, train_loss: 0.018318072773325138, valid_loss: 0.017349454574286938\n",
      "EPOCH: 22, train_loss: 0.017977636737319138, valid_loss: 0.017200575908645988\n",
      "EPOCH: 23, train_loss: 0.017533019937288303, valid_loss: 0.017356703290715814\n",
      "EPOCH: 24, train_loss: 0.017099968324869107, valid_loss: 0.01729971240274608\n",
      "EPOCH: 25, train_loss: 0.016554505815013096, valid_loss: 0.017396493814885616\n",
      "EPOCH: 26, train_loss: 0.016016002505635604, valid_loss: 0.017379892989993095\n",
      "EPOCH: 27, train_loss: 0.01551759010180831, valid_loss: 0.01738395099528134\n",
      "EPOCH: 28, train_loss: 0.01522649522536458, valid_loss: 0.01740483776666224\n",
      "EPOCH: 29, train_loss: 0.01509293062516894, valid_loss: 0.01740648248232901\n",
      "FOLD: 2\n",
      "EPOCH: 0, train_loss: 0.6594584183051035, valid_loss: 0.27971333637833595\n",
      "EPOCH: 1, train_loss: 0.05754524170874785, valid_loss: 0.021058604586869478\n",
      "EPOCH: 2, train_loss: 0.022795076792438824, valid_loss: 0.019297916442155838\n",
      "EPOCH: 3, train_loss: 0.021499449769273784, valid_loss: 0.01838097651489079\n",
      "EPOCH: 4, train_loss: 0.020667720466661148, valid_loss: 0.01878616469912231\n",
      "EPOCH: 5, train_loss: 0.020280074328184128, valid_loss: 0.018059530295431614\n",
      "EPOCH: 6, train_loss: 0.020042413988938697, valid_loss: 0.018103531561791897\n",
      "EPOCH: 7, train_loss: 0.019908727289965518, valid_loss: 0.018252408131957054\n",
      "EPOCH: 8, train_loss: 0.019806709355459765, valid_loss: 0.018023809185251594\n",
      "EPOCH: 9, train_loss: 0.019797225626042254, valid_loss: 0.01804604404605925\n",
      "EPOCH: 10, train_loss: 0.019757275971082542, valid_loss: 0.018104609567672014\n",
      "EPOCH: 11, train_loss: 0.019671518618288714, valid_loss: 0.017927938140928745\n",
      "EPOCH: 12, train_loss: 0.0195744605973745, valid_loss: 0.01801250339485705\n",
      "EPOCH: 13, train_loss: 0.019514647121421803, valid_loss: 0.017877984093502164\n",
      "EPOCH: 14, train_loss: 0.019427482205896806, valid_loss: 0.01788527495227754\n",
      "EPOCH: 15, train_loss: 0.019333214045335084, valid_loss: 0.01791298808529973\n",
      "EPOCH: 16, train_loss: 0.0192809101098623, valid_loss: 0.017553889891132712\n",
      "EPOCH: 17, train_loss: 0.019110885735314626, valid_loss: 0.01764145609922707\n",
      "EPOCH: 18, train_loss: 0.018932373501742497, valid_loss: 0.017823185306042433\n",
      "EPOCH: 19, train_loss: 0.018735208835166235, valid_loss: 0.017651471309363842\n",
      "EPOCH: 20, train_loss: 0.018473125946445342, valid_loss: 0.01761632366105914\n",
      "EPOCH: 21, train_loss: 0.018174036740301512, valid_loss: 0.017697328701615334\n",
      "EPOCH: 22, train_loss: 0.017888813494489744, valid_loss: 0.017544417642056942\n",
      "EPOCH: 23, train_loss: 0.01747968487250499, valid_loss: 0.01759365131147206\n",
      "EPOCH: 24, train_loss: 0.01699393493338273, valid_loss: 0.017613840522244573\n",
      "EPOCH: 25, train_loss: 0.016501587600662157, valid_loss: 0.017657674150541425\n",
      "EPOCH: 26, train_loss: 0.016010745476262692, valid_loss: 0.017732887528836727\n",
      "EPOCH: 27, train_loss: 0.015510995943958942, valid_loss: 0.017723346361890435\n",
      "EPOCH: 28, train_loss: 0.015231749520469934, valid_loss: 0.017708257073536515\n",
      "EPOCH: 29, train_loss: 0.015112174376367759, valid_loss: 0.01770272245630622\n",
      "FOLD: 3\n",
      "EPOCH: 0, train_loss: 0.6583952055527613, valid_loss: 0.28520458191633224\n",
      "EPOCH: 1, train_loss: 0.0561817264279876, valid_loss: 0.02099299570545554\n",
      "EPOCH: 2, train_loss: 0.02268863708162919, valid_loss: 0.019779200665652752\n",
      "EPOCH: 3, train_loss: 0.02134743872552346, valid_loss: 0.018938909750431776\n",
      "EPOCH: 4, train_loss: 0.020831503356114413, valid_loss: 0.01811382477171719\n",
      "EPOCH: 5, train_loss: 0.0201411441875956, valid_loss: 0.01823442312888801\n",
      "EPOCH: 6, train_loss: 0.019959462711062186, valid_loss: 0.018149618059396744\n",
      "EPOCH: 7, train_loss: 0.019902958892858945, valid_loss: 0.018188134767115116\n",
      "EPOCH: 8, train_loss: 0.019819114858714435, valid_loss: 0.01791708660311997\n",
      "EPOCH: 9, train_loss: 0.019802966298392184, valid_loss: 0.017909015994518995\n",
      "EPOCH: 10, train_loss: 0.01971333461980789, valid_loss: 0.018354192841798067\n",
      "EPOCH: 11, train_loss: 0.019753526251476545, valid_loss: 0.017734345281496644\n",
      "EPOCH: 12, train_loss: 0.01961502086562224, valid_loss: 0.018003680044785142\n",
      "EPOCH: 13, train_loss: 0.01960442945934259, valid_loss: 0.017857534578070045\n",
      "EPOCH: 14, train_loss: 0.019544230463604133, valid_loss: 0.01769512635655701\n",
      "EPOCH: 15, train_loss: 0.01941579291358208, valid_loss: 0.017547463299706578\n",
      "EPOCH: 16, train_loss: 0.0192900664674548, valid_loss: 0.01761508290655911\n",
      "EPOCH: 17, train_loss: 0.019159681163728237, valid_loss: 0.017547406256198883\n",
      "EPOCH: 18, train_loss: 0.018980825988528054, valid_loss: 0.01779403304681182\n",
      "EPOCH: 19, train_loss: 0.0188314332268559, valid_loss: 0.017428386956453323\n",
      "EPOCH: 20, train_loss: 0.018590646700408213, valid_loss: 0.01732066972181201\n",
      "EPOCH: 21, train_loss: 0.018312047593868695, valid_loss: 0.017381006386131048\n",
      "EPOCH: 22, train_loss: 0.017966036756451313, valid_loss: 0.01736145978793502\n",
      "EPOCH: 23, train_loss: 0.01755046245092765, valid_loss: 0.01730550522916019\n",
      "EPOCH: 24, train_loss: 0.017111791655994378, valid_loss: 0.017338682897388935\n",
      "EPOCH: 25, train_loss: 0.016561392217110366, valid_loss: 0.01736689079552889\n",
      "EPOCH: 26, train_loss: 0.016040525040947474, valid_loss: 0.017393752932548523\n",
      "EPOCH: 27, train_loss: 0.015550712326493783, valid_loss: 0.017364206491038203\n",
      "EPOCH: 28, train_loss: 0.015242922800378157, valid_loss: 0.017355127492919564\n",
      "EPOCH: 29, train_loss: 0.015096367002488712, valid_loss: 0.017373665468767285\n",
      "FOLD: 4\n",
      "EPOCH: 0, train_loss: 0.6584949695911163, valid_loss: 0.2705600745975971\n",
      "EPOCH: 1, train_loss: 0.05655151416953558, valid_loss: 0.02105948026292026\n",
      "EPOCH: 2, train_loss: 0.02272870706824156, valid_loss: 0.02033811598084867\n",
      "EPOCH: 3, train_loss: 0.021503392009972, valid_loss: 0.01817879779264331\n",
      "EPOCH: 4, train_loss: 0.020671884099451397, valid_loss: 0.01793000102043152\n",
      "EPOCH: 5, train_loss: 0.020137895400134418, valid_loss: 0.017740770941600204\n",
      "EPOCH: 6, train_loss: 0.020079635131435517, valid_loss: 0.017486944561824203\n",
      "EPOCH: 7, train_loss: 0.01992978583066127, valid_loss: 0.017711407970637083\n",
      "EPOCH: 8, train_loss: 0.01982013327188981, valid_loss: 0.017645774642005563\n",
      "EPOCH: 9, train_loss: 0.019804482825864583, valid_loss: 0.01758895325474441\n",
      "EPOCH: 10, train_loss: 0.019732038896435346, valid_loss: 0.017570915864780545\n",
      "EPOCH: 11, train_loss: 0.019694824679157674, valid_loss: 0.01728359912522137\n",
      "EPOCH: 12, train_loss: 0.019644938624249056, valid_loss: 0.017465087352320552\n",
      "EPOCH: 13, train_loss: 0.019619044680625964, valid_loss: 0.017445084871724248\n",
      "EPOCH: 14, train_loss: 0.01947046544116277, valid_loss: 0.017406180035322905\n",
      "EPOCH: 15, train_loss: 0.01943311496422841, valid_loss: 0.017533928155899048\n",
      "EPOCH: 16, train_loss: 0.019280551096949823, valid_loss: 0.017197157721966505\n",
      "EPOCH: 17, train_loss: 0.01916224901110698, valid_loss: 0.017228289041668177\n",
      "EPOCH: 18, train_loss: 0.01901524277547231, valid_loss: 0.01719123055227101\n",
      "EPOCH: 19, train_loss: 0.018841848469888553, valid_loss: 0.01698022964410484\n",
      "EPOCH: 20, train_loss: 0.01856699447410229, valid_loss: 0.017008254071697593\n",
      "EPOCH: 21, train_loss: 0.018274488858878613, valid_loss: 0.01694937562569976\n",
      "EPOCH: 22, train_loss: 0.01792708311516505, valid_loss: 0.016987275797873735\n",
      "EPOCH: 23, train_loss: 0.0174868583249358, valid_loss: 0.017026899848133326\n",
      "EPOCH: 24, train_loss: 0.01700755186044635, valid_loss: 0.017022580606862903\n",
      "EPOCH: 25, train_loss: 0.01648566781137234, valid_loss: 0.016957828076556325\n",
      "EPOCH: 26, train_loss: 0.015974808269395277, valid_loss: 0.017044595442712307\n",
      "EPOCH: 27, train_loss: 0.015461857884358138, valid_loss: 0.017096238443627954\n",
      "EPOCH: 28, train_loss: 0.015151284324626127, valid_loss: 0.017114503774791956\n",
      "EPOCH: 29, train_loss: 0.015014594038709616, valid_loss: 0.01710034580901265\n",
      "FOLD: 5\n",
      "EPOCH: 0, train_loss: 0.6577158501515021, valid_loss: 0.28897180035710335\n",
      "EPOCH: 1, train_loss: 0.05673626244354706, valid_loss: 0.023006988922134042\n",
      "EPOCH: 2, train_loss: 0.023021157544392806, valid_loss: 0.019741583382710814\n",
      "EPOCH: 3, train_loss: 0.021492673681141473, valid_loss: 0.025135133182629943\n",
      "EPOCH: 4, train_loss: 0.020831780293239996, valid_loss: 0.0185991944745183\n",
      "EPOCH: 5, train_loss: 0.020294691889713973, valid_loss: 0.018476192839443684\n",
      "EPOCH: 6, train_loss: 0.019984925261292703, valid_loss: 0.01847314415499568\n",
      "EPOCH: 7, train_loss: 0.01986856932918995, valid_loss: 0.018209395464509726\n",
      "EPOCH: 8, train_loss: 0.019779840102180455, valid_loss: 0.018617108231410384\n",
      "EPOCH: 9, train_loss: 0.01972067764458748, valid_loss: 0.01852067932486534\n",
      "EPOCH: 10, train_loss: 0.019603586851213224, valid_loss: 0.01857923506759107\n",
      "EPOCH: 11, train_loss: 0.01959249835747939, valid_loss: 0.017998767318204045\n",
      "EPOCH: 12, train_loss: 0.01956587401815714, valid_loss: 0.01815379154868424\n",
      "EPOCH: 13, train_loss: 0.019525525112373706, valid_loss: 0.018247126834467053\n",
      "EPOCH: 14, train_loss: 0.019513072732549448, valid_loss: 0.018142804270610213\n",
      "EPOCH: 15, train_loss: 0.019389261157275774, valid_loss: 0.01807088009081781\n",
      "EPOCH: 16, train_loss: 0.019270539450912904, valid_loss: 0.018253354588523507\n",
      "EPOCH: 17, train_loss: 0.019073454806437858, valid_loss: 0.018130032112821937\n",
      "EPOCH: 18, train_loss: 0.018964393518100947, valid_loss: 0.01826473162509501\n",
      "EPOCH: 19, train_loss: 0.018771022653732546, valid_loss: 0.018159593921154737\n",
      "EPOCH: 20, train_loss: 0.01849736698353902, valid_loss: 0.018054606160148978\n",
      "EPOCH: 21, train_loss: 0.018220906504071675, valid_loss: 0.018155154073610902\n",
      "EPOCH: 22, train_loss: 0.017907250039757062, valid_loss: 0.018115363316610456\n",
      "EPOCH: 23, train_loss: 0.017506352745187588, valid_loss: 0.018103602109476924\n",
      "EPOCH: 24, train_loss: 0.01701239423635296, valid_loss: 0.01813890039920807\n",
      "EPOCH: 25, train_loss: 0.01650142501323269, valid_loss: 0.018117960542440414\n",
      "EPOCH: 26, train_loss: 0.015981017695501063, valid_loss: 0.018133750651031733\n",
      "EPOCH: 27, train_loss: 0.015524858405861335, valid_loss: 0.01819947105832398\n",
      "EPOCH: 28, train_loss: 0.01522782300479519, valid_loss: 0.01817905972711742\n",
      "EPOCH: 29, train_loss: 0.015092438564468652, valid_loss: 0.018182766158133745\n",
      "FOLD: 6\n",
      "EPOCH: 0, train_loss: 0.6588132029924637, valid_loss: 0.28174132108688354\n",
      "EPOCH: 1, train_loss: 0.056767891614865035, valid_loss: 0.021682380698621273\n",
      "EPOCH: 2, train_loss: 0.022835347562646255, valid_loss: 0.01934657944366336\n",
      "EPOCH: 3, train_loss: 0.02154236764479906, valid_loss: 0.018208203138783574\n",
      "EPOCH: 4, train_loss: 0.020790964890366945, valid_loss: 0.017978863092139363\n",
      "EPOCH: 5, train_loss: 0.020204917193414308, valid_loss: 0.01774481311440468\n",
      "EPOCH: 6, train_loss: 0.02009356552018569, valid_loss: 0.017865957925096154\n",
      "EPOCH: 7, train_loss: 0.019972805506907977, valid_loss: 0.017735748318955302\n",
      "EPOCH: 8, train_loss: 0.019846856355285034, valid_loss: 0.01785664795897901\n",
      "EPOCH: 9, train_loss: 0.019834103492590096, valid_loss: 0.01768356841057539\n",
      "EPOCH: 10, train_loss: 0.019771840256185103, valid_loss: 0.01779486588202417\n",
      "EPOCH: 11, train_loss: 0.019715945093104474, valid_loss: 0.017510993173345923\n",
      "EPOCH: 12, train_loss: 0.019689821996367894, valid_loss: 0.017450107028707862\n",
      "EPOCH: 13, train_loss: 0.01961997318535279, valid_loss: 0.01747836614958942\n",
      "EPOCH: 14, train_loss: 0.019563227653121337, valid_loss: 0.017509519821032882\n",
      "EPOCH: 15, train_loss: 0.0195384997014816, valid_loss: 0.017323314445093274\n",
      "EPOCH: 16, train_loss: 0.01932541775302245, valid_loss: 0.017373097827658057\n",
      "EPOCH: 17, train_loss: 0.019217778498736713, valid_loss: 0.01720416243188083\n",
      "EPOCH: 18, train_loss: 0.01910170239324753, valid_loss: 0.017199212918058038\n",
      "EPOCH: 19, train_loss: 0.01887579372104926, valid_loss: 0.01716943783685565\n",
      "EPOCH: 20, train_loss: 0.018631794346639745, valid_loss: 0.0170233272947371\n",
      "EPOCH: 21, train_loss: 0.018379658818818055, valid_loss: 0.017170215025544167\n",
      "EPOCH: 22, train_loss: 0.018066624872004375, valid_loss: 0.017121104057878256\n",
      "EPOCH: 23, train_loss: 0.017652378990673102, valid_loss: 0.017086045118048787\n",
      "EPOCH: 24, train_loss: 0.01716590142593934, valid_loss: 0.01714440598152578\n",
      "EPOCH: 25, train_loss: 0.01667842242675714, valid_loss: 0.017114953137934208\n",
      "EPOCH: 26, train_loss: 0.016222390226828746, valid_loss: 0.017090662149712443\n",
      "EPOCH: 27, train_loss: 0.015789294770608347, valid_loss: 0.017126582795754075\n",
      "EPOCH: 28, train_loss: 0.015484979423956994, valid_loss: 0.01715573575347662\n",
      "EPOCH: 29, train_loss: 0.015382212706101246, valid_loss: 0.017163618467748165\n",
      "FOLD: 7\n",
      "EPOCH: 0, train_loss: 0.6581039021286783, valid_loss: 0.2915487699210644\n",
      "EPOCH: 1, train_loss: 0.05669686264252361, valid_loss: 0.021726613165810704\n",
      "EPOCH: 2, train_loss: 0.02299182972858978, valid_loss: 0.02076852135360241\n",
      "EPOCH: 3, train_loss: 0.021739038296892672, valid_loss: 0.018961394671350718\n",
      "EPOCH: 4, train_loss: 0.02125243043314807, valid_loss: 0.03125686198472977\n",
      "EPOCH: 5, train_loss: 0.021573583890177026, valid_loss: 0.019153186585754156\n",
      "EPOCH: 6, train_loss: 0.020711726049267794, valid_loss: 0.018078668974339962\n",
      "EPOCH: 7, train_loss: 0.020238866781980933, valid_loss: 0.018005992518737912\n",
      "EPOCH: 8, train_loss: 0.02020252642186382, valid_loss: 0.018651240738108754\n",
      "EPOCH: 9, train_loss: 0.02001880178864621, valid_loss: 0.018306531012058258\n",
      "EPOCH: 10, train_loss: 0.02001631946031806, valid_loss: 0.01776533992961049\n",
      "EPOCH: 11, train_loss: 0.02003851919611798, valid_loss: 0.018079859437420964\n",
      "EPOCH: 12, train_loss: 0.020025478605228134, valid_loss: 0.01753506949171424\n",
      "EPOCH: 13, train_loss: 0.019754303265598756, valid_loss: 0.017738624708727002\n",
      "EPOCH: 14, train_loss: 0.01982662902225422, valid_loss: 0.017689428757876158\n",
      "EPOCH: 15, train_loss: 0.019692553537367267, valid_loss: 0.01765458472073078\n",
      "EPOCH: 16, train_loss: 0.019535110131660594, valid_loss: 0.01770312013104558\n",
      "EPOCH: 17, train_loss: 0.019514885436319098, valid_loss: 0.01758695556782186\n",
      "EPOCH: 18, train_loss: 0.019431100568816632, valid_loss: 0.017538518412038684\n",
      "EPOCH: 19, train_loss: 0.019147217250134373, valid_loss: 0.017507238779217005\n",
      "EPOCH: 20, train_loss: 0.018898579480621635, valid_loss: 0.017456288216635585\n",
      "EPOCH: 21, train_loss: 0.018658524355556393, valid_loss: 0.017468312988057733\n",
      "EPOCH: 22, train_loss: 0.018445647875719434, valid_loss: 0.017349244793877006\n",
      "EPOCH: 23, train_loss: 0.01807714237159566, valid_loss: 0.017347716260701418\n",
      "EPOCH: 24, train_loss: 0.017798010472066795, valid_loss: 0.017489412100985646\n",
      "EPOCH: 25, train_loss: 0.01735744997859001, valid_loss: 0.01743956352584064\n",
      "EPOCH: 26, train_loss: 0.0168251588327598, valid_loss: 0.017529818462207913\n",
      "EPOCH: 27, train_loss: 0.01643482243194233, valid_loss: 0.017511826939880848\n",
      "EPOCH: 28, train_loss: 0.01619847949971504, valid_loss: 0.017545647686347365\n",
      "EPOCH: 29, train_loss: 0.016161402380919156, valid_loss: 0.017541068606078625\n",
      "FOLD: 8\n",
      "EPOCH: 0, train_loss: 0.657226949930191, valid_loss: 0.26861869916319847\n",
      "EPOCH: 1, train_loss: 0.05529263132263588, valid_loss: 0.020742565859109163\n",
      "EPOCH: 2, train_loss: 0.022954036375578447, valid_loss: 0.019952175905928016\n",
      "EPOCH: 3, train_loss: 0.02174869884701469, valid_loss: 0.018652641214430332\n",
      "EPOCH: 4, train_loss: 0.02089714270698119, valid_loss: 0.017544941743835807\n",
      "EPOCH: 5, train_loss: 0.02044862801138359, valid_loss: 0.01770231407135725\n",
      "EPOCH: 6, train_loss: 0.020243317383942725, valid_loss: 0.0172646997962147\n",
      "EPOCH: 7, train_loss: 0.020048647293750242, valid_loss: 0.018287915736436844\n",
      "EPOCH: 8, train_loss: 0.020067220860266986, valid_loss: 0.01738082605879754\n",
      "EPOCH: 9, train_loss: 0.019897922236896768, valid_loss: 0.01755886955652386\n",
      "EPOCH: 10, train_loss: 0.019962375064062166, valid_loss: 0.017203326686285436\n",
      "EPOCH: 11, train_loss: 0.019855822778389424, valid_loss: 0.017124145291745663\n",
      "EPOCH: 12, train_loss: 0.019755988652947584, valid_loss: 0.017126736463978887\n",
      "EPOCH: 13, train_loss: 0.019747658149351047, valid_loss: 0.017179897404275835\n",
      "EPOCH: 14, train_loss: 0.019658187168497075, valid_loss: 0.01697158406022936\n",
      "EPOCH: 15, train_loss: 0.019619163455842418, valid_loss: 0.017250933567993343\n",
      "EPOCH: 16, train_loss: 0.019713324412137648, valid_loss: 0.016911069164052606\n",
      "EPOCH: 17, train_loss: 0.019484473510256298, valid_loss: 0.016946377465501428\n",
      "EPOCH: 18, train_loss: 0.019218860052620308, valid_loss: 0.016785902669653296\n",
      "EPOCH: 19, train_loss: 0.018971840674175493, valid_loss: 0.01691430213395506\n",
      "EPOCH: 20, train_loss: 0.01892935189925417, valid_loss: 0.01693151076324284\n",
      "EPOCH: 21, train_loss: 0.018570642163859136, valid_loss: 0.01692170323804021\n",
      "EPOCH: 22, train_loss: 0.018206544055403034, valid_loss: 0.01687406876590103\n",
      "EPOCH: 23, train_loss: 0.017903622640650485, valid_loss: 0.016846503713168204\n",
      "EPOCH: 24, train_loss: 0.01751219160571883, valid_loss: 0.016890124534256756\n",
      "EPOCH: 25, train_loss: 0.017035527791403517, valid_loss: 0.016883698874153197\n",
      "EPOCH: 26, train_loss: 0.01658266483322729, valid_loss: 0.01691609271802008\n",
      "EPOCH: 27, train_loss: 0.016189074709634238, valid_loss: 0.01695213874336332\n",
      "EPOCH: 28, train_loss: 0.01590836285082977, valid_loss: 0.016908262856304646\n",
      "EPOCH: 29, train_loss: 0.01576235503712787, valid_loss: 0.016943435068242252\n",
      "FOLD: 9\n",
      "EPOCH: 0, train_loss: 0.6560202165494992, valid_loss: 0.2706373520195484\n",
      "EPOCH: 1, train_loss: 0.05643884450951709, valid_loss: 0.0227964511141181\n",
      "EPOCH: 2, train_loss: 0.02521010632096212, valid_loss: 0.02091877907514572\n",
      "EPOCH: 3, train_loss: 0.02293096588853794, valid_loss: 0.019967295695096254\n",
      "EPOCH: 4, train_loss: 0.021934812251902833, valid_loss: 0.019389762077480555\n",
      "EPOCH: 5, train_loss: 0.021389202226566362, valid_loss: 0.020090678241103888\n",
      "EPOCH: 6, train_loss: 0.021136173271114313, valid_loss: 0.018251791829243302\n",
      "EPOCH: 7, train_loss: 0.02090314287645153, valid_loss: 0.018648948520421982\n",
      "EPOCH: 8, train_loss: 0.020735647128541257, valid_loss: 0.018203390995040536\n",
      "EPOCH: 9, train_loss: 0.020575275809704502, valid_loss: 0.018427806673571467\n",
      "EPOCH: 10, train_loss: 0.020635558693092082, valid_loss: 0.01813390082679689\n",
      "EPOCH: 11, train_loss: 0.020355063243002833, valid_loss: 0.017860964173451066\n",
      "EPOCH: 12, train_loss: 0.020224174390299412, valid_loss: 0.017753425054252148\n",
      "EPOCH: 13, train_loss: 0.019918401902423628, valid_loss: 0.01749657024629414\n",
      "EPOCH: 14, train_loss: 0.019928744133514694, valid_loss: 0.018065346870571375\n",
      "EPOCH: 15, train_loss: 0.019855047965162916, valid_loss: 0.017750540049746633\n",
      "EPOCH: 16, train_loss: 0.019555003488365606, valid_loss: 0.017389997374266386\n",
      "EPOCH: 17, train_loss: 0.019391327271167234, valid_loss: 0.01726199360564351\n",
      "EPOCH: 18, train_loss: 0.019159174111636378, valid_loss: 0.01734149898402393\n",
      "EPOCH: 19, train_loss: 0.01897114461075656, valid_loss: 0.01732662506401539\n",
      "EPOCH: 20, train_loss: 0.018734989758533768, valid_loss: 0.017179312650114298\n",
      "EPOCH: 21, train_loss: 0.01840053211095967, valid_loss: 0.017208023462444544\n",
      "EPOCH: 22, train_loss: 0.018264581178185305, valid_loss: 0.017207504715770483\n",
      "EPOCH: 23, train_loss: 0.01775612975647555, valid_loss: 0.017095837043598294\n",
      "EPOCH: 24, train_loss: 0.017191178342209585, valid_loss: 0.01710633561015129\n",
      "EPOCH: 25, train_loss: 0.01689439503876846, valid_loss: 0.017134364927187562\n",
      "EPOCH: 26, train_loss: 0.016458431812875634, valid_loss: 0.017116865376010537\n",
      "EPOCH: 27, train_loss: 0.015922204555967188, valid_loss: 0.01725791720673442\n",
      "EPOCH: 28, train_loss: 0.015530050437473044, valid_loss: 0.01716098957695067\n",
      "EPOCH: 29, train_loss: 0.01550598034658764, valid_loss: 0.017148188082501292\n",
      "FOLD: 10\n",
      "EPOCH: 0, train_loss: 0.6593653345719362, valid_loss: 0.2792344018816948\n",
      "EPOCH: 1, train_loss: 0.05696273977175737, valid_loss: 0.022630159510299563\n",
      "EPOCH: 2, train_loss: 0.02294145491069708, valid_loss: 0.019545969320461154\n",
      "EPOCH: 3, train_loss: 0.021512755455496985, valid_loss: 0.01817254675552249\n",
      "EPOCH: 4, train_loss: 0.02081720609791004, valid_loss: 0.018287165090441704\n",
      "EPOCH: 5, train_loss: 0.020330647317071755, valid_loss: 0.01774557400494814\n",
      "EPOCH: 6, train_loss: 0.020051182677539494, valid_loss: 0.01774260401725769\n",
      "EPOCH: 7, train_loss: 0.01998712819738266, valid_loss: 0.01783933164551854\n",
      "EPOCH: 8, train_loss: 0.019897312690050174, valid_loss: 0.01741334586404264\n",
      "EPOCH: 9, train_loss: 0.019749785630175702, valid_loss: 0.01763117639347911\n",
      "EPOCH: 10, train_loss: 0.019781456352808535, valid_loss: 0.017416195012629032\n",
      "EPOCH: 11, train_loss: 0.019785939644162472, valid_loss: 0.01760830939747393\n",
      "EPOCH: 12, train_loss: 0.019640433602035046, valid_loss: 0.01746148895472288\n",
      "EPOCH: 13, train_loss: 0.019611164640921813, valid_loss: 0.017690016189590096\n",
      "EPOCH: 14, train_loss: 0.019565807321132757, valid_loss: 0.017313403077423573\n",
      "EPOCH: 15, train_loss: 0.019451693536188357, valid_loss: 0.01719907787628472\n",
      "EPOCH: 16, train_loss: 0.01933473262649316, valid_loss: 0.017146827187389135\n",
      "EPOCH: 17, train_loss: 0.01917755503494006, valid_loss: 0.017166096018627286\n",
      "EPOCH: 18, train_loss: 0.019025495872856714, valid_loss: 0.017063620733097196\n",
      "EPOCH: 19, train_loss: 0.01887195848692686, valid_loss: 0.017043912084773183\n",
      "EPOCH: 20, train_loss: 0.018576485654100392, valid_loss: 0.017047581961378455\n",
      "EPOCH: 21, train_loss: 0.018336903065060958, valid_loss: 0.017049641581252217\n",
      "EPOCH: 22, train_loss: 0.017964742767314117, valid_loss: 0.01693751267157495\n",
      "EPOCH: 23, train_loss: 0.017549171064717647, valid_loss: 0.016933390870690346\n",
      "EPOCH: 24, train_loss: 0.01711718451518279, valid_loss: 0.017032614443451166\n",
      "EPOCH: 25, train_loss: 0.016625293649924107, valid_loss: 0.016905902419239283\n",
      "EPOCH: 26, train_loss: 0.016101408212517317, valid_loss: 0.017070814268663526\n",
      "EPOCH: 27, train_loss: 0.015617429863852568, valid_loss: 0.016991496551781893\n",
      "EPOCH: 28, train_loss: 0.015344814672015416, valid_loss: 0.01704247551970184\n",
      "EPOCH: 29, train_loss: 0.015212273738609675, valid_loss: 0.017045211978256702\n",
      "SEED: 567\n",
      "FOLD: 0\n",
      "EPOCH: 0, train_loss: 0.6573107246405039, valid_loss: 0.24514149874448776\n",
      "EPOCH: 1, train_loss: 0.05579161629653894, valid_loss: 0.021139565389603376\n",
      "EPOCH: 2, train_loss: 0.02276298117179137, valid_loss: 0.019718363415449858\n",
      "EPOCH: 3, train_loss: 0.02143078961242468, valid_loss: 0.01881467388011515\n",
      "EPOCH: 4, train_loss: 0.02056174173664588, valid_loss: 0.017933554714545608\n",
      "EPOCH: 5, train_loss: 0.020263751085178975, valid_loss: 0.01766979997046292\n",
      "EPOCH: 6, train_loss: 0.01999458023466361, valid_loss: 0.017831541830673814\n",
      "EPOCH: 7, train_loss: 0.019932659486165412, valid_loss: 0.0176475178450346\n",
      "EPOCH: 8, train_loss: 0.01985932158258481, valid_loss: 0.01788562792353332\n",
      "EPOCH: 9, train_loss: 0.019782429799819604, valid_loss: 0.01744955568574369\n",
      "EPOCH: 10, train_loss: 0.019755761592816085, valid_loss: 0.01746383961290121\n",
      "EPOCH: 11, train_loss: 0.01968268866244799, valid_loss: 0.017614393029361963\n",
      "EPOCH: 12, train_loss: 0.019653040748567153, valid_loss: 0.017456725938245654\n",
      "EPOCH: 13, train_loss: 0.01957226475366415, valid_loss: 0.01736953156068921\n",
      "EPOCH: 14, train_loss: 0.019522351594880607, valid_loss: 0.017389083048328757\n",
      "EPOCH: 15, train_loss: 0.019421897374857694, valid_loss: 0.017569060903042555\n",
      "EPOCH: 16, train_loss: 0.019281712599480763, valid_loss: 0.01728519215248525\n",
      "EPOCH: 17, train_loss: 0.019158606465237264, valid_loss: 0.01746341143734753\n",
      "EPOCH: 18, train_loss: 0.018979504465674743, valid_loss: 0.017413234105333686\n",
      "EPOCH: 19, train_loss: 0.018800020719376895, valid_loss: 0.017313379677943885\n",
      "EPOCH: 20, train_loss: 0.018606849062519196, valid_loss: 0.017393185291439295\n",
      "EPOCH: 21, train_loss: 0.018295544223525584, valid_loss: 0.017435273388400674\n",
      "EPOCH: 22, train_loss: 0.017944269718076937, valid_loss: 0.017252105521038175\n",
      "EPOCH: 23, train_loss: 0.01756988773838832, valid_loss: 0.01723399292677641\n",
      "EPOCH: 24, train_loss: 0.017098120652521268, valid_loss: 0.017209339188411832\n",
      "EPOCH: 25, train_loss: 0.016594855819279566, valid_loss: 0.017241311259567738\n",
      "EPOCH: 26, train_loss: 0.01607381455743542, valid_loss: 0.017258656327612698\n",
      "EPOCH: 27, train_loss: 0.01559977862649621, valid_loss: 0.017267034854739904\n",
      "EPOCH: 28, train_loss: 0.01529775777210792, valid_loss: 0.01731850055512041\n",
      "EPOCH: 29, train_loss: 0.015169281297578262, valid_loss: 0.017305772518739104\n",
      "FOLD: 1\n",
      "EPOCH: 0, train_loss: 0.656110018873826, valid_loss: 0.24629490077495575\n",
      "EPOCH: 1, train_loss: 0.05606507242490084, valid_loss: 0.021024742629379034\n",
      "EPOCH: 2, train_loss: 0.022776486447606333, valid_loss: 0.01936239772476256\n",
      "EPOCH: 3, train_loss: 0.022159362044663, valid_loss: 0.018479645252227783\n",
      "EPOCH: 4, train_loss: 0.020953399654573355, valid_loss: 0.01801202353090048\n",
      "EPOCH: 5, train_loss: 0.02035456212858359, valid_loss: 0.017622173996642232\n",
      "EPOCH: 6, train_loss: 0.020053456752346113, valid_loss: 0.017802068265154958\n",
      "EPOCH: 7, train_loss: 0.02000201782450462, valid_loss: 0.01783270388841629\n",
      "EPOCH: 8, train_loss: 0.019896075344429567, valid_loss: 0.018061497015878558\n",
      "EPOCH: 9, train_loss: 0.019834982111859016, valid_loss: 0.017762940376996994\n",
      "EPOCH: 10, train_loss: 0.019805690464683067, valid_loss: 0.017656499752774835\n",
      "EPOCH: 11, train_loss: 0.019765901474807508, valid_loss: 0.017808929784223437\n",
      "EPOCH: 12, train_loss: 0.01967207994312048, valid_loss: 0.017582946689799428\n",
      "EPOCH: 13, train_loss: 0.019606639893773276, valid_loss: 0.017662172438576818\n",
      "EPOCH: 14, train_loss: 0.019531735481742103, valid_loss: 0.017475104657933116\n",
      "EPOCH: 15, train_loss: 0.019433074845717505, valid_loss: 0.01752773649059236\n",
      "EPOCH: 16, train_loss: 0.01934947668073269, valid_loss: 0.017303718952462077\n",
      "EPOCH: 17, train_loss: 0.01919183349953248, valid_loss: 0.017397132702171803\n",
      "EPOCH: 18, train_loss: 0.019025742983779848, valid_loss: 0.017295451601967216\n",
      "EPOCH: 19, train_loss: 0.01884591405112774, valid_loss: 0.017488251673057675\n",
      "EPOCH: 20, train_loss: 0.018701298998143427, valid_loss: 0.017178931273519993\n",
      "EPOCH: 21, train_loss: 0.018337758329625312, valid_loss: 0.017193087609484792\n",
      "EPOCH: 22, train_loss: 0.018022299266587466, valid_loss: 0.01722447434440255\n",
      "EPOCH: 23, train_loss: 0.01764101962535045, valid_loss: 0.017161708092316985\n",
      "EPOCH: 24, train_loss: 0.01713998193064561, valid_loss: 0.01740769692696631\n",
      "EPOCH: 25, train_loss: 0.016609962766942304, valid_loss: 0.017248159274458885\n",
      "EPOCH: 26, train_loss: 0.01607557076913042, valid_loss: 0.017268261639401317\n",
      "EPOCH: 27, train_loss: 0.015619650817452332, valid_loss: 0.017281648702919483\n",
      "EPOCH: 28, train_loss: 0.015301148108660411, valid_loss: 0.01732915616594255\n",
      "EPOCH: 29, train_loss: 0.015180067983097754, valid_loss: 0.017318385187536478\n",
      "FOLD: 2\n",
      "EPOCH: 0, train_loss: 0.6588438860116861, valid_loss: 0.2722529508173466\n",
      "EPOCH: 1, train_loss: 0.05689119755362089, valid_loss: 0.023140115663409233\n",
      "EPOCH: 2, train_loss: 0.022965264673798513, valid_loss: 0.019198596011847258\n",
      "EPOCH: 3, train_loss: 0.021624996159703303, valid_loss: 0.018370573641732335\n",
      "EPOCH: 4, train_loss: 0.02066046068779169, valid_loss: 0.018431377364322543\n",
      "EPOCH: 5, train_loss: 0.0203492517511432, valid_loss: 0.018417835468426347\n",
      "EPOCH: 6, train_loss: 0.020119105513470296, valid_loss: 0.01806957251392305\n",
      "EPOCH: 7, train_loss: 0.01995023423567032, valid_loss: 0.018350485246628523\n",
      "EPOCH: 8, train_loss: 0.01986646848038221, valid_loss: 0.018237963784486055\n",
      "EPOCH: 9, train_loss: 0.019786894608002443, valid_loss: 0.018021026626229286\n",
      "EPOCH: 10, train_loss: 0.019744905977486037, valid_loss: 0.01776850107125938\n",
      "EPOCH: 11, train_loss: 0.01969715444227824, valid_loss: 0.017745415680110455\n",
      "EPOCH: 12, train_loss: 0.019676134563409366, valid_loss: 0.017623293679207563\n",
      "EPOCH: 13, train_loss: 0.019579846722384293, valid_loss: 0.017709904816001654\n",
      "EPOCH: 14, train_loss: 0.01951564232317301, valid_loss: 0.017730687279254198\n",
      "EPOCH: 15, train_loss: 0.019430931562032454, valid_loss: 0.017794230254366994\n",
      "EPOCH: 16, train_loss: 0.019331764883528918, valid_loss: 0.017741319490596652\n",
      "EPOCH: 17, train_loss: 0.019155035726726055, valid_loss: 0.017579003470018506\n",
      "EPOCH: 18, train_loss: 0.01898444288720687, valid_loss: 0.017542368499562144\n",
      "EPOCH: 19, train_loss: 0.01874510841205334, valid_loss: 0.01788051542825997\n",
      "EPOCH: 20, train_loss: 0.018555834555091, valid_loss: 0.01771026896312833\n",
      "EPOCH: 21, train_loss: 0.018351914647680063, valid_loss: 0.01769055938348174\n",
      "EPOCH: 22, train_loss: 0.01794702774630143, valid_loss: 0.01759228273294866\n",
      "EPOCH: 23, train_loss: 0.01756795837233464, valid_loss: 0.017663156148046255\n",
      "EPOCH: 24, train_loss: 0.01707099837800249, valid_loss: 0.017614019801840186\n",
      "EPOCH: 25, train_loss: 0.016571382514368266, valid_loss: 0.01766187767498195\n",
      "EPOCH: 26, train_loss: 0.01601374437077305, valid_loss: 0.017667042091488838\n",
      "EPOCH: 27, train_loss: 0.0155144352465868, valid_loss: 0.017678163712844253\n",
      "EPOCH: 28, train_loss: 0.015184686423685307, valid_loss: 0.017696538008749485\n",
      "EPOCH: 29, train_loss: 0.015024443276417561, valid_loss: 0.01772601855918765\n",
      "FOLD: 3\n",
      "EPOCH: 0, train_loss: 0.6591232724678822, valid_loss: 0.2471610102802515\n",
      "EPOCH: 1, train_loss: 0.05668048534351282, valid_loss: 0.021286883391439915\n",
      "EPOCH: 2, train_loss: 0.022505761339114264, valid_loss: 0.019322789506986737\n",
      "EPOCH: 3, train_loss: 0.021605981370577447, valid_loss: 0.018841302953660488\n",
      "EPOCH: 4, train_loss: 0.02061157372708504, valid_loss: 0.018348367419093847\n",
      "EPOCH: 5, train_loss: 0.020178518496835843, valid_loss: 0.018060456728562713\n",
      "EPOCH: 6, train_loss: 0.019905827700709686, valid_loss: 0.01783779403194785\n",
      "EPOCH: 7, train_loss: 0.019803249921936255, valid_loss: 0.01789240841753781\n",
      "EPOCH: 8, train_loss: 0.019890680741996337, valid_loss: 0.017820224864408374\n",
      "EPOCH: 9, train_loss: 0.019750689204113606, valid_loss: 0.01810163538902998\n",
      "EPOCH: 10, train_loss: 0.019779773620076668, valid_loss: 0.017879805527627468\n",
      "EPOCH: 11, train_loss: 0.01966613043959324, valid_loss: 0.01763332705013454\n",
      "EPOCH: 12, train_loss: 0.01967914803670003, valid_loss: 0.017980098957195878\n",
      "EPOCH: 13, train_loss: 0.01961257017384737, valid_loss: 0.017725468147546053\n",
      "EPOCH: 14, train_loss: 0.0195570360057247, valid_loss: 0.01739677763544023\n",
      "EPOCH: 15, train_loss: 0.019473633609521084, valid_loss: 0.017553903395310044\n",
      "EPOCH: 16, train_loss: 0.019321120559022978, valid_loss: 0.01750565762631595\n",
      "EPOCH: 17, train_loss: 0.019165323736766975, valid_loss: 0.01752103865146637\n",
      "EPOCH: 18, train_loss: 0.01902333410600057, valid_loss: 0.017671602545306087\n",
      "EPOCH: 19, train_loss: 0.018832874460480153, valid_loss: 0.01751683745533228\n",
      "EPOCH: 20, train_loss: 0.018622635242839653, valid_loss: 0.01742374594323337\n",
      "EPOCH: 21, train_loss: 0.018352875103935216, valid_loss: 0.017384828068315983\n",
      "EPOCH: 22, train_loss: 0.017999868219097454, valid_loss: 0.017290304182097316\n",
      "EPOCH: 23, train_loss: 0.017627662668625515, valid_loss: 0.017356242053210735\n",
      "EPOCH: 24, train_loss: 0.01716224846836084, valid_loss: 0.017362926388159394\n",
      "EPOCH: 25, train_loss: 0.016678635842907123, valid_loss: 0.017343789106234908\n",
      "EPOCH: 26, train_loss: 0.016159095479032166, valid_loss: 0.017397765070199966\n",
      "EPOCH: 27, train_loss: 0.015685408268696986, valid_loss: 0.017450482351705432\n",
      "EPOCH: 28, train_loss: 0.015390143395425418, valid_loss: 0.017419030657038093\n",
      "EPOCH: 29, train_loss: 0.01524695625098852, valid_loss: 0.017427594400942326\n",
      "FOLD: 4\n",
      "EPOCH: 0, train_loss: 0.6580791446642998, valid_loss: 0.27300721034407616\n",
      "EPOCH: 1, train_loss: 0.05698252677057798, valid_loss: 0.02104944665916264\n",
      "EPOCH: 2, train_loss: 0.022726073431280944, valid_loss: 0.019275171915069222\n",
      "EPOCH: 3, train_loss: 0.021482558347857915, valid_loss: 0.018250914989039302\n",
      "EPOCH: 4, train_loss: 0.02078393789438101, valid_loss: 0.017761160153895617\n",
      "EPOCH: 5, train_loss: 0.020449472448000543, valid_loss: 0.018122830893844366\n",
      "EPOCH: 6, train_loss: 0.02008368831892044, valid_loss: 0.017668488901108503\n",
      "EPOCH: 7, train_loss: 0.019888044072267335, valid_loss: 0.017709821229800582\n",
      "EPOCH: 8, train_loss: 0.019927950504307564, valid_loss: 0.017700814409181476\n",
      "EPOCH: 9, train_loss: 0.019783650286113605, valid_loss: 0.017649594694375992\n",
      "EPOCH: 10, train_loss: 0.01973834516814886, valid_loss: 0.017390395049005747\n",
      "EPOCH: 11, train_loss: 0.01969964797489154, valid_loss: 0.01750813494436443\n",
      "EPOCH: 12, train_loss: 0.01963292298695216, valid_loss: 0.017479595262557268\n",
      "EPOCH: 13, train_loss: 0.01962508039119152, valid_loss: 0.01752689713612199\n",
      "EPOCH: 14, train_loss: 0.01957403429043599, valid_loss: 0.01724091707728803\n",
      "EPOCH: 15, train_loss: 0.019491441380710173, valid_loss: 0.017296106088906527\n",
      "EPOCH: 16, train_loss: 0.01930540370253416, valid_loss: 0.0175985312089324\n",
      "EPOCH: 17, train_loss: 0.019228442906378172, valid_loss: 0.017128437757492065\n",
      "EPOCH: 18, train_loss: 0.019041423470928118, valid_loss: 0.017127168830484152\n",
      "EPOCH: 19, train_loss: 0.018817079635575797, valid_loss: 0.017047840636223555\n",
      "EPOCH: 20, train_loss: 0.01854106401785826, valid_loss: 0.017167904181405902\n",
      "EPOCH: 21, train_loss: 0.018354928479171716, valid_loss: 0.017063314095139503\n",
      "EPOCH: 22, train_loss: 0.017949105956806585, valid_loss: 0.017042320920154452\n",
      "EPOCH: 23, train_loss: 0.0175419757142663, valid_loss: 0.016947800759226084\n",
      "EPOCH: 24, train_loss: 0.017049454857046023, valid_loss: 0.01717845187522471\n",
      "EPOCH: 25, train_loss: 0.016587223236759503, valid_loss: 0.01718509173952043\n",
      "EPOCH: 26, train_loss: 0.016076951514547452, valid_loss: 0.01716469065286219\n",
      "EPOCH: 27, train_loss: 0.015622855976032905, valid_loss: 0.017181423492729664\n",
      "EPOCH: 28, train_loss: 0.015290493850047007, valid_loss: 0.01721580559387803\n",
      "EPOCH: 29, train_loss: 0.015202241340795388, valid_loss: 0.017192431492730975\n",
      "FOLD: 5\n",
      "EPOCH: 0, train_loss: 0.6588456592498682, valid_loss: 0.25164713338017464\n",
      "EPOCH: 1, train_loss: 0.05713147436005947, valid_loss: 0.021524124313145876\n",
      "EPOCH: 2, train_loss: 0.022617661824020054, valid_loss: 0.01943219010718167\n",
      "EPOCH: 3, train_loss: 0.021334518511325885, valid_loss: 0.018903510412201285\n",
      "EPOCH: 4, train_loss: 0.02064510193677285, valid_loss: 0.018409522948786616\n",
      "EPOCH: 5, train_loss: 0.020183034885961276, valid_loss: 0.018559121526777744\n",
      "EPOCH: 6, train_loss: 0.02000901327492335, valid_loss: 0.018213520757853985\n",
      "EPOCH: 7, train_loss: 0.019952054016101055, valid_loss: 0.018491710303351283\n",
      "EPOCH: 8, train_loss: 0.019798939331219748, valid_loss: 0.018280536867678165\n",
      "EPOCH: 9, train_loss: 0.01971871243455471, valid_loss: 0.018357485998421907\n",
      "EPOCH: 10, train_loss: 0.01968643394036171, valid_loss: 0.018223563907667994\n",
      "EPOCH: 11, train_loss: 0.019646970053704884, valid_loss: 0.018119393847882748\n",
      "EPOCH: 12, train_loss: 0.019663390130377732, valid_loss: 0.018428870476782322\n",
      "EPOCH: 13, train_loss: 0.019510960588470485, valid_loss: 0.018238103948533535\n",
      "EPOCH: 14, train_loss: 0.019471565285363257, valid_loss: 0.018239849945530295\n",
      "EPOCH: 15, train_loss: 0.019375296978232186, valid_loss: 0.018264387734234333\n",
      "EPOCH: 16, train_loss: 0.019292977208701465, valid_loss: 0.018265291349962354\n",
      "EPOCH: 17, train_loss: 0.01913809262884733, valid_loss: 0.018197561847046018\n",
      "EPOCH: 18, train_loss: 0.019015098563753642, valid_loss: 0.01808464527130127\n",
      "EPOCH: 19, train_loss: 0.018770650793344546, valid_loss: 0.017932424088940024\n",
      "EPOCH: 20, train_loss: 0.01859027314453553, valid_loss: 0.018148753326386213\n",
      "EPOCH: 21, train_loss: 0.018321513819197815, valid_loss: 0.017992172157391906\n",
      "EPOCH: 22, train_loss: 0.017949310035850756, valid_loss: 0.01803879253566265\n",
      "EPOCH: 23, train_loss: 0.01757318848887315, valid_loss: 0.018110781209543347\n",
      "EPOCH: 24, train_loss: 0.017179157955046646, valid_loss: 0.018170897848904133\n",
      "EPOCH: 25, train_loss: 0.016685644212441567, valid_loss: 0.018191954120993614\n",
      "EPOCH: 26, train_loss: 0.016181977179187994, valid_loss: 0.018209490226581693\n",
      "EPOCH: 27, train_loss: 0.01575693168128148, valid_loss: 0.018235362134873867\n",
      "EPOCH: 28, train_loss: 0.015472528070975572, valid_loss: 0.01820672652684152\n",
      "EPOCH: 29, train_loss: 0.015339593438861461, valid_loss: 0.018226265674456954\n",
      "FOLD: 6\n",
      "EPOCH: 0, train_loss: 0.6591734213706775, valid_loss: 0.2524167951196432\n",
      "EPOCH: 1, train_loss: 0.0570426683825178, valid_loss: 0.02155303070321679\n",
      "EPOCH: 2, train_loss: 0.022870641130094346, valid_loss: 0.01977550331503153\n",
      "EPOCH: 3, train_loss: 0.02147238250248707, valid_loss: 0.018373823259025812\n",
      "EPOCH: 4, train_loss: 0.020525723385314148, valid_loss: 0.018882408272475004\n",
      "EPOCH: 5, train_loss: 0.02022162273239631, valid_loss: 0.01785167190246284\n",
      "EPOCH: 6, train_loss: 0.019992114474567082, valid_loss: 0.01761982007883489\n",
      "EPOCH: 7, train_loss: 0.019922433588176202, valid_loss: 0.01762603153474629\n",
      "EPOCH: 8, train_loss: 0.019869888583436992, valid_loss: 0.017855133628472686\n",
      "EPOCH: 9, train_loss: 0.019792493289479844, valid_loss: 0.017734138295054436\n",
      "EPOCH: 10, train_loss: 0.01967813690694479, valid_loss: 0.017802510177716613\n",
      "EPOCH: 11, train_loss: 0.019678068848756645, valid_loss: 0.017620841041207314\n",
      "EPOCH: 12, train_loss: 0.0195877467497037, valid_loss: 0.01753833517432213\n",
      "EPOCH: 13, train_loss: 0.019567453875564612, valid_loss: 0.017519044457003474\n",
      "EPOCH: 14, train_loss: 0.019502566387064945, valid_loss: 0.01756416168063879\n",
      "EPOCH: 15, train_loss: 0.01942243570318589, valid_loss: 0.017327335895970464\n",
      "EPOCH: 16, train_loss: 0.019261346222498477, valid_loss: 0.017564494162797928\n",
      "EPOCH: 17, train_loss: 0.019123227956394356, valid_loss: 0.01722535234875977\n",
      "EPOCH: 18, train_loss: 0.018953722997162588, valid_loss: 0.017175691202282906\n",
      "EPOCH: 19, train_loss: 0.018740287193885215, valid_loss: 0.017118870047852397\n",
      "EPOCH: 20, train_loss: 0.018539495455722015, valid_loss: 0.017095851013436913\n",
      "EPOCH: 21, train_loss: 0.01825760808797219, valid_loss: 0.01696859300136566\n",
      "EPOCH: 22, train_loss: 0.017900721289408512, valid_loss: 0.016989317256957293\n",
      "EPOCH: 23, train_loss: 0.017510146881716374, valid_loss: 0.017054243944585323\n",
      "EPOCH: 24, train_loss: 0.017063456420332957, valid_loss: 0.0170130159240216\n",
      "EPOCH: 25, train_loss: 0.016581133437844422, valid_loss: 0.016952047357335687\n",
      "EPOCH: 26, train_loss: 0.016033496516637314, valid_loss: 0.017074235016480088\n",
      "EPOCH: 27, train_loss: 0.015615431209787345, valid_loss: 0.017081186641007662\n",
      "EPOCH: 28, train_loss: 0.015316314541567594, valid_loss: 0.01710896915756166\n",
      "EPOCH: 29, train_loss: 0.015177204058720516, valid_loss: 0.017102473648265004\n",
      "FOLD: 7\n",
      "EPOCH: 0, train_loss: 0.6562635702422902, valid_loss: 0.2603236101567745\n",
      "EPOCH: 1, train_loss: 0.05687949799378462, valid_loss: 0.022082178154960275\n",
      "EPOCH: 2, train_loss: 0.023192893973068347, valid_loss: 0.019508663332089782\n",
      "EPOCH: 3, train_loss: 0.021747314595157587, valid_loss: 0.026979519985616207\n",
      "EPOCH: 4, train_loss: 0.0226789742613895, valid_loss: 0.018438335740938783\n",
      "EPOCH: 5, train_loss: 0.02103890455033206, valid_loss: 0.01913520391099155\n",
      "EPOCH: 6, train_loss: 0.020541391076072106, valid_loss: 0.01802817336283624\n",
      "EPOCH: 7, train_loss: 0.020370000053810167, valid_loss: 0.018525612773373723\n",
      "EPOCH: 8, train_loss: 0.020276503448810757, valid_loss: 0.017867036862298846\n",
      "EPOCH: 9, train_loss: 0.020206378041943418, valid_loss: 0.018134930403903127\n",
      "EPOCH: 10, train_loss: 0.020063967420424843, valid_loss: 0.01778845372609794\n",
      "EPOCH: 11, train_loss: 0.019821430261753783, valid_loss: 0.01804943196475506\n",
      "EPOCH: 12, train_loss: 0.019852564469734324, valid_loss: 0.018018331844359636\n",
      "EPOCH: 13, train_loss: 0.019882577412490603, valid_loss: 0.01763579691760242\n",
      "EPOCH: 14, train_loss: 0.019741196256083778, valid_loss: 0.017707846825942397\n",
      "EPOCH: 15, train_loss: 0.019578246423338032, valid_loss: 0.017666645580902696\n",
      "EPOCH: 16, train_loss: 0.01955461575166334, valid_loss: 0.017625965643674135\n",
      "EPOCH: 17, train_loss: 0.019437019866478594, valid_loss: 0.017538964049890637\n",
      "EPOCH: 18, train_loss: 0.019288988477444348, valid_loss: 0.01806771382689476\n",
      "EPOCH: 19, train_loss: 0.019278108719972115, valid_loss: 0.017437082948163152\n",
      "EPOCH: 20, train_loss: 0.018940380196782607, valid_loss: 0.017480386653915048\n",
      "EPOCH: 21, train_loss: 0.018597840579061567, valid_loss: 0.017493819585070014\n",
      "EPOCH: 22, train_loss: 0.01836625335714485, valid_loss: 0.017391415778547525\n",
      "EPOCH: 23, train_loss: 0.017985776726958117, valid_loss: 0.017443488817662\n",
      "EPOCH: 24, train_loss: 0.01758802783545814, valid_loss: 0.0174422818236053\n",
      "EPOCH: 25, train_loss: 0.017103335466471654, valid_loss: 0.01745871314778924\n",
      "EPOCH: 26, train_loss: 0.016697881177445, valid_loss: 0.017462151823565364\n",
      "EPOCH: 27, train_loss: 0.016349573372096957, valid_loss: 0.017529751639813185\n",
      "EPOCH: 28, train_loss: 0.016108337412529355, valid_loss: 0.017533979145810008\n",
      "EPOCH: 29, train_loss: 0.01594745943063422, valid_loss: 0.017513197846710682\n",
      "FOLD: 8\n",
      "EPOCH: 0, train_loss: 0.6571799795838851, valid_loss: 0.25453358702361584\n",
      "EPOCH: 1, train_loss: 0.055664283023038996, valid_loss: 0.021301957545801997\n",
      "EPOCH: 2, train_loss: 0.022930009172687046, valid_loss: 0.019639505771920085\n",
      "EPOCH: 3, train_loss: 0.02189974562276768, valid_loss: 0.018942321185022593\n",
      "EPOCH: 4, train_loss: 0.020878181144406524, valid_loss: 0.017913786228746176\n",
      "EPOCH: 5, train_loss: 0.02025710977613926, valid_loss: 0.01756047224625945\n",
      "EPOCH: 6, train_loss: 0.02012996109131771, valid_loss: 0.017281340202316642\n",
      "EPOCH: 7, train_loss: 0.019881057187537604, valid_loss: 0.017575781093910336\n",
      "EPOCH: 8, train_loss: 0.019896151309337796, valid_loss: 0.017229029210284352\n",
      "EPOCH: 9, train_loss: 0.01979911294353159, valid_loss: 0.0171969827497378\n",
      "EPOCH: 10, train_loss: 0.019777181004232997, valid_loss: 0.01748593896627426\n",
      "EPOCH: 11, train_loss: 0.01978779897753951, valid_loss: 0.017051493865437806\n",
      "EPOCH: 12, train_loss: 0.01976702428316768, valid_loss: 0.01717719272710383\n",
      "EPOCH: 13, train_loss: 0.01961540608796515, valid_loss: 0.0173042124370113\n",
      "EPOCH: 14, train_loss: 0.01959607830341858, valid_loss: 0.017357042524963617\n",
      "EPOCH: 15, train_loss: 0.01955016645826871, valid_loss: 0.0170530560426414\n",
      "EPOCH: 16, train_loss: 0.019425602676936344, valid_loss: 0.01711448945570737\n",
      "EPOCH: 17, train_loss: 0.019276339796525013, valid_loss: 0.016847659135237336\n",
      "EPOCH: 18, train_loss: 0.019168061546132535, valid_loss: 0.017073644557967782\n",
      "EPOCH: 19, train_loss: 0.0190411875896816, valid_loss: 0.01679800229612738\n",
      "EPOCH: 20, train_loss: 0.01874880296991596, valid_loss: 0.016975940437987447\n",
      "EPOCH: 21, train_loss: 0.018572302322976197, valid_loss: 0.01667209737934172\n",
      "EPOCH: 22, train_loss: 0.018155312872951544, valid_loss: 0.016769165406003594\n",
      "EPOCH: 23, train_loss: 0.01785361585266228, valid_loss: 0.016750308452174067\n",
      "EPOCH: 24, train_loss: 0.01744620960583038, valid_loss: 0.01679366361349821\n",
      "EPOCH: 25, train_loss: 0.017031709062336368, valid_loss: 0.0167881561210379\n",
      "EPOCH: 26, train_loss: 0.016471849129641357, valid_loss: 0.01683604612480849\n",
      "EPOCH: 27, train_loss: 0.01604947977098106, valid_loss: 0.016886220197193325\n",
      "EPOCH: 28, train_loss: 0.015765207241984863, valid_loss: 0.016862793127074838\n",
      "EPOCH: 29, train_loss: 0.01569760449324982, valid_loss: 0.016895721317268908\n",
      "FOLD: 9\n",
      "EPOCH: 0, train_loss: 0.6561539618274833, valid_loss: 0.27003926783800125\n",
      "EPOCH: 1, train_loss: 0.056221827652446835, valid_loss: 0.02146724541671574\n",
      "EPOCH: 2, train_loss: 0.023370168160034132, valid_loss: 0.019799302332103252\n",
      "EPOCH: 3, train_loss: 0.022007912468118004, valid_loss: 0.021818295354023576\n",
      "EPOCH: 4, train_loss: 0.0214058668411608, valid_loss: 0.019108418375253677\n",
      "EPOCH: 5, train_loss: 0.02067318364176192, valid_loss: 0.02898616809397936\n",
      "EPOCH: 6, train_loss: 0.020448057829767843, valid_loss: 0.01786815677769482\n",
      "EPOCH: 7, train_loss: 0.02033375550202931, valid_loss: 0.01825003605335951\n",
      "EPOCH: 8, train_loss: 0.020297490225373943, valid_loss: 0.01772856363095343\n",
      "EPOCH: 9, train_loss: 0.020108305177168002, valid_loss: 0.017604205291718245\n",
      "EPOCH: 10, train_loss: 0.020128281763460064, valid_loss: 0.017349847126752138\n",
      "EPOCH: 11, train_loss: 0.01992665792379198, valid_loss: 0.0174073688685894\n",
      "EPOCH: 12, train_loss: 0.019698123518330387, valid_loss: 0.017659701639786363\n",
      "EPOCH: 13, train_loss: 0.019696985288888594, valid_loss: 0.017251054057851434\n",
      "EPOCH: 14, train_loss: 0.019709704738534704, valid_loss: 0.01780432602390647\n",
      "EPOCH: 15, train_loss: 0.01971884607042693, valid_loss: 0.01742390776053071\n",
      "EPOCH: 16, train_loss: 0.019709706778013255, valid_loss: 0.017465232871472836\n",
      "EPOCH: 17, train_loss: 0.019584296778127362, valid_loss: 0.017174588050693274\n",
      "EPOCH: 18, train_loss: 0.019314693522792827, valid_loss: 0.0170527552254498\n",
      "EPOCH: 19, train_loss: 0.01926455818871154, valid_loss: 0.01698515983298421\n",
      "EPOCH: 20, train_loss: 0.01925288706640654, valid_loss: 0.016848824452608824\n",
      "EPOCH: 21, train_loss: 0.019057653726467602, valid_loss: 0.016991898184642196\n",
      "EPOCH: 22, train_loss: 0.018699975896485244, valid_loss: 0.016857086215168238\n",
      "EPOCH: 23, train_loss: 0.018342906868533244, valid_loss: 0.016887829871848226\n",
      "EPOCH: 24, train_loss: 0.018170819700330118, valid_loss: 0.016883407719433308\n",
      "EPOCH: 25, train_loss: 0.017716582227922693, valid_loss: 0.01688304916024208\n",
      "EPOCH: 26, train_loss: 0.017325160576950147, valid_loss: 0.016881708288565278\n",
      "EPOCH: 27, train_loss: 0.01723083643879317, valid_loss: 0.016826994833536446\n",
      "EPOCH: 28, train_loss: 0.01684161064604038, valid_loss: 0.01688457850832492\n",
      "EPOCH: 29, train_loss: 0.01674078592346816, valid_loss: 0.016895615146495402\n",
      "FOLD: 10\n",
      "EPOCH: 0, train_loss: 0.6580508725765424, valid_loss: 0.2391317430883646\n",
      "EPOCH: 1, train_loss: 0.05694095446513249, valid_loss: 0.02124537294730544\n",
      "EPOCH: 2, train_loss: 0.0226922995195939, valid_loss: 0.019395752111449838\n",
      "EPOCH: 3, train_loss: 0.021856361283705786, valid_loss: 0.018228732515126467\n",
      "EPOCH: 4, train_loss: 0.020702217060786027, valid_loss: 0.017712755361571908\n",
      "EPOCH: 5, train_loss: 0.020277710679249886, valid_loss: 0.018038460984826088\n",
      "EPOCH: 6, train_loss: 0.020072140539876927, valid_loss: 0.017426528269425035\n",
      "EPOCH: 7, train_loss: 0.019951469861926176, valid_loss: 0.017435387475416064\n",
      "EPOCH: 8, train_loss: 0.01984560604278858, valid_loss: 0.01735199009999633\n",
      "EPOCH: 9, train_loss: 0.01980032767049777, valid_loss: 0.017454402754083276\n",
      "EPOCH: 10, train_loss: 0.01977104514550704, valid_loss: 0.01743449456989765\n",
      "EPOCH: 11, train_loss: 0.019792196054298144, valid_loss: 0.017245687311515212\n",
      "EPOCH: 12, train_loss: 0.019711926101874083, valid_loss: 0.01718997466377914\n",
      "EPOCH: 13, train_loss: 0.019601797088025473, valid_loss: 0.017677721800282598\n",
      "EPOCH: 14, train_loss: 0.01952194233830923, valid_loss: 0.01721477718092501\n",
      "EPOCH: 15, train_loss: 0.01950591358427818, valid_loss: 0.017238580621778965\n",
      "EPOCH: 16, train_loss: 0.019306623950027503, valid_loss: 0.01762910862453282\n",
      "EPOCH: 17, train_loss: 0.019224622645057164, valid_loss: 0.017266154987737536\n",
      "EPOCH: 18, train_loss: 0.01911473639595967, valid_loss: 0.017198673449456692\n",
      "EPOCH: 19, train_loss: 0.01886462016652028, valid_loss: 0.017042283667251468\n",
      "EPOCH: 20, train_loss: 0.01868454770495494, valid_loss: 0.01713297702372074\n",
      "EPOCH: 21, train_loss: 0.01843301120858926, valid_loss: 0.01709287823177874\n",
      "EPOCH: 22, train_loss: 0.01806109694716258, valid_loss: 0.01708544883877039\n",
      "EPOCH: 23, train_loss: 0.017663862412938706, valid_loss: 0.016975413309410214\n",
      "EPOCH: 24, train_loss: 0.01721598735700051, valid_loss: 0.01695870910771191\n",
      "EPOCH: 25, train_loss: 0.016681098295614507, valid_loss: 0.017065655440092087\n",
      "EPOCH: 26, train_loss: 0.016130845623616226, valid_loss: 0.01706062420271337\n",
      "EPOCH: 27, train_loss: 0.015669348601920482, valid_loss: 0.017054342664778233\n",
      "EPOCH: 28, train_loss: 0.01535565041913054, valid_loss: 0.017070931615307927\n",
      "EPOCH: 29, train_loss: 0.015233712569356728, valid_loss: 0.017053564777597785\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [561, 42, 256, 1881, 1903, 2020, 567]\n",
    "oof_model1 = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    print(f\"SEED: {seed}\")\n",
    "    oof_, predictions_ = run_k_fold(FOLDS, seed)\n",
    "    oof_model1 += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof_model1\n",
    "test[target_cols] = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T20:24:25.433732Z",
     "iopub.status.busy": "2020-11-10T20:24:25.432694Z",
     "iopub.status.idle": "2020-11-10T20:24:25.462796Z",
     "shell.execute_reply": "2020-11-10T20:24:25.462293Z"
    },
    "papermill": {
     "duration": 0.899622,
     "end_time": "2020-11-10T20:24:25.462903",
     "exception": false,
     "start_time": "2020-11-10T20:24:24.563281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save oof \n",
    "os.makedirs('MODELS_OOF/', exist_ok=True)\n",
    "\n",
    "#will store our models here\n",
    "np.save('MODELS_OOF/oof_model1.npy', oof_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T20:24:27.197733Z",
     "iopub.status.busy": "2020-11-10T20:24:27.196400Z",
     "iopub.status.idle": "2020-11-10T20:24:28.391964Z",
     "shell.execute_reply": "2020-11-10T20:24:28.390908Z"
    },
    "papermill": {
     "duration": 2.068522,
     "end_time": "2020-11-10T20:24:28.392085",
     "exception": false,
     "start_time": "2020-11-10T20:24:26.323563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.015454305745102563\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T20:24:30.186433Z",
     "iopub.status.busy": "2020-11-10T20:24:30.184081Z",
     "iopub.status.idle": "2020-11-10T20:24:33.308219Z",
     "shell.execute_reply": "2020-11-10T20:24:33.306974Z"
    },
    "papermill": {
     "duration": 4.043545,
     "end_time": "2020-11-10T20:24:33.308365",
     "exception": false,
     "start_time": "2020-11-10T20:24:29.264820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_1 = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "sub_1.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T20:24:35.331338Z",
     "iopub.status.busy": "2020-11-10T20:24:35.329870Z",
     "iopub.status.idle": "2020-11-10T20:24:35.334047Z",
     "shell.execute_reply": "2020-11-10T20:24:35.334781Z"
    },
    "papermill": {
     "duration": 0.919125,
     "end_time": "2020-11-10T20:24:35.334923",
     "exception": false,
     "start_time": "2020-11-10T20:24:34.415798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3982, 207)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T20:24:37.080442Z",
     "iopub.status.busy": "2020-11-10T20:24:37.079145Z",
     "iopub.status.idle": "2020-11-10T20:24:37.082534Z",
     "shell.execute_reply": "2020-11-10T20:24:37.082027Z"
    },
    "papermill": {
     "duration": 0.889481,
     "end_time": "2020-11-10T20:24:37.082644",
     "exception": false,
     "start_time": "2020-11-10T20:24:36.193163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BLEND = sub_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T20:24:38.907824Z",
     "iopub.status.busy": "2020-11-10T20:24:38.906849Z",
     "iopub.status.idle": "2020-11-10T20:24:41.768787Z",
     "shell.execute_reply": "2020-11-10T20:24:41.768139Z"
    },
    "papermill": {
     "duration": 3.787362,
     "end_time": "2020-11-10T20:24:41.768901",
     "exception": false,
     "start_time": "2020-11-10T20:24:37.981539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET_COL = ['5-alpha_reductase_inhibitor', '11-beta-hsd1_inhibitor', 'acat_inhibitor', 'acetylcholine_receptor_agonist', 'acetylcholine_receptor_antagonist', 'acetylcholinesterase_inhibitor', 'adenosine_receptor_agonist', 'adenosine_receptor_antagonist', 'adenylyl_cyclase_activator', 'adrenergic_receptor_agonist', 'adrenergic_receptor_antagonist', 'akt_inhibitor', 'aldehyde_dehydrogenase_inhibitor', 'alk_inhibitor', 'ampk_activator', 'analgesic', 'androgen_receptor_agonist', 'androgen_receptor_antagonist', 'anesthetic_-_local', 'angiogenesis_inhibitor', 'angiotensin_receptor_antagonist', 'anti-inflammatory', 'antiarrhythmic', 'antibiotic', 'anticonvulsant', 'antifungal', 'antihistamine', 'antimalarial', 'antioxidant', 'antiprotozoal', 'antiviral', 'apoptosis_stimulant', 'aromatase_inhibitor', 'atm_kinase_inhibitor', 'atp-sensitive_potassium_channel_antagonist', 'atp_synthase_inhibitor', 'atpase_inhibitor', 'atr_kinase_inhibitor', 'aurora_kinase_inhibitor', 'autotaxin_inhibitor', 'bacterial_30s_ribosomal_subunit_inhibitor', 'bacterial_50s_ribosomal_subunit_inhibitor', 'bacterial_antifolate', 'bacterial_cell_wall_synthesis_inhibitor', 'bacterial_dna_gyrase_inhibitor', 'bacterial_dna_inhibitor', 'bacterial_membrane_integrity_inhibitor', 'bcl_inhibitor', 'bcr-abl_inhibitor', 'benzodiazepine_receptor_agonist', 'beta_amyloid_inhibitor', 'bromodomain_inhibitor', 'btk_inhibitor', 'calcineurin_inhibitor', 'calcium_channel_blocker', 'cannabinoid_receptor_agonist', 'cannabinoid_receptor_antagonist', 'carbonic_anhydrase_inhibitor', 'casein_kinase_inhibitor', 'caspase_activator', 'catechol_o_methyltransferase_inhibitor', 'cc_chemokine_receptor_antagonist', 'cck_receptor_antagonist', 'cdk_inhibitor', 'chelating_agent', 'chk_inhibitor', 'chloride_channel_blocker', 'cholesterol_inhibitor', 'cholinergic_receptor_antagonist', 'coagulation_factor_inhibitor', 'corticosteroid_agonist', 'cyclooxygenase_inhibitor', 'cytochrome_p450_inhibitor', 'dihydrofolate_reductase_inhibitor', 'dipeptidyl_peptidase_inhibitor', 'diuretic', 'dna_alkylating_agent', 'dna_inhibitor', 'dopamine_receptor_agonist', 'dopamine_receptor_antagonist', 'egfr_inhibitor', 'elastase_inhibitor', 'erbb2_inhibitor', 'estrogen_receptor_agonist', 'estrogen_receptor_antagonist', 'faah_inhibitor', 'farnesyltransferase_inhibitor', 'fatty_acid_receptor_agonist', 'fgfr_inhibitor', 'flt3_inhibitor', 'focal_adhesion_kinase_inhibitor', 'free_radical_scavenger', 'fungal_squalene_epoxidase_inhibitor', 'gaba_receptor_agonist', 'gaba_receptor_antagonist', 'gamma_secretase_inhibitor', 'glucocorticoid_receptor_agonist', 'glutamate_inhibitor', 'glutamate_receptor_agonist', 'glutamate_receptor_antagonist', 'gonadotropin_receptor_agonist', 'gsk_inhibitor', 'hcv_inhibitor', 'hdac_inhibitor', 'histamine_receptor_agonist', 'histamine_receptor_antagonist', 'histone_lysine_demethylase_inhibitor', 'histone_lysine_methyltransferase_inhibitor', 'hiv_inhibitor', 'hmgcr_inhibitor', 'hsp_inhibitor', 'igf-1_inhibitor', 'ikk_inhibitor', 'imidazoline_receptor_agonist', 'immunosuppressant', 'insulin_secretagogue', 'insulin_sensitizer', 'integrin_inhibitor', 'jak_inhibitor', 'kit_inhibitor', 'laxative', 'leukotriene_inhibitor', 'leukotriene_receptor_antagonist', 'lipase_inhibitor', 'lipoxygenase_inhibitor', 'lxr_agonist', 'mdm_inhibitor', 'mek_inhibitor', 'membrane_integrity_inhibitor', 'mineralocorticoid_receptor_antagonist', 'monoacylglycerol_lipase_inhibitor', 'monoamine_oxidase_inhibitor', 'monopolar_spindle_1_kinase_inhibitor', 'mtor_inhibitor', 'mucolytic_agent', 'neuropeptide_receptor_antagonist', 'nfkb_inhibitor', 'nicotinic_receptor_agonist', 'nitric_oxide_donor', 'nitric_oxide_production_inhibitor', 'nitric_oxide_synthase_inhibitor', 'norepinephrine_reuptake_inhibitor', 'nrf2_activator', 'opioid_receptor_agonist', 'opioid_receptor_antagonist', 'orexin_receptor_antagonist', 'p38_mapk_inhibitor', 'p-glycoprotein_inhibitor', 'parp_inhibitor', 'pdgfr_inhibitor', 'pdk_inhibitor', 'phosphodiesterase_inhibitor', 'phospholipase_inhibitor', 'pi3k_inhibitor', 'pkc_inhibitor', 'potassium_channel_activator', 'potassium_channel_antagonist', 'ppar_receptor_agonist', 'ppar_receptor_antagonist', 'progesterone_receptor_agonist', 'progesterone_receptor_antagonist', 'prostaglandin_inhibitor', 'prostanoid_receptor_antagonist', 'proteasome_inhibitor', 'protein_kinase_inhibitor', 'protein_phosphatase_inhibitor', 'protein_synthesis_inhibitor', 'protein_tyrosine_kinase_inhibitor', 'radiopaque_medium', 'raf_inhibitor', 'ras_gtpase_inhibitor', 'retinoid_receptor_agonist', 'retinoid_receptor_antagonist', 'rho_associated_kinase_inhibitor', 'ribonucleoside_reductase_inhibitor', 'rna_polymerase_inhibitor', 'serotonin_receptor_agonist', 'serotonin_receptor_antagonist', 'serotonin_reuptake_inhibitor', 'sigma_receptor_agonist', 'sigma_receptor_antagonist', 'smoothened_receptor_antagonist', 'sodium_channel_inhibitor', 'sphingosine_receptor_agonist', 'src_inhibitor', 'steroid', 'syk_inhibitor', 'tachykinin_antagonist', 'tgf-beta_receptor_inhibitor', 'thrombin_inhibitor', 'thymidylate_synthase_inhibitor', 'tlr_agonist', 'tlr_antagonist', 'tnf_inhibitor', 'topoisomerase_inhibitor', 'transient_receptor_potential_channel_antagonist', 'tropomyosin_receptor_kinase_inhibitor', 'trpv_agonist', 'trpv_antagonist', 'tubulin_inhibitor', 'tyrosine_kinase_inhibitor', 'ubiquitin_specific_protease_inhibitor', 'vegfr_inhibitor', 'vitamin_b', 'vitamin_d_receptor_agonist', 'wnt_inhibitor']\n",
    "NUM_TARGET = len(TARGET_COL)\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/lish-moa/sample_submission.csv\")\n",
    "\n",
    "public_id = list(df['sig_id'].values)\n",
    "\n",
    "df_test = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\n",
    "test_id = list(df_test['sig_id'].values)\n",
    "\n",
    "private_id = list(set(test_id)-set(public_id))\n",
    "\n",
    "df_submit = pd.DataFrame(index = public_id+private_id, columns=TARGET_COL)\n",
    "df_submit.index.name = 'sig_id'\n",
    "df_submit[:] = 0\n",
    "df_predict = BLEND.copy()\n",
    "df_submit.loc[df_predict.sig_id,:] = df_predict[TARGET_COL].values\n",
    "df_submit.loc[df_test[df_test.cp_type=='ctl_vehicle'].sig_id]= 0\n",
    "df_submit.to_csv('submission.csv',index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 3307.273865,
   "end_time": "2020-11-10T20:24:43.162309",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-10T19:29:35.888444",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
